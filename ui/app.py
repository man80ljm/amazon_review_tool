# ui/app.py
import sys
import os
from huggingface_hub import snapshot_download
import queue
import traceback

from pathlib import Path
from config import load_user_settings, save_user_settings

import os
import threading
import tkinter as tk
from tkinter import ttk, filedialog, messagebox

import pandas as pd
import numpy as np

from config import AppConfig
from core.io_utils import load_file, save_csv, save_excel, ensure_dir
from core.sentiment import SentimentAnalyzer
from core.embedding import Embedder
from core.clustering import scan_k, fit_kmeans
from core.keywords import top_keywords_by_cluster
from core.representatives import top_representatives
from core.robustness import clustering_stability

from core.plot_k import recommend_k, plot_k_curves
from core.plot_style import apply_matplotlib_style
from core.translate import Translator
from core.insights import asin_cluster_percent, plot_heatmap, cluster_priority, plot_priority,cluster_priority_safe

from core.report_word import build_offline_report


class App(ttk.Frame):
    def __init__(self, master, cfg: AppConfig):
        super().__init__(master)
        self.master = master
        self.cfg = cfg

        # âœ…ã€åŠ åœ¨è¿™é‡Œã€‘è®¾ç½®çª—å£é»˜è®¤å¤§å°
        self.master.geometry("960x550")   # ä½ å¯ä»¥æ”¹è¿™ä¸ªæ•°
        self.master.minsize(960, 550)      # å¯é€‰ï¼šé˜²æ­¢ç¼©å¤ªå°
        
        # åŠ è½½æœ¬åœ° settings.json
        settings = load_user_settings()
        self.cfg.apply_user_settings(settings)

        #æ‰“åŒ…ååŠ è½½æ¨¡å‹è·¯å¾„ä¿®æ­£
        from config import resolve_path
        self._resolve_path = resolve_path

        self.cfg.sentiment_model = resolve_path(getattr(self.cfg, "sentiment_model", "models/sentiment"))
        self.cfg.embedding_model = resolve_path(getattr(self.cfg, "embedding_model", "models/embedding"))
        self.cfg.translate_model_zh_en = resolve_path(getattr(self.cfg, "translate_model_zh_en", "models/translate/zh_en"))
        self.cfg.translate_model_en_zh = resolve_path(getattr(self.cfg, "translate_model_en_zh", "models/translate/en_zh"))
        self.sentiment_model_label_to_key = {}
        self.sentiment_model_key_to_label = {}

        
        # è®¾ç½®æ¸…åé•œåƒ
        os.environ['HF_ENDPOINT'] = 'https://mirrors.tuna.tsinghua.edu.cn/huggingface-hub'
        os.environ['HF_HUB_OFFLINE'] = '0'

        self.df = None
        self.df_work = None
        self.emb = None
        self.labels = None
        self.centers = None
        self.k_scan = None
        self.cluster_keywords = None
        self.cluster_reps = None
        self._translators = {}
        self.output_dir = os.path.join(os.getcwd(), "outputs")
        ensure_dir(self.output_dir)

        self._build_ui()
        self.log_queue = queue.Queue()
        self._start_log_pump()
        self._log("App started. Ready.")
        self._job_lock = threading.Lock()
        self._running = False

        # ====== graceful shutdown support ======
        self._threads = []         # ç”¨æ¥ä¿å­˜åå°çº¿ç¨‹ï¼ˆdaemon=Falseï¼‰
        self._closing = False      # é€€å‡ºæ ‡è®°
        self._log_pump_id = None   # after å¥æŸ„ï¼ˆç”¨äº cancelï¼‰
        
        # ğŸ”¥ å…³é”®ï¼šç»‘å®šçª—å£å…³é—­äº‹ä»¶
        self.master.protocol("WM_DELETE_WINDOW", self._on_close)

    def _build_ui(self):
        self.master.title("Review Analyzer")
        self.pack(fill="both", expand=True)

        top = ttk.Frame(self)
        top.pack(fill="x", padx=10, pady=8)

        # ä¸¤è¡Œå·¥å…·æ 
        row1 = ttk.Frame(top)
        row1.pack(fill="x")
        row2 = ttk.Frame(top)
        row2.pack(fill="x", pady=(6, 0))

        # ===== Row1ï¼šä¸»æµç¨‹ =====
        self.btn_import = ttk.Button(row1, text="å¯¼å…¥æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰", command=self.on_load_csv)
        self.btn_import.pack(side="left")

        self.btn_run_all = ttk.Button(row1, text="è¿è¡Œ Step1-5ï¼ˆå…¨æµç¨‹ï¼‰", command=self.on_run_all)
        self.btn_run_all.pack(side="left", padx=8)

        self.btn_export = ttk.Button(row1, text="å¯¼å‡ºç»“æœ", command=self.on_export)
        self.btn_export.pack(side="left")

        self.btn_kplot = ttk.Button(row1, text="å¯¼å‡º/æ˜¾ç¤ºKé€‰æ‹©å›¾", command=self.on_plot_k)
        self.btn_kplot.pack(side="left", padx=8)

        self.btn_compare = ttk.Button(row1, text="è·¨ASINå¯¹æ¯”", command=self.on_asin_compare)
        self.btn_compare.pack(side="left", padx=8)

        self.btn_priority = ttk.Button(row1, text="ä¼˜å…ˆçº§æ’åº", command=self.on_priority)
        self.btn_priority.pack(side="left", padx=8)

        # å³ä¾§çŠ¶æ€
        self.status = tk.StringVar(value="Ready")
        ttk.Label(row1, textvariable=self.status).pack(side="right")

        # ===== Row2ï¼šè¯­è¨€ + ç¦»çº¿æŠ¥å‘Šï¼ˆå·²å»æ‰ LLM ç›¸å…³ï¼‰ =====
        ttk.Label(row2, text="æ–‡æœ¬è¯­è¨€:").pack(side="left")

        self.lang_var = tk.StringVar(value=getattr(self.cfg, "text_language", "en"))
        self.lang_box = ttk.Combobox(
            row2,
            textvariable=self.lang_var,
            values=["en", "zh_cn"],
            width=8,
            state="readonly"
        )
        self.lang_box.pack(side="left", padx=(6, 12))
        self.lang_box.bind("<<ComboboxSelected>>", self.on_language_changed)

        # è¾“å‡ºè¯­è¨€ï¼ˆç¿»è¯‘è¾“å‡ºï¼‰
        ttk.Label(row2, text="è¾“å‡ºè¯­è¨€:").pack(side="left")
        self.output_lang_label_to_key = {"åŸæ–‡": "none", "ä¸­æ–‡": "zh", "è‹±æ–‡": "en"}
        self.output_lang_key_to_label = {v: k for k, v in self.output_lang_label_to_key.items()}
        cur_out = (getattr(self.cfg, "output_language", "none") or "none").strip().lower()
        self.output_lang_var = tk.StringVar(value=self.output_lang_key_to_label.get(cur_out, "åŸæ–‡"))
        self.output_lang_box = ttk.Combobox(
            row2,
            textvariable=self.output_lang_var,
            values=list(self.output_lang_label_to_key.keys()),
            width=8,
            state="readonly"
        )
        self.output_lang_box.pack(side="left", padx=(6, 12))
        self.output_lang_box.bind("<<ComboboxSelected>>", self.on_output_language_changed)

        # æƒ…æ„Ÿæ¨¡å‹é€‰æ‹©
        ttk.Label(row2, text="æƒ…æ„Ÿæ¨¡å‹:").pack(side="left")
        self.sentiment_model_var = tk.StringVar(value="")
        self.sentiment_model_box = ttk.Combobox(
            row2,
            textvariable=self.sentiment_model_var,
            values=[],
            width=20,
            state="readonly"
        )
        self.sentiment_model_box.pack(side="left", padx=(6, 12))
        self.sentiment_model_box.bind("<<ComboboxSelected>>", self.on_sentiment_model_changed)

        current_key = self._derive_sentiment_key_from_cfg()
        self._refresh_sentiment_model_options(self.cfg.text_language, select_key=current_key, save=False)

        # ç¦»çº¿æŠ¥å‘ŠæŒ‰é’®
        self.btn_report_offline = ttk.Button(row2, text="ç”ŸæˆWordæŠ¥å‘Šï¼ˆç¦»çº¿ï¼‰", command=self.on_report_offline)
        self.btn_report_offline.pack(side="left", padx=(0, 8))

        # å ä½ï¼šè®©å¸ƒå±€æ›´ç¾è§‚
        ttk.Label(row2, text=" ").pack(side="left", expand=True)

        # è¿›åº¦æ¡
        self.progress = ttk.Progressbar(self, mode="determinate")
        self.progress.pack(fill="x", padx=10, pady=6)

        nb = ttk.Notebook(self)
        nb.pack(fill="both", expand=True, padx=10, pady=10)

        self.tab_data = ttk.Frame(nb)
        self.tab_k = ttk.Frame(nb)
        self.tab_results = ttk.Frame(nb)
        self.tab_log = ttk.Frame(nb)

        nb.add(self.tab_data, text="æ•°æ®é¢„è§ˆ")
        nb.add(self.tab_k, text="é€‰Kç»“æœ")
        nb.add(self.tab_results, text="èšç±»ç»“æœ")
        nb.add(self.tab_log, text="è¿è¡Œæ—¥å¿—")

        # Data preview
        self.data_text = tk.Text(self.tab_data, height=18, wrap="none")
        self.data_text.pack(fill="both", expand=True)

        # K scan
        self.k_text = tk.Text(self.tab_k, height=18, wrap="none")
        self.k_text.pack(fill="both", expand=True)

        # Results
        self.res_text = tk.Text(self.tab_results, height=18, wrap="none")
        self.res_text.pack(fill="both", expand=True)

        # Log
        self.log_text = tk.Text(self.tab_log, height=18, wrap="word")
        self.log_text.pack(fill="both", expand=True)

        # Bottom controls
        bottom = ttk.Frame(self)
        bottom.pack(fill="x", padx=10, pady=6)
        row1 = ttk.Frame(bottom)
        row1.pack(fill="x")
        row2 = ttk.Frame(bottom)
        row2.pack(fill="x", pady=(4, 0))

        # ====== é˜ˆå€¼å˜é‡ï¼ˆä» cfg è¯»ï¼Œç¡®ä¿ UI æ‰“å¼€å°±æ˜¾ç¤ºå½“å‰å€¼ï¼‰======
        self.star_th_var = tk.DoubleVar(value=float(getattr(self.cfg, "star_negative_threshold", 4.0)))
        self.conf_th_var = tk.DoubleVar(value=float(getattr(self.cfg, "sentiment_conf_threshold", 0.6)))

        # ====== FUSION æƒé‡/é˜ˆå€¼ ======
        self.fusion_w_star_var = tk.DoubleVar(value=float(getattr(self.cfg, "fusion_w_star", 1.0)))
        self.fusion_w_sent_var = tk.DoubleVar(value=float(getattr(self.cfg, "fusion_w_sent", 1.0)))
        self.fusion_keep_var = tk.DoubleVar(value=float(getattr(self.cfg, "fusion_keep_threshold", 1.0)))

        # ====== K æ¨èå‚æ•° ======
        self.k_weight_var = tk.DoubleVar(value=float(getattr(self.cfg, "k_score_weight", 0.7)))
        self.k_penalty_th_var = tk.IntVar(value=int(getattr(self.cfg, "k_penalty_threshold", 12)))
        self.k_penalty_strength_var = tk.DoubleVar(value=float(getattr(self.cfg, "k_penalty_strength", 0.02)))

        self.auto_apply_k = tk.BooleanVar(value=True)
        ttk.Checkbutton(row1, text="æ‰«æåè‡ªåŠ¨åº”ç”¨æ¨èK", variable=self.auto_apply_k).pack(side="left", padx=10)

        ttk.Label(row1, text="èšç±»K:").pack(side="left")
        self.k_var = tk.IntVar(value=5)
        ttk.Spinbox(
            row1,
            from_=self.cfg.k_min,
            to=self.cfg.k_max,
            textvariable=self.k_var,
            width=5
        ).pack(side="left", padx=6)

        # NOTE: comment text was garbled; replaced with English placeholder.
        ttk.Label(row1, text="wK").pack(side="left", padx=(8, 2))
        self.k_weight_spin = ttk.Spinbox(
            row1, from_=0.0, to=1.0, increment=0.05,
            textvariable=self.k_weight_var, width=4
        )
        self.k_weight_spin.pack(side="left")

        ttk.Label(row1, text="K>=").pack(side="left", padx=(5, 2))
        self.k_penalty_th_spin = ttk.Spinbox(
            row1, from_=2, to=50, increment=1,
            textvariable=self.k_penalty_th_var, width=4
        )
        self.k_penalty_th_spin.pack(side="left")

        ttk.Label(row1, text="penalty").pack(side="left", padx=(5, 2))
        self.k_penalty_strength_spin = ttk.Spinbox(
            row1, from_=0.0, to=0.5, increment=0.01,
            textvariable=self.k_penalty_strength_var, width=5
        )
        self.k_penalty_strength_spin.pack(side="left")

        # ä»…åˆ†æè´Ÿé¢
        self.only_negative = tk.BooleanVar(value=True)
        self.cb_only_negative = ttk.Checkbutton(
            row2,
            text="ä»…åˆ†æè´Ÿé¢",
            variable=self.only_negative
        )
        self.cb_only_negative.pack(side="left", padx=10)

        # ===== è´Ÿé¢ç­›é€‰ç­–ç•¥ï¼ˆSTAR / FUSION / SENTIMENTï¼‰=====
        ttk.Label(row2, text="è´Ÿé¢åˆ¤å®š:").pack(side="left", padx=(10, 4))

        self.negative_mode_var = tk.StringVar(
            value=getattr(self.cfg, "negative_mode", "STAR_ONLY")
        )

        self.negative_mode_box = ttk.Combobox(
            row2,
            textvariable=self.negative_mode_var,
            values=["STAR_ONLY", "FUSION", "SENTIMENT_ONLY"],
            width=14,
            state="readonly"
        )
        self.negative_mode_box.pack(side="left")
        self.negative_mode_box.bind("<<ComboboxSelected>>", self.on_negative_mode_changed)

        # =========================================================
        # ğŸ”¥ æ–°å¢ï¼šå‚æ•°å¾®è°ƒæ§ä»¶ (Star / Conf / Fusion Weights)
        # =========================================================
        
        # 1. Star é˜ˆå€¼
        ttk.Label(row2, text="Star<=").pack(side="left", padx=(10, 2))
        self.star_th_spin = ttk.Spinbox(
            row2, from_=1.0, to=5.0, increment=0.5,
            textvariable=self.star_th_var, width=4
        )
        self.star_th_spin.pack(side="left")

        # 2. Conf é˜ˆå€¼
        ttk.Label(row2, text="Conf>=").pack(side="left", padx=(8, 2))
        self.conf_th_spin = ttk.Spinbox(
            row2, from_=0.0, to=1.0, increment=0.05,
            textvariable=self.conf_th_var, width=4
        )
        self.conf_th_spin.pack(side="left")

        # 3. Fusion å‚æ•° (W_Star, W_Sent, Keep)
        ttk.Label(row2, text="wStar").pack(side="left", padx=(8, 2))
        self.fusion_w_star_spin = ttk.Spinbox(
            row2, from_=0.0, to=5.0, increment=0.1,
            textvariable=self.fusion_w_star_var, width=4
        )
        self.fusion_w_star_spin.pack(side="left")

        ttk.Label(row2, text="wSent").pack(side="left", padx=(5, 2))
        self.fusion_w_sent_spin = ttk.Spinbox(
            row2, from_=0.0, to=5.0, increment=0.1,
            textvariable=self.fusion_w_sent_var, width=4
        )
        self.fusion_w_sent_spin.pack(side="left")

        ttk.Label(row2, text="Keep>=").pack(side="left", padx=(5, 2))
        self.fusion_keep_spin = ttk.Spinbox(
            row2, from_=0.0, to=5.0, increment=0.1,
            textvariable=self.fusion_keep_var, width=4
        )
        self.fusion_keep_spin.pack(side="left")

        # =========================================================

        self.btn_run_cluster = ttk.Button(
            row2,
            text="ä»…é‡è·‘ Step4-5",
            command=self.on_run_cluster_only
        )
        self.btn_run_cluster.pack(side="right", padx=(10, 0))

        # ğŸ”¥ ç»‘å®šè‡ªåŠ¨ä¿å­˜äº‹ä»¶ (å›è½¦ OR å¤±å»ç„¦ç‚¹)
        def _bind_save(widget, func):
            widget.bind("<Return>", func)
            widget.bind("<FocusOut>", func)

        _bind_save(self.star_th_spin, self.on_thresholds_changed)
        _bind_save(self.conf_th_spin, self.on_thresholds_changed)
        _bind_save(self.fusion_w_star_spin, self.on_thresholds_changed)
        _bind_save(self.fusion_w_sent_spin, self.on_thresholds_changed)
        _bind_save(self.fusion_keep_spin, self.on_thresholds_changed)
        _bind_save(self.k_weight_spin, self.on_thresholds_changed)
        _bind_save(self.k_penalty_th_spin, self.on_thresholds_changed)
        _bind_save(self.k_penalty_strength_spin, self.on_thresholds_changed)


    def _set_progress(self, cur, total, msg):
        """çº¿ç¨‹å®‰å…¨è¿›åº¦æ›´æ–°ï¼šåå°çº¿ç¨‹è°ƒç”¨ä¹Ÿä¸ä¼šç¢° Tkã€‚"""
        def _apply():
            try:
                self.status.set(msg)
                self.progress["maximum"] = max(int(total), 1)
                self.progress["value"] = int(cur)
                self.master.update_idletasks()
            except Exception:
                pass

        self._ui(_apply)          # UI æ›´æ–°å›ä¸»çº¿ç¨‹
        self._log(f"[{cur}/{total}] {msg}")  # æ—¥å¿—ç”¨é˜Ÿåˆ—ï¼Œçº¿ç¨‹å®‰å…¨

    def _start_log_pump(self):
        """
        å°† log_queue çš„å†…å®¹åˆ·åˆ° Text æ§ä»¶ã€‚
        å…³é”®ï¼šä¿å­˜ after idï¼Œé€€å‡ºæ—¶ after_cancelï¼Œé¿å… mainloop ç»“æŸåä»ç„¶å›è°ƒå¯¼è‡´å´©æºƒã€‚
        """
        import queue

        def pump():
            # å¦‚æœæ­£åœ¨å…³é—­ï¼Œå°±ä¸å†è°ƒåº¦
            if getattr(self, "_closing", False):
                return

            try:
                while True:
                    msg = self.log_queue.get_nowait()
                    if hasattr(self, "log_text") and self.log_text is not None:
                        try:
                            self.log_text.insert("end", msg + "\n")
                            self.log_text.see("end")
                        except Exception:
                            pass  # çª—å£å·²é”€æ¯
            except queue.Empty:
                pass

            # ä¿å­˜å¥æŸ„ï¼Œé€€å‡ºæ—¶å¯å–æ¶ˆ
            if not getattr(self, "_closing", False):
                try:
                    self._log_pump_id = self.after(120, pump)
                except Exception:
                    pass  # çª—å£å·²é”€æ¯

        pump()

    def _log(self, msg: str):
        """çº¿ç¨‹å®‰å…¨æ—¥å¿—ï¼šåå°çº¿ç¨‹ä¹Ÿå¯ä»¥è°ƒç”¨ã€‚"""
        try:
            self.log_queue.put(str(msg))
        except Exception:
            pass  # é˜Ÿåˆ—å·²å…³é—­/é”€æ¯

    def _log_exception(self, e: Exception):
        """æŠŠå¼‚å¸¸å †æ ˆå†™è¿›æ—¥å¿—ï¼Œæ–¹ä¾¿å®šä½ã€‚"""
        self._log("âŒ ERROR: " + str(e))
        self._log(traceback.format_exc())

    def _ui(self, fn, *args, **kwargs):
        """ä¿è¯ UI æ“ä½œåœ¨ä¸»çº¿ç¨‹æ‰§è¡Œ"""
        try:
            self.master.after(0, lambda: fn(*args, **kwargs))
        except Exception:
            pass

    def _set_running(self, is_running: bool):
        """ç»Ÿä¸€ç®¡ç†è¿è¡ŒçŠ¶æ€ + æŒ‰é’®å¯ç”¨æ€§ï¼ˆé˜²è¿ç‚¹ï¼‰"""
        self._running = is_running
        state = "disabled" if is_running else "normal"
        try:
            # è¿™äº›æŒ‰é’®åå­—æŒ‰ä½ çš„å®é™…å˜é‡åæ”¹ä¸€ä¸‹ï¼ˆä¸‹é¢æˆ‘ä¹Ÿç»™ä½ æœ€é€šç”¨å†™æ³•ï¼‰
            self.btn_run_all.config(state=state)
            self.btn_run_cluster.config(state=state)
            self.btn_export.config(state=state)
            self.btn_kplot.config(state=state)
            self.btn_compare.config(state=state)
            self.btn_priority.config(state=state)
            self.btn_report_offline.config(state=state)
            self.btn_import.config(state=state)
        except Exception:
            # å¦‚æœä½ æ²¡ä¿å­˜æŒ‰é’®å¼•ç”¨ï¼Œä¹Ÿæ²¡å…³ç³»ï¼šè‡³å°‘é˜²æ­¢çº¿ç¨‹é‡å…¥
            pass

    def on_load_csv(self):
        path = filedialog.askopenfilename(
            filetypes=[("CSV / Excel Files", "*.csv *.xlsx")]
        )

        if not path:
            return

        try:
            # ========= 1) å…ˆå®Œæ•´åŠ è½½æ–‡ä»¶ï¼ˆä¸åšä»»ä½•åˆ—åå‡è®¾ï¼‰ =========
            self.df = load_file(path, required_cols=None)

            # æ¸…ç©ºä¸­é—´çŠ¶æ€
            self.df_work = None
            self.emb = None
            self.labels = None
            self.centers = None
            self.k_scan = None
            self.cluster_keywords = None
            self.cluster_reps = None

            # ========= 2) è‡ªåŠ¨è¯†åˆ«åˆ—åï¼ˆå…³é”®æ–°å¢ï¼‰ =========
            self._auto_map_fields(self.df)

            fm = self.cfg.field_map  # è¯†åˆ«åçš„æ˜ å°„ç»“æœ

            # ========= 3) ç»Ÿä¸€å†…éƒ¨å­—æ®µï¼ˆåç»­æµç¨‹åªç”¨ _xxxï¼‰ =========
            self.df["_text"] = self.df[fm["text"]]

            # star / scoreï¼ˆå¯é€‰ï¼‰
            star_col = fm.get("star")
            if star_col and star_col in self.df.columns:
                self.df["_score"] = self.df[star_col]
            else:
                self.df["_score"] = None

            # asin / groupï¼ˆå¯é€‰ï¼‰
            asin_col = fm.get("asin")
            if asin_col and asin_col in self.df.columns:
                self.df["_group"] = self.df[asin_col]
            else:
                self.df["_group"] = None

            # idï¼ˆå¯é€‰ï¼‰
            id_col = fm.get("id")
            if id_col and id_col in self.df.columns:
                self.df["_id"] = self.df[id_col]
            else:
                self.df["_id"] = self.df.index.astype(str)

            # ========= 4) é¢„è§ˆ & æ—¥å¿— =========
            self.data_text.delete("1.0", "end")
            self.data_text.insert("end", f"Loaded: {path}\n")
            self.data_text.insert("end", f"Rows: {len(self.df)}\n\n")

            self._log(f"Loaded file: {path}")
            self._log(f"Total rows: {len(self.df)}")

            empty_text = self.df["_text"].astype(str).str.strip().eq("").sum()
            self._log(f"Empty text rows: {empty_text}")

            self.data_text.insert("end", self.df.head(20).to_string(index=False))

            self.status.set("Data loaded & auto-mapped")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", str(e))

    def _run_in_thread(self, fn, start_msg="Task started..."):
        """
        ç»Ÿä¸€çº¿ç¨‹å®‰å…¨æ‰§è¡Œå™¨
        ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿çº¿ç¨‹æ­£ç¡®æ¸…ç†
        """
        import threading

        # æ­£åœ¨å…³é—­å°±åˆ«å†å¯åŠ¨ä»»åŠ¡äº†
        if getattr(self, "_closing", False):
            return

        # é˜²è¿ç‚¹ï¼ˆä¸»çº¿ç¨‹ï¼‰
        if getattr(self, "_running", False):
            self._log("âš ï¸ æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆåå†æ“ä½œã€‚")
            return

        def ui(callable_):
            # å¦‚æœæ­£åœ¨å…³é—­ï¼Œä¸å†è§¦å‘ UI æ›´æ–°
            if getattr(self, "_closing", False):
                return
            try:
                self.master.after(0, callable_)
            except Exception:
                pass  # çª—å£å·²é”€æ¯ï¼Œå¿½ç•¥

        def runner():
            try:
                ui(lambda: self._set_running(True))
                ui(lambda: self.status.set("Running"))
                ui(lambda: self._log(f"â–¶ {start_msg}"))

                fn()  # åå°æ‰§è¡Œï¼šåªåšè®¡ç®—/IO/APIï¼ˆä¸è¦ç›´æ¥ç¢° Tkï¼‰

                ui(lambda: self.status.set("Done"))
                ui(lambda: self._log("âœ… Task finished."))

            except Exception as e:
                ui(lambda: self.status.set("Error"))
                ui(lambda: self._log_exception(e))
                ui(lambda: messagebox.showerror("é”™è¯¯", str(e)))
            finally:
                ui(lambda: self._set_running(False))

        t = threading.Thread(target=runner, daemon=False)  # daemon=False å¯ä»¥ join
        # ğŸ”¥ è®°å½•çº¿ç¨‹ï¼Œé€€å‡ºæ—¶ join
        if not hasattr(self, "_threads"):
            self._threads = []
        self._threads.append(t)
        t.start()
        
    def on_run_all(self):
        """
        å…¨æµç¨‹ï¼šStep1â€“5ï¼ˆä»…è®¡ç®—ï¼Œä¸å¯¼å‡ºã€ä¸å‡ºå›¾ã€ä¸ç”ŸæˆæŠ¥å‘Šï¼‰
        å…³é”®ä¿®å¤ï¼š
        - åœ¨ä¸»çº¿ç¨‹ä¸€æ¬¡æ€§è¯»å– Tk å˜é‡ï¼ˆonly_negative/auto_apply_k/k_varï¼‰
        - åå°çº¿ç¨‹ job() / _pipeline_all() å†…ç¦æ­¢å† .get() / .set()
        - è‡ªåŠ¨åº”ç”¨æ¨èKï¼šç”¨ _ui å›ä¸»çº¿ç¨‹ set
        - è¡¥é½ self.cluster_reps ç­‰çŠ¶æ€å˜é‡ï¼Œä¿è¯å¯¼å‡º/æŠ¥å‘Šå¯ç”¨
        """
        if self.df is None or len(self.df) == 0:
            messagebox.showwarning("æç¤º", "è¯·å…ˆå¯¼å…¥æ•°æ®æ–‡ä»¶")
            return

        # âœ… ä¸»çº¿ç¨‹ä¸€æ¬¡æ€§è¯»å– Tk å˜é‡ï¼ˆéå¸¸å…³é”®ï¼šåå°çº¿ç¨‹ç¦æ­¢å† get/setï¼‰
        try:
            only_negative_flag = bool(self.only_negative.get())
        except Exception:
            only_negative_flag = False

        try:
            auto_apply_flag = bool(self.auto_apply_k.get())
        except Exception:
            auto_apply_flag = False

        try:
            k_used_ui = int(self.k_var.get())
        except Exception:
            k_used_ui = None

        self.artifacts_dirty = True

        # UIï¼šå¿™ç¢Œæç¤ºæ”¾ä¸»çº¿ç¨‹
        try:
            self._busy(True, "å…¨æµç¨‹åˆ†æä¸­...")
        except Exception:
            pass

        def job():
            try:
                self._pipeline_all(
                    only_negative_flag=only_negative_flag,
                    auto_apply_flag=auto_apply_flag,
                    k_used_ui=k_used_ui
                )

                # UI ç»“æŸï¼ˆå¿…é¡»ä¸»çº¿ç¨‹ï¼‰
                def done():
                    try:
                        self._busy(False, "åˆ†æå®Œæˆ")
                    except Exception:
                        pass
                    messagebox.showinfo(
                        "å®Œæˆ",
                        "Step1â€“5 å·²å®Œæˆã€‚\n\n"
                        "è¯·æŒ‰éœ€ç‚¹å‡»ï¼š\n"
                        "â€¢ å¯¼å‡ºç»“æœ\n"
                        "â€¢ å¯¼å‡º K é€‰æ‹©å›¾\n"
                        "â€¢ è·¨ ASIN å¯¹æ¯”\n"
                        "â€¢ ä¼˜å…ˆçº§æ’åº\n"
                        "â€¢ ç”Ÿæˆ Word æŠ¥å‘Š"
                    )
                    self._log("Step1â€“5 completed. Waiting for user actions.")

                self._ui(done)

            except Exception as e:
                # å¤±è´¥ä¹Ÿè¦è§£é™¤ busyï¼ˆä¸»çº¿ç¨‹ï¼‰
                self._ui(lambda: self._busy(False, "å°±ç»ª"))
                raise

        self._run_in_thread(job, "Running Step1-5 (full pipeline)...")

    def on_run_cluster_only(self):
        """
        ä»…é‡è·‘ Step4â€“5ï¼ˆèšç±» + å…³é”®è¯/ä»£è¡¨è¯„è®ºï¼‰
        ä¿®å¤ç‚¹ï¼š
        1) å…¨éƒ¨èµ° _run_in_thread
        2) è¡¥é½ self.cluster_repsï¼Œå¦åˆ™æŠ¥å‘ŠæŒ‰é’®ä¼šè¯¯åˆ¤
        3) é‡è·‘åæ ‡è®° artifacts_dirty=Falseï¼ˆæ•°æ®å·²é½å…¨ï¼‰
        """
        if self.df_work is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆè¿è¡Œ Step1â€“5")
            return
        if self.emb is None:
            messagebox.showwarning("æç¤º", "Embedding ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ Step1â€“5")
            return

        # UIï¼šå¿™ç¢Œæç¤ºæ”¾ä¸»çº¿ç¨‹
        try:
            self._busy(True, "é‡æ–°èšç±»ä¸­ (Step4â€“5)...")
        except Exception:
            pass

        # é‡è·‘æ„å‘³ç€æ—§äº§ç‰©ä½œåºŸ
        self.artifacts_dirty = True

        def job():
            self.k_used = int(self.k_var.get())
            self._log(f"Re-run clustering with K={self.k_used}")

            # Step4
            self.labels, self.centers = fit_kmeans(
                self.emb,
                k=self.k_used,
                random_state=self.cfg.random_state
            )
            self.df_work["cluster_id"] = self.labels

            # Step5: keywords
            self.cluster_keywords = top_keywords_by_cluster(
                self.df_work[self.cfg.field_map["text"]].tolist(),
                self.labels,
                top_n=self.cfg.top_keywords,
                language=self.cfg.text_language
            )

            # Step5: reps
            reps_dict = top_representatives(
                self.emb,
                self.labels,
                self.centers,
                top_n=self.cfg.top_representatives
            )

            # â˜…å…³é”®ï¼šæŠ¥å‘Š/å¯¼å‡ºä¾èµ–è¿™ä¸ª
            self.cluster_reps = reps_dict

            rows = []
            for cid, idx_list in reps_dict.items():
                for rank, idx in enumerate(idx_list, 1):
                    row = self.df_work.iloc[idx].to_dict()
                    row["cluster_id"] = cid
                    row["rank_in_cluster"] = rank
                    rows.append(row)
            self.reps_df = pd.DataFrame(rows)

            # summary
            cluster_sizes = pd.Series(self.labels).value_counts().sort_index()
            self.cluster_summary = pd.DataFrame({
                "cluster_id": cluster_sizes.index,
                "cluster_size": cluster_sizes.values,
                "ratio": cluster_sizes.values / len(self.labels),
                "keywords": [", ".join(self.cluster_keywords.get(c, [])) for c in cluster_sizes.index]
            }).sort_values("ratio", ascending=False)

            # æ ‡è®°ï¼šå½“å‰äº§ç‰©å·²å‡†å¤‡å¥½
            self.artifacts_dirty = False

            def done():
                try:
                    self._busy(False, "èšç±»å®Œæˆ")
                except Exception:
                    pass
                messagebox.showinfo(
                    "å®Œæˆ",
                    f"å·²ä½¿ç”¨ K={self.k_used} é‡æ–°å®Œæˆèšç±»ã€‚\n\n"
                    "è¯·æŒ‰éœ€ç‚¹å‡»ï¼š\n"
                    "â€¢ å¯¼å‡ºç»“æœ\n"
                    "â€¢ è·¨ ASIN å¯¹æ¯”\n"
                    "â€¢ ä¼˜å…ˆçº§æ’åº\n"
                    "â€¢ ç”Ÿæˆ Word æŠ¥å‘Š"
                )

            self._ui(done)

        self._run_in_thread(job, "Re-running Step4-5 (cluster only)...")

    def _pipeline_all(self, only_negative_flag: bool, auto_apply_flag: bool, k_used_ui: int | None):
        """
        åå°çº¿ç¨‹è¿è¡Œçš„å…¨æµç¨‹é€»è¾‘ï¼ˆStep1-5ï¼‰
        """

        # ç»Ÿä¸€æ‹·è´ä¸€ä»½ï¼Œç”¨äºæœ€ç»ˆå¯¼å‡º"å¸¦æƒ…æ„Ÿæ ‡ç­¾"çš„å…¨é‡æ•°æ®
        df2 = self.df.copy()

        # ---------- Step1: sentimentï¼ˆé»˜è®¤å¯ç”¨ï¼›å¤±è´¥è‡ªåŠ¨é™çº§ï¼‰ ----------
        sent_model = getattr(self.cfg, "sentiment_model", None)

        # å…ˆç»™ sentiment åˆ—ä¸€ä¸ªé»˜è®¤å€¼ï¼Œä¿è¯åç»­é€»è¾‘ç¨³
        df2["sentiment"] = np.nan

        if sent_model:
            try:
                self._set_progress(0, 1, "Loading sentiment model...")
                
                # ğŸ”¥ ä¿®å¤ï¼šè¿™é‡Œä¸è¦ç”¨ embedding_modelï¼
                sa = SentimentAnalyzer(
                    model_name=sent_model,  # â† ç”¨ sentiment_model
                    batch_size=self.cfg.sentiment_batch_size,
                    max_chars=self.cfg.sentiment_max_chars
                )

                # æ³¨æ„ï¼šè¿™é‡Œç”¨ä½ å†…éƒ¨ç»Ÿä¸€åˆ— _text
                sent, conf = SentimentAnalyzer.predict_sentiment_aligned(
                    sa, df2, "_text", progress=self._set_progress, return_conf=True
                )
                df2["sentiment"] = sent
                df2["sentiment_conf"] = conf

                valid_n = int(pd.Series(sent).notna().sum())
                self._log(f"âœ… Sentiment done. valid rows={valid_n}, total={len(df2)}")

            except Exception as e:
                # æƒ…æ„Ÿæ¨¡å‹åŠ è½½/æ¨ç†å¤±è´¥ï¼šä¸ç»ˆæ­¢ï¼Œå…¨é‡ç»§ç»­ + å…è®¸ä»…è´Ÿé¢èµ°æ˜Ÿçº§å…œåº•
                self._log("âš ï¸ Sentiment failed, fallback to star-based negative filter if needed.")
                self._log_exception(e)
        else:
            # ä¸ç¦ç”¨ï¼Œä»…æç¤º
            self._log("âš ï¸ sentiment_model is empty. 'only negative' will fallback to star-based filter if possible.")

        # ---------- Step2: filterï¼ˆç»Ÿä¸€è´Ÿé¢è¿‡æ»¤ç­–ç•¥ï¼‰ ----------
        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šè¿™æ®µä»£ç å¿…é¡»åœ¨ Step1 çš„ if å—ä¹‹å¤–ï¼
        if only_negative_flag:
            # star åˆ—ï¼šä¼˜å…ˆç”¨ field_mapï¼Œå…¶æ¬¡ç”¨å†…éƒ¨ _score
            star_col = None
            try:
                star_col = (self.cfg.field_map.get("star") or "").strip()
            except Exception:
                star_col = None
            if not star_col or star_col not in df2.columns:
                star_col = "_score"

            # sentiment åˆ—ï¼šä½ è¿™é‡Œå›ºå®šå« sentiment
            sentiment_col = "sentiment" if "sentiment" in df2.columns else None

            # ç½®ä¿¡åº¦åˆ—ï¼šå½“å‰ä½ çš„ df2 é‡Œæ²¡æœ‰ sentiment_confï¼ˆå…ˆä¼  Noneï¼Œåç»­å‡çº§æ¨¡å‹è¾“å‡ºæ—¶è¡¥ï¼‰
            sentiment_conf_col = "sentiment_conf" if "sentiment_conf" in df2.columns else None

            mode = getattr(self.cfg, "negative_mode", "STAR_ONLY")
            star_th = float(getattr(self.cfg, "star_negative_threshold", 4.0))
            conf_th = float(getattr(self.cfg, "sentiment_conf_threshold", 0.6))

            # âœ… æ–°å¢ï¼šfusion å‚æ•°
            w_star = float(getattr(self.cfg, "fusion_w_star", 1.0))
            w_sent = float(getattr(self.cfg, "fusion_w_sent", 1.0))
            keep_th = float(getattr(self.cfg, "fusion_keep_threshold", 1.0))

            dfw = self.apply_negative_filter(
                df2,
                star_col=star_col,
                sentiment_col=sentiment_col,
                sentiment_conf_col=sentiment_conf_col,
                mode=mode,
                star_threshold=star_th,
                conf_threshold=conf_th,
                w_star=w_star,
                w_sent=w_sent,
                fusion_keep_threshold=keep_th
            )

            self._log(
                f"only_negative=True | mode={mode} | star_th={star_th} | conf_th={conf_th} | "
                f"w_star={w_star} | w_sent={w_sent} | keep={keep_th} | rows={len(dfw)}"
            )

            # å®‰å…¨å…œåº•ï¼šå¦‚æœç­›å®Œå˜æˆ 0 è¡Œï¼Œè‡ªåŠ¨é™çº§ä¸º ALLï¼ˆé¿å…ç”¨æˆ·è¯¯æ“ä½œç›´æ¥å´©ï¼‰
            if len(dfw) == 0:
                self._log("âš ï¸ è´Ÿé¢è¿‡æ»¤åä¸º 0 è¡Œï¼Œè‡ªåŠ¨é™çº§ä¸º ALLï¼ˆä¸åšè¿‡æ»¤ï¼‰ã€‚")
                dfw = df2.reset_index(drop=True)

        else:
            dfw = df2.reset_index(drop=True)

        self._log(f"only_negative_flag = {only_negative_flag}")
        self._log(f"Rows after filter: {len(dfw)}")

        if len(dfw) < 30:
            raise ValueError(f"è¿‡æ»¤åæ ·æœ¬å¤ªå°‘ï¼ˆ{len(dfw)}ï¼‰ã€‚å»ºè®®å–æ¶ˆä»…è´Ÿé¢æˆ–è°ƒæ•´é˜ˆå€¼/ç­–ç•¥ã€‚")

        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šèµ‹å€¼ç»™ self.df_work
        self.df_work = dfw
        
        self._log(f"âœ… df_work å·²èµ‹å€¼ï¼Œshape={self.df_work.shape}")

        # ---------- Step3: embedding ----------
        self._set_progress(0, 1, "Loading embedding model...")
        
        # ğŸ”¥ è¯Šæ–­ï¼šæ‰“å°æ‰€æœ‰å…³é”®å˜é‡
        self._log(f"ğŸ” DEBUG - df_work ä¿¡æ¯:")
        self._log(f"  - shape: {self.df_work.shape if self.df_work is not None else 'None'}")
        self._log(f"  - columns: {list(self.df_work.columns) if self.df_work is not None else 'None'}")
        self._log(f"  - _text ç±»å‹: {type(self.df_work['_text']) if self.df_work is not None and '_text' in self.df_work.columns else 'N/A'}")
        
        if self.df_work is not None and '_text' in self.df_work.columns:
            texts_raw = self.df_work["_text"]
            self._log(f"  - _text å‰3æ¡: {texts_raw.head(3).tolist()}")
            self._log(f"  - _text.isnull().sum(): {texts_raw.isnull().sum()}")
        
        self._log(f"ğŸ” DEBUG - cfg ä¿¡æ¯:")
        self._log(f"  - embedding_model: {repr(self.cfg.embedding_model)}")
        self._log(f"  - embedding_batch_size: {repr(self.cfg.embedding_batch_size)}")
        self._log(f"  - type(embedding_batch_size): {type(self.cfg.embedding_batch_size)}")
        
        model_name = getattr(self.cfg, "embedding_model", None)
        batch_size_raw = getattr(self.cfg, "embedding_batch_size", None)
        
        self._log(f"ğŸ” DEBUG - getattr ç»“æœ:")
        self._log(f"  - model_name: {repr(model_name)}")
        self._log(f"  - batch_size_raw: {repr(batch_size_raw)}")
        
        if not model_name:
            raise RuntimeError(
                "embedding_model ä¸ºç©º(None)ã€‚\n"
                "é€šå¸¸æ˜¯ settings.json è¦†ç›–å¯¼è‡´ã€‚\n"
                "è§£å†³:åˆ é™¤ settings.json æˆ–åœ¨ settings.json ä¸­è®¾ç½® embedding_model='models/embedding'ã€‚"
            )

        # ğŸ”¥ å…³é”®é˜²å¾¡ï¼šbatch_size
        if batch_size_raw is None or not isinstance(batch_size_raw, (int, float)) or batch_size_raw <= 0:
            self._log(f"âš ï¸ embedding_batch_size æ— æ•ˆ: {repr(batch_size_raw)}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 64")
            batch_size_safe = 64
        else:
            batch_size_safe = int(batch_size_raw)
        
        self._log(f"ğŸ” å‡†å¤‡åˆ›å»º Embedder:")
        self._log(f"  - model_name: {repr(model_name)}")
        self._log(f"  - batch_size: {repr(batch_size_safe)}")
        
        # cache è·¯å¾„
        tag = "neg" if only_negative_flag else "all"
        emb_cache = os.path.join(self.output_dir, f"embeddings_{tag}_{len(self.df_work)}.npy")
        
        # ğŸ”¥ åœ¨åˆ›å»º Embedder ä¹‹å‰æ‰“å°
        self._log("ğŸ” å³å°†æ‰§è¡Œ: emb = Embedder(...)")
        
        try:
            emb = Embedder(
                model_name=model_name,
                batch_size=batch_size_safe
            )
            self._log("âœ… Embedder åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            self._log(f"âŒ Embedder åˆ›å»ºå¤±è´¥!")
            self._log(f"  - Exception type: {type(e)}")
            self._log(f"  - Exception message: {str(e)}")
            raise
        
        # ğŸ”¥ å‡†å¤‡æ–‡æœ¬æ•°æ®
        self._log("ğŸ” å‡†å¤‡ encode çš„æ–‡æœ¬æ•°æ®:")
        
        if self.df_work is None:
            raise RuntimeError("df_work ä¸º None!")
        
        if "_text" not in self.df_work.columns:
            raise RuntimeError(f"df_work ç¼ºå°‘ _text åˆ—! å½“å‰åˆ—: {list(self.df_work.columns)}")
        
        texts_series = self.df_work["_text"]
        self._log(f"  - texts_series ç±»å‹: {type(texts_series)}")
        self._log(f"  - texts_series é•¿åº¦: {len(texts_series) if texts_series is not None else 'None'}")
        
        if texts_series is None:
            raise RuntimeError("df_work['_text'] ä¸º None!")
        
        texts_list = texts_series.fillna("").astype(str).tolist()
        self._log(f"  - texts_list ç±»å‹: {type(texts_list)}")
        self._log(f"  - texts_list é•¿åº¦: {len(texts_list) if texts_list is not None else 'None'}")
        self._log(f"  - texts_list å‰3æ¡: {texts_list[:3] if texts_list else 'None'}")
        
        if texts_list is None:
            raise RuntimeError("texts_list ä¸º None!")
        
        if len(texts_list) == 0:
            raise RuntimeError("texts_list ä¸ºç©ºåˆ—è¡¨!")
        
        self._log("ğŸ” å³å°†æ‰§è¡Œ: emb.encode(...)")
        
        try:
            self.emb = emb.encode(
                texts_list,
                cache_path=emb_cache,
                progress=self._set_progress
            )
            self._log("âœ… emb.encode() æˆåŠŸ")
        except Exception as e:
            self._log(f"âŒ emb.encode() å¤±è´¥!")
            self._log(f"  - Exception type: {type(e)}")
            self._log(f"  - Exception message: {str(e)}")
            raise

        self._log(f"Embedding model: {self.cfg.embedding_model}")
        try:
            self._log(f"Embedding shape: {self.emb.shape}")
        except Exception:
            pass

        # ---------- Step4: scan k ----------
        self._set_progress(0, 1, "Scanning k...")
        self.k_scan = scan_k(
            self.emb,
            self.cfg.k_min,
            self.cfg.k_max,
            random_state=self.cfg.random_state
        )
        self._log(f"K scan done. range=[{self.cfg.k_min},{self.cfg.k_max}]")

        rec = recommend_k(
                self.k_scan.k_to_inertia,
                self.k_scan.k_to_silhouette,
                weight=getattr(self.cfg, "k_score_weight", 0.7),
                penalty_threshold=getattr(self.cfg, "k_penalty_threshold", 12),
                penalty_strength=getattr(self.cfg, "k_penalty_strength", 0.02)
            )
        self.k_best = int(rec.best_k)
        score = self.k_scan.k_to_silhouette.get(rec.best_k, float("nan"))
        self._log(f"Recommended K by {rec.method} = {self.k_best} (score={rec.score})")

        # ä½ åŸæ¥ä¼šæ¸²æŸ“ K æ‰«æç»“æœï¼ˆæ³¨æ„ï¼šæ­¤å‡½æ•°å†…éƒ¨å¿…é¡»çº¿ç¨‹å®‰å…¨ï¼‰
        try:
            self._render_k_scan()
        except Exception as e:
            self._log("âš ï¸ _render_k_scan failed (ignored).")
            self._log_exception(e)

        # ---------- è‡ªåŠ¨åº”ç”¨æ¨èKï¼ˆå¦‚æœå‹¾é€‰ï¼‰ ----------
        # âœ… è¿™é‡Œä¸èƒ½ self.k_var.setï¼Œå¿…é¡»å›ä¸»çº¿ç¨‹
        if auto_apply_flag:
            self._ui(lambda: self.k_var.set(self.k_best))

            # å¦‚æœè‡ªåŠ¨åº”ç”¨æ¨èKï¼Œæˆ‘ä»¬ä¹ŸåŒæ­¥æŠŠ k_used_ui æ”¹æˆ k_bestï¼ˆç”¨äºæœ¬æ¬¡èšç±»ï¼‰
            k_for_cluster = self.k_best
        else:
            # ä¸è‡ªåŠ¨åº”ç”¨ï¼šç”¨ç”¨æˆ·ç‚¹å‡»æŒ‰é’®é‚£ä¸€åˆ»çš„ Kï¼ˆä¸»çº¿ç¨‹è¯»å‡ºæ¥çš„ï¼‰
            k_for_cluster = int(k_used_ui) if k_used_ui is not None else self.k_best

        self.k_used = int(k_for_cluster)
        self._log(f"Clustering K used = {self.k_used}")

        # ---------- Step4/5: fit kmeans + keywords + representatives ----------
        # è¿™é‡Œä¸å†è°ƒç”¨ä½ åŸæ¥çš„ _pipeline_cluster_onlyï¼ˆå®ƒå¤§æ¦‚ç‡å†…éƒ¨ä¹Ÿåœ¨ get/set Tk å˜é‡ï¼‰
        self._set_progress(0, 1, f"Clustering with K={self.k_used}...")

        self.labels, self.centers = fit_kmeans(
            self.emb,
            k=self.k_used,
            random_state=self.cfg.random_state
        )

        # å†™å› cluster_idï¼ˆåç»­å¯¼å‡º/å¯¹æ¯”/æŠ¥å‘Šéƒ½ä¾èµ–ï¼‰
        self.df_work["cluster_id"] = self.labels

        self._set_progress(0, 1, "Extracting keywords...")
        self.cluster_keywords = top_keywords_by_cluster(
            self.df_work["_text"].tolist(),
            self.labels,
            top_n=self.cfg.top_keywords,
            language=self.cfg.text_language
        )

        self._set_progress(0, 1, "Selecting representatives...")
        reps_dict = top_representatives(
            self.emb,
            self.labels,
            self.centers,
            top_n=self.cfg.top_representatives
        )

        # â˜…å…³é”®ï¼šæŠ¥å‘Š/å¯¼å‡ºä¾èµ–è¿™ä¸ª
        self.cluster_reps = reps_dict

        # reps_df
        rows = []
        for cid, idx_list in reps_dict.items():
            for rank, idx in enumerate(idx_list, 1):
                row = self.df_work.iloc[int(idx)].to_dict()
                row["cluster_id"] = int(cid)
                row["rank_in_cluster"] = int(rank)
                rows.append(row)
        self.reps_df = pd.DataFrame(rows)

        # cluster_summaryï¼ˆå¯¼å‡º/æŠ¥å‘Šç”¨ï¼‰
        cluster_sizes = pd.Series(self.labels).value_counts().sort_index()
        self.cluster_summary = pd.DataFrame({
            "cluster_id": cluster_sizes.index,
            "cluster_size": cluster_sizes.values,
            "ratio": cluster_sizes.values / len(self.labels),
            "keywords": [", ".join(self.cluster_keywords.get(int(c), [])) for c in cluster_sizes.index]
        }).sort_values("ratio", ascending=False)

        # ---------- Exportï¼ˆä¿ç•™ä½ åŸæ¥çš„ reviews_with_sentiment.csvï¼‰ ----------
        out_csv = os.path.join(self.output_dir, "reviews_with_sentiment.csv")
        save_csv(df2, out_csv)
        self._log(f"Exported: {out_csv}")

        # æ ‡è®°ï¼šå½“å‰äº§ç‰©å·²å‡†å¤‡å¥½
        self.artifacts_dirty = False

    def _is_negative_by_star(self, df: pd.DataFrame) -> pd.Series:
        """
        æƒ…æ„Ÿæ¨¡å‹ä¸å¯ç”¨æ—¶ï¼Œç”¨æ˜Ÿçº§å…œåº•â€œä»…è´Ÿé¢â€ï¼š
        - ä¼˜å…ˆç”¨ _scoreï¼ˆä½ åœ¨ on_load_csv å·²æ˜ å°„ï¼‰
        - æ¬¡é€‰ç”¨ Star
        è§„åˆ™ï¼š<=2 è§†ä¸ºè´Ÿé¢
        """
        s = None
        if "_score" in df.columns:
            s = df["_score"]
        elif "Star" in df.columns:
            s = df["Star"]

        if s is None:
            return pd.Series([False] * len(df), index=df.index)

        s_num = pd.to_numeric(s, errors="coerce")
        return s_num.le(2)

    def _pipeline_cluster_only(self):
        if self.emb is None:
            raise ValueError("embeddings ä¸ºç©ºï¼šè¯·å…ˆè¿è¡Œåˆ° Step3ï¼ˆEmbeddingï¼‰æˆ–ç›´æ¥è¿è¡Œå…¨æµç¨‹ã€‚")
        if self.df_work is None:
            raise ValueError("df_work ä¸ºç©ºï¼šè¯·å…ˆè¿è¡Œå…¨æµç¨‹ï¼ˆè‡³å°‘å®Œæˆè¿‡æ»¤ Step2ï¼‰ï¼Œæˆ–å–æ¶ˆâ€œä»…è´Ÿé¢â€åé‡è¯•ã€‚")

        k = int(self.k_var.get())
        self._set_progress(0, 1, f"Clustering k={k} ...")

        # Step4: KMeans
        labels, centers = fit_kmeans(
            self.emb,
            k=k,
            random_state=self.cfg.random_state
        )

        self.labels = labels
        self.centers = centers

        # å†™å› df_work
        self.df_work["cluster_id"] = labels

        # æ¯ä¸ª cluster çš„æ ·æœ¬æ•°
        sizes = self.df_work["cluster_id"].value_counts().sort_index().to_dict()
        self._log(f"Cluster sizes: {sizes}")

        # Step5: keywordsï¼ˆå…³é”®ï¼šæ¥å…¥è¯­è¨€ï¼‰
        self._set_progress(0, 1, "Extracting keywords...")

        lang = getattr(self.cfg, "text_language", "en")  # æ¥è‡ª UI + settings.json
        self.cluster_keywords = top_keywords_by_cluster(
            self.df_work["_text"].tolist(),
            self.labels,
            top_n=self.cfg.top_keywords,
            language=lang
        )

        self._log(
            f"Keywords extracted for clusters (language={lang}): "
            + ", ".join(str(cid) for cid in self.cluster_keywords.keys())
        )

        # Step5: representatives
        self._set_progress(0, 1, "Finding representatives...")
        self.cluster_reps = top_representatives(
            self.emb,
            self.labels,
            self.centers,
            top_n=self.cfg.top_representatives
        )

        # Robustness
        self._set_progress(0, 1, "Robustness (bootstrap ARI)...")
        stab = clustering_stability(
            self.emb,
            k=k,
            runs=5,
            random_state=self.cfg.random_state
        )

        # Render
        self._render_results(stab)

    def _render_k_scan(self):
        self.k_text.delete("1.0", "end")
        self.k_text.insert("end", "k\tinertia(SSE)\tsilhouette\n")
        for k in range(self.cfg.k_min, self.cfg.k_max + 1):
            sse = self.k_scan.k_to_inertia.get(k, None)
            sil = self.k_scan.k_to_silhouette.get(k, None)
            self.k_text.insert("end", f"{k}\t{(sse or 0):.2f}\t\t{(sil or 0):.4f}\n")

    def _render_results(self, stability: dict):
        self.res_text.delete("1.0", "end")
        self.res_text.insert("end", f"Filtered rows: {len(self.df_work)}\n")
        self.res_text.insert(
            "end",
            f"Stability ARI (bootstrap): mean={stability['ari_mean']:.3f}, "
            f"min={stability['ari_min']:.3f}, max={stability['ari_max']:.3f}\n\n"
        )

        for c in sorted(self.cluster_keywords.keys()):
            self.res_text.insert("end", f"=== Cluster {c} ===\n")
            kws = ", ".join(self.cluster_keywords[c])
            self.res_text.insert("end", f"Keywords: {kws}\n")

            reps = self.cluster_reps.get(c, [])
            self.res_text.insert("end", "Representatives:\n")
            for idx in reps:
                row = self.df_work.iloc[idx]
                gid = row["_group"] if row["_group"] is not None else "-"
                score = row["_score"] if row["_score"] is not None else "-"
                text = str(row["_text"])[:180]
                self.res_text.insert(
                    "end",
                    f"- ({gid}, Score={score}) {text}...\n"
                )
            self.res_text.insert("end", "\n")

    def on_plot_k(self):
        if self.k_scan is None:
            messagebox.showwarning("Warning", "Please run the full pipeline (at least through K scan).")
            return

        def job():
            self._set_progress(0, 1, "Generating K selection plot...")

            rec = recommend_k(
                self.k_scan.k_to_inertia,
                self.k_scan.k_to_silhouette,
                weight=getattr(self.cfg, "k_score_weight", 0.7),
                penalty_threshold=getattr(self.cfg, "k_penalty_threshold", 12),
                penalty_strength=getattr(self.cfg, "k_penalty_strength", 0.02)
            )
            best_k = int(rec.best_k)

            labels = {
                "x_label": "K",
                "y1_label": "WCSS / Inertia",
                "y2_label": "Silhouette Score",
                "line1_label": "WCSS/Inertia (Elbow) - solid (blue)",
                "line2_label": "Silhouette Score - dashed (orange)",
                "title": "Optimal K Selection (Elbow & Silhouette)",
                "title_with_k": f"Optimal K Selection (Recommended K={best_k})",
                "vline_label": f"Recommended K = {best_k} - vertical (green)",
            }

            out_lang = self._get_output_language()
            if out_lang in {"zh", "en"}:
                keys = list(labels.keys())
                vals = self._translate_texts_to(list(labels.values()), src_lang="en", tgt_lang=out_lang)
                labels = dict(zip(keys, vals))

            png_path = os.path.join(self.output_dir, "k_selection.png")
            plot_k_curves(
                self.k_scan.k_to_inertia,
                self.k_scan.k_to_silhouette,
                recommended_k=best_k,
                save_path=png_path,
                lang=self.cfg.text_language,
                labels=labels
            )

            def done():
                if self.auto_apply_k.get():
                    try:
                        self.k_var.set(best_k)
                    except Exception:
                        pass

                cur_k = None
                try:
                    cur_k = int(self.k_var.get())
                except Exception:
                    cur_k = best_k

                self._set_progress(1, 1, "K selection plot ready.")
                messagebox.showinfo(
                    "Done",
                    f"K plot exported:\n{png_path}\n\n"
                    f"Recommended K={best_k}\nCurrent K={cur_k}\n\n"
                    "If you want to update clustering, re-run Step4-5 with current K."
                )

            self._ui(done)

        self._run_in_thread(job, "Generating K selection plot...")
    def on_asin_compare(self):
        """
        Cross-ASIN outputs:
        - ASINCluster heatmap + csv
        - Attribute taxonomy
        - ASINAttribute share heatmap
        - ASINAttribute pain heatmap
        - Opportunity insights
        - Export: asin_attribute_matrix.xlsx
        """
        import os
        import pandas as pd
        from tkinter import messagebox

        if self.df_work is None or "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("Warning", "Please finish clustering (Step4-5) first.")
            return

        def job():
            self._set_progress(0, 1, "Generating cross-ASIN outputs...")

            try:
                df_clustered = self.df_work.copy()

                asin_col = None
                try:
                    asin_col = (self.cfg.field_map.get("asin") or "").strip()
                except Exception:
                    asin_col = None
                if not asin_col:
                    asin_col = "_group"

                if asin_col not in df_clustered.columns:
                    self._ui(lambda: messagebox.showwarning(
                        "Warning",
                        f"Missing ASIN column (current: {asin_col}).\n"
                        "Please check your data or field_map."
                    ))
                    return

                star_col = None
                try:
                    star_col = (self.cfg.field_map.get("star") or "").strip()
                except Exception:
                    star_col = None
                if not star_col or star_col not in df_clustered.columns:
                    star_col = "_score" if "_score" in df_clustered.columns else ("Star" if "Star" in df_clustered.columns else None)

                if star_col is None or star_col not in df_clustered.columns:
                    self._ui(lambda: messagebox.showwarning("Warning", "Missing Star/_score column; cannot compute pain/priority."))
                    return

                cluster_keywords = getattr(self, "cluster_keywords", None)
                if not cluster_keywords:
                    cs = getattr(self, "cluster_summary", None)
                    if cs is not None and hasattr(cs, "columns") and ("cluster_id" in cs.columns) and ("keywords" in cs.columns):
                        cluster_keywords = dict(zip(cs["cluster_id"].tolist(), cs["keywords"].tolist()))

                if not cluster_keywords:
                    self._ui(lambda: messagebox.showwarning("Warning", "Missing cluster_keywords. Run Step5 first."))
                    return

                out_dir = getattr(self, "output_dir", None) or os.path.join(os.getcwd(), "outputs")
                os.makedirs(out_dir, exist_ok=True)

                pivot_cluster = asin_cluster_percent(df_clustered, asin_col=asin_col, cluster_col="cluster_id")

                asin_label_map = None
                out_lang = self._get_output_language()
                if out_lang in {"zh", "en"} and self._translation_needed():
                    asin_vals = [str(v) for v in pivot_cluster.index.tolist()]
                    asin_trans = self._translate_labels(asin_vals)
                    asin_label_map = dict(zip(asin_vals, asin_trans))
                    pivot_cluster = pivot_cluster.copy()
                    pivot_cluster.index = [asin_label_map.get(str(v), str(v)) for v in pivot_cluster.index]

                self.asin_pivot = pivot_cluster

                old_png = os.path.join(out_dir, "asin_cluster_percent_heatmap.png")
                title_cluster = "ASIN  Cluster Share (%)"
                if out_lang in {"zh", "en"}:
                    title_cluster = self._translate_texts_to([title_cluster], "en", out_lang)[0]

                labels = {"x_label": "Cluster ID", "y_label": "ASIN"}
                if out_lang in {"zh", "en"}:
                    keys = list(labels.keys())
                    vals = self._translate_texts_to(list(labels.values()), src_lang="en", tgt_lang=out_lang)
                    labels = dict(zip(keys, vals))

                fig = plot_heatmap(
                    pivot_cluster,
                    save_path=old_png,
                    title=title_cluster,
                    lang=self.cfg.text_language,
                    labels=labels
                )
                import matplotlib.pyplot as plt
                plt.close(fig)

                old_csv = os.path.join(out_dir, "asin_cluster_percent.csv")
                pivot_cluster.round(2).to_csv(old_csv, encoding="utf-8-sig")
                self.asin_heatmap_png = old_png

                from core.insights import (
                    build_attribute_taxonomy,
                    asin_attribute_share,
                    asin_attribute_pain,
                    opportunity_insights,
                )

                taxonomy_df = build_attribute_taxonomy(cluster_keywords, topn=3)
                if self._translation_needed() and "attribute_name" in taxonomy_df.columns:
                    taxonomy_df = taxonomy_df.copy()
                    taxonomy_df["attribute_name"] = self._translate_series(taxonomy_df["attribute_name"])

                share_pivot = asin_attribute_share(
                    df_clustered,
                    asin_col=asin_col,
                    cluster_col="cluster_id",
                    taxonomy_df=taxonomy_df
                )
                pain_pivot = asin_attribute_pain(
                    df_clustered,
                    asin_col=asin_col,
                    cluster_col="cluster_id",
                    star_col=star_col,
                    taxonomy_df=taxonomy_df
                )

                if asin_label_map:
                    share_pivot = share_pivot.copy()
                    share_pivot.index = [asin_label_map.get(str(v), str(v)) for v in share_pivot.index]
                    pain_pivot = pain_pivot.copy()
                    pain_pivot.index = [asin_label_map.get(str(v), str(v)) for v in pain_pivot.index]

                opp_df = opportunity_insights(pain_pivot, topk=15)
                if opp_df is not None and len(opp_df) > 0 and "attribute" in opp_df.columns and self._translation_needed():
                    opp_df = opp_df.copy()
                    opp_df["attribute"] = self._translate_series(opp_df["attribute"])

                out_xlsx = os.path.join(out_dir, "asin_attribute_matrix.xlsx")
                with pd.ExcelWriter(out_xlsx, engine="openpyxl") as writer:
                    taxonomy_df.to_excel(writer, sheet_name="attribute_taxonomy", index=False)
                    share_pivot.to_excel(writer, sheet_name="asin_attribute_share")
                    pain_pivot.to_excel(writer, sheet_name="asin_attribute_pain")
                    (opp_df if opp_df is not None else pd.DataFrame()).to_excel(writer, sheet_name="opportunity_top", index=False)

                import numpy as np
                import matplotlib.pyplot as plt

                def _plot_heatmap(pivot_df: pd.DataFrame, title: str, out_png: str):
                    if pivot_df is None or pivot_df.shape[0] == 0 or pivot_df.shape[1] == 0:
                        return
                    apply_matplotlib_style(self.cfg.text_language)
                    fig = plt.figure(figsize=(12, max(4, 0.35 * pivot_df.shape[0])))
                    ax = fig.add_subplot(111)
                    data = pivot_df.values.astype(float)
                    im = ax.imshow(data, aspect="auto")
                    ax.set_title(title)
                    ax.set_yticks(np.arange(pivot_df.shape[0]))
                    ax.set_yticklabels(pivot_df.index.astype(str).tolist(), fontsize=8)
                    ax.set_xticks(np.arange(pivot_df.shape[1]))
                    ax.set_xticklabels(pivot_df.columns.astype(str).tolist(), rotation=45, ha="right", fontsize=8)
                    fig.colorbar(im, ax=ax, fraction=0.02, pad=0.02)
                    fig.tight_layout()
                    fig.savefig(out_png, dpi=300)
                    plt.close(fig)

                png_share = os.path.join(out_dir, "asin_attribute_share.png")
                png_pain  = os.path.join(out_dir, "asin_attribute_pain.png")
                title_share = "ASIN  Attribute Share (%)"
                title_pain = "ASIN  Attribute Pain (Priority)"
                if out_lang in {"zh", "en"}:
                    title_share, title_pain = self._translate_texts_to(
                        [title_share, title_pain],
                        src_lang="en",
                        tgt_lang=out_lang
                    )

                _plot_heatmap(share_pivot, title_share, png_share)
                _plot_heatmap(pain_pivot, title_pain, png_pain)

                self._set_progress(1, 1, "Cross-ASIN outputs ready.")
                self._ui(lambda: messagebox.showinfo(
                    "Done",
                    "Cross-ASIN outputs saved:\n"
                    f"[Old] Heatmap: {old_png}\n"
                    f"[Old] CSV: {old_csv}\n\n"
                    f"[New] Excel: {out_xlsx}\n"
                    f"[New] Share heatmap: {png_share}\n"
                    f"[New] Pain heatmap: {png_pain}\n"
                ))

            except Exception as e:
                self._ui(lambda: messagebox.showwarning("Warning", f"Cross-ASIN generation failed: {e}"))

        self._run_in_thread(job, "Generating cross-ASIN outputs...")
    def on_priority(self):
        if self.df_work is None or "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("Warning", "Please finish clustering (Step4-5) first.")
            return

        def job():
            self._set_progress(0, 1, "Generating priority outputs...")
            df = self.df_work.copy()

            group_col = None
            for cand in ["ASIN", "asin", "", "place", "group"]:
                if cand in df.columns:
                    group_col = cand
                    break

            if group_col is None:
                df["__GROUP__"] = "ALL"
                group_col = "__GROUP__"

            try:
                star_col = (self.cfg.field_map.get("star") or "").strip()
            except Exception:
                star_col = None

            if not star_col or star_col not in df.columns:
                star_col = "_score"

            if star_col not in df.columns:
                self._ui(lambda: messagebox.showwarning(
                    "Warning",
                    f"Missing rating column (current: {star_col}).\n"
                    "Please check Star/Rating or field_map."
                ))
                return

            pr = cluster_priority_safe(
                df,
                cluster_col="cluster_id",
                star_col=star_col,
                group_col=group_col
            )

            self.priority_df = pr

            png_path = os.path.join(self.output_dir, "cluster_priority.png")
            labels = {
                "x_label": "Cluster ID",
                "y_label": "Priority Score",
                "title": "Cluster Priority Ranking",
            }
            out_lang = self._get_output_language()
            if out_lang in {"zh", "en"}:
                keys = list(labels.keys())
                vals = self._translate_texts_to(list(labels.values()), src_lang="en", tgt_lang=out_lang)
                labels = dict(zip(keys, vals))

            fig = plot_priority(pr, save_path=png_path, lang=self.cfg.text_language, labels=labels)
            import matplotlib.pyplot as plt
            plt.close(fig)

            csv_path = os.path.join(self.output_dir, "cluster_priority.csv")
            pr.to_csv(csv_path, index=False, encoding="utf-8-sig")

            self._set_progress(1, 1, "Priority outputs ready.")
            self._ui(lambda: messagebox.showinfo(
                "Done",
                f"Priority outputs saved:\n{png_path}\n{csv_path}"
            ))

        self._run_in_thread(job, "Generating priority outputs...")

    def on_export(self):
        if self.df_work is None or self.labels is None:
            messagebox.showwarning("Warning", "Please run the pipeline to get clustering results first.")
            return
        if "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("Warning", "cluster_id missing in df_work; re-run Step4-5.")
            return

        def job():
            self._set_progress(0, 1, "Exporting results...")

            detail_path = os.path.join(self.output_dir, "clustered_reviews.csv")
            save_csv(self.df_work, detail_path)

            asin_col = (getattr(self.cfg, "field_map", {}) or {}).get("asin") or None
            star_col = (getattr(self.cfg, "field_map", {}) or {}).get("star") or None
            text_col = (getattr(self.cfg, "field_map", {}) or {}).get("text") or None
            id_col   = (getattr(self.cfg, "field_map", {}) or {}).get("id") or None

            if not asin_col or asin_col not in self.df_work.columns:
                asin_col = "_group" if "_group" in self.df_work.columns else None
            if not star_col or star_col not in self.df_work.columns:
                star_col = "_score" if "_score" in self.df_work.columns else None
            if not text_col or text_col not in self.df_work.columns:
                text_col = "_text" if "_text" in self.df_work.columns else None
            if not id_col or id_col not in self.df_work.columns:
                id_col = "_id" if "_id" in self.df_work.columns else None

            rows = []
            total = len(self.df_work)
            for c in sorted(self.cluster_keywords.keys()):
                idx = (self.df_work["cluster_id"] == c)
                ratio = float(idx.mean()) if total > 0 else 0.0
                rows.append({
                    "cluster_id": int(c),
                    "cluster_size": int(idx.sum()),
                    "ratio": ratio,
                    "keywords": ", ".join(self.cluster_keywords.get(c, [])),
                })
            summary = pd.DataFrame(rows).sort_values("ratio", ascending=False)

            rep_rows = []
            for c, idx_list in (self.cluster_reps or {}).items():
                for rank, i in enumerate(idx_list, start=1):
                    r = self.df_work.iloc[int(i)]
                    rep_rows.append({
                        "cluster_id": int(c),
                        "rank": int(rank),
                        "ASIN": r.get(asin_col, "-") if asin_col else r.get("_group", "-"),
                        "Star": r.get(star_col, "-") if star_col else r.get("_score", "-"),
                        "review_id": r.get(id_col, "-") if id_col else r.get("_id", "-"),
                        "review_text": r.get(text_col, "") if text_col else r.get("_text", ""),
                    })

            reps_df = pd.DataFrame(rep_rows)

            out_lang = self._get_output_language()
            if self._translation_needed():
                if "keywords" in summary.columns:
                    summary = summary.copy()
                    summary["keywords"] = self._translate_series(summary["keywords"])
                if "review_text" in reps_df.columns:
                    reps_df = reps_df.copy()
                    reps_df["review_text"] = self._translate_series(reps_df["review_text"])

            if out_lang in {"zh", "en"}:
                summary.columns = self._translate_texts_to(list(summary.columns), src_lang="en", tgt_lang=out_lang)
                reps_df.columns = self._translate_texts_to(list(reps_df.columns), src_lang="en", tgt_lang=out_lang)

            xlsx_path = os.path.join(self.output_dir, "results.xlsx")
            sheets = {"cluster_summary": summary, "representatives": reps_df}

            if hasattr(self, "asin_pivot") and self.asin_pivot is not None:
                sheets["asin_cluster_percent"] = self.asin_pivot.reset_index()

            if hasattr(self, "priority_df") and self.priority_df is not None:
                sheets["cluster_priority"] = self.priority_df

            save_excel(sheets, xlsx_path)

            self._set_progress(1, 1, "Export complete.")
            self._ui(lambda: messagebox.showinfo(
                "Export complete",
                f"Exported files:\n- {detail_path}\n- {xlsx_path}"
            ))

        self._run_in_thread(job, "Exporting results...")

    def on_report_offline(self):
        if self.df_work is None or self.cluster_keywords is None or self.cluster_reps is None or self.k_scan is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆè¿è¡Œ Step1-5 å¹¶å¾—åˆ°èšç±»ç»“æœåå†ç”ŸæˆæŠ¥å‘Š")
            return
        if "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("æç¤º", "å½“å‰ df_work ç¼ºå°‘ cluster_idï¼Œè¯·å…ˆé‡è·‘ Step4-5")
            return

        def job():
            # ====== åˆ—åå…¼å®¹ï¼šä¼˜å…ˆä½¿ç”¨æ˜ å°„åˆ—ï¼Œå¦åˆ™ç”¨å†…éƒ¨ç»Ÿä¸€åˆ— ======
            asin_col = (getattr(self.cfg, "field_map", {}) or {}).get("asin") or None
            star_col = (getattr(self.cfg, "field_map", {}) or {}).get("star") or None
            text_col = (getattr(self.cfg, "field_map", {}) or {}).get("text") or None
            id_col   = (getattr(self.cfg, "field_map", {}) or {}).get("id") or None

            if not asin_col or asin_col not in self.df_work.columns:
                asin_col = "_group" if "_group" in self.df_work.columns else None
            if not star_col or star_col not in self.df_work.columns:
                star_col = "_score" if "_score" in self.df_work.columns else None
            if not text_col or text_col not in self.df_work.columns:
                text_col = "_text" if "_text" in self.df_work.columns else None
            if not id_col or id_col not in self.df_work.columns:
                id_col = "_id" if "_id" in self.df_work.columns else None

            # summary
            rows = []
            total = len(self.df_work)
            for c in sorted(self.cluster_keywords.keys()):
                idx = (self.df_work["cluster_id"] == c)
                ratio = float(idx.mean()) if total > 0 else 0.0
                rows.append({
                    "cluster_id": int(c),
                    "cluster_size": int(idx.sum()),
                    "ratio": ratio,
                    "keywords": ", ".join(self.cluster_keywords.get(c, [])),
                })
            summary = pd.DataFrame(rows).sort_values("ratio", ascending=False)

            # representatives
            rep_rows = []
            for c, idx_list in (self.cluster_reps or {}).items():
                for rank, i in enumerate(idx_list, start=1):
                    r = self.df_work.iloc[int(i)]
                    rep_rows.append({
                        "cluster_id": int(c),
                        "rank": int(rank),
                        "ASIN": r.get(asin_col, "-") if asin_col else r.get("_group", "-"),
                        "Star": r.get(star_col, "-") if star_col else r.get("_score", "-"),
                        "review_id": r.get(id_col, "-") if id_col else r.get("_id", "-"),
                        "review_text": r.get(text_col, "") if text_col else r.get("_text", ""),
                    })
            reps_df = pd.DataFrame(rep_rows)

            if self._translation_needed():
                if "keywords" in summary.columns:
                    summary = summary.copy()
                    summary["keywords"] = self._translate_series(summary["keywords"])
                if "review_text" in reps_df.columns:
                    reps_df = reps_df.copy()
                    reps_df["review_text"] = self._translate_series(reps_df["review_text"])

            out_lang = self._get_output_language()
            def report_translate(texts):
                if out_lang == "zh":
                    return self._translate_texts_to(texts, src_lang="en", tgt_lang="zh")
                if out_lang == "en":
                    return self._translate_texts_to(texts, src_lang="zh", tgt_lang="en")
                return texts

            # ====== å›¾/è¡¨è·¯å¾„ï¼ˆå­˜åœ¨å°±æ’å…¥ï¼‰ ======
            k_png = os.path.join(self.output_dir, "k_selection.png")

            # âœ… æ—§è·¨ASINçƒ­åŠ›å›¾ï¼šä½ ç°åœ¨ç”Ÿæˆçš„æ˜¯è¿™ä¸ªåå­—
            asin_png = os.path.join(self.output_dir, "asin_cluster_percent_heatmap.png")

            # âœ… Priority å›¾ï¼ˆä¼˜å…ˆçº§æ’åºæŒ‰é’®ç”Ÿæˆï¼‰
            pr_png = os.path.join(self.output_dir, "cluster_priority.png")

            # âœ… æ–°ï¼šASINÃ—Attribute æ ¸å¿ƒå‡çº§äº§ç‰©
            attr_xlsx = os.path.join(self.output_dir, "asin_attribute_matrix.xlsx")
            attr_share_png = os.path.join(self.output_dir, "asin_attribute_share.png")
            attr_pain_png  = os.path.join(self.output_dir, "asin_attribute_pain.png")

            rec = recommend_k(
                self.k_scan.k_to_inertia,
                self.k_scan.k_to_silhouette,
                weight=getattr(self.cfg, "k_score_weight", 0.7),
                penalty_threshold=getattr(self.cfg, "k_penalty_threshold", 12),
                penalty_strength=getattr(self.cfg, "k_penalty_strength", 0.02)
            )
            w = getattr(self.cfg, "k_score_weight", 0.7)
            th = getattr(self.cfg, "k_penalty_threshold", 12)
            ps = getattr(self.cfg, "k_penalty_strength", 0.02)
            k_note_en = (
                "K selection uses a composite score: "
                "score = w*silhouette_norm + (1-w)*elbow_norm - penalty. "
                f"penalty = max(0, k - {th})*{ps}. "
                f"Params: w={w:.2f}, threshold={th}, strength={ps:.3f}. "
                f"Recommended K={int(rec.best_k)}."
            )
            k_note_zh = (
                "K"
                "score = w*silhouette_norm + (1-w)*elbow_norm - penalty"
                f"penalty = max(0, k - {th})*{ps}"
                f"w={w:.2f}={th}={ps:.3f}"
                f"K={int(rec.best_k)}"
            )
            out_lang = self._get_output_language()
            if out_lang == "zh":
                k_method_note = k_note_en
            elif out_lang == "en":
                k_method_note = k_note_zh
            else:
                k_method_note = k_note_zh if self._lang_bucket(self.cfg.text_language) == "zh" else k_note_en

            out_path = build_offline_report(
                cfg=self.cfg,
                output_dir=self.output_dir,
                df_all=self.df,          # åŸå§‹å…¨é‡
                df_work=self.df_work,    # ç”¨äºèšç±»çš„é‚£ä»½
                k_to_inertia=self.k_scan.k_to_inertia,
                k_to_silhouette=self.k_scan.k_to_silhouette,
                k_best=int(rec.best_k),
                cluster_summary=summary,
                reps_df=reps_df,

                # æ—§ï¼šå›¾
                k_plot_png=k_png if os.path.exists(k_png) else None,
                asin_heatmap_png=asin_png if os.path.exists(asin_png) else None,
                priority_png=pr_png if os.path.exists(pr_png) else None,

                # âœ… æ–°ï¼šASINÃ—Attributeï¼ˆæ ¸å¿ƒå‡çº§ï¼‰
                asin_attr_xlsx=attr_xlsx if os.path.exists(attr_xlsx) else None,
                asin_attr_share_png=attr_share_png if os.path.exists(attr_share_png) else None,
                asin_attr_pain_png=attr_pain_png if os.path.exists(attr_pain_png) else None,
                
                key_findings_with_metrics=True,   # âœ… è®ºæ–‡ç‰ˆï¼šå¸¦æ•°å€¼
                translate_fn=report_translate
            )

            self._log(f"âœ… Offline report generated: {out_path}")
            self._ui(lambda: messagebox.showinfo("å®Œæˆ", f"ç¦»çº¿WordæŠ¥å‘Šå·²ç”Ÿæˆï¼š\n{out_path}"))

        self._run_in_thread(job, "Generating offline Word report...")

    def _lang_bucket(self, lang: str) -> str:
        if not lang:
            return "en"
        return "zh" if lang.lower().startswith("zh") else "en"

    def _get_output_language(self) -> str:
        out = getattr(self.cfg, "output_language", "none")
        return (out or "none").strip().lower()

    def _translation_needed(self) -> bool:
        out = self._get_output_language()
        if out not in {"zh", "en"}:
            return False
        src = self._lang_bucket(getattr(self.cfg, "text_language", "en"))
        return out != src

    def _get_translator(self, src: str, tgt: str):
        key = f"{src}->{tgt}"
        if key in self._translators:
            return self._translators[key]

        if src == "zh" and tgt == "en":
            model_path = getattr(self.cfg, "translate_model_zh_en", "")
        else:
            model_path = getattr(self.cfg, "translate_model_en_zh", "")

        try:
            translator = Translator(model_path, batch_size=getattr(self.cfg, "translate_batch_size", 16))
        except Exception as e:
            self._log(f"âš ï¸ Translator init failed: {e}")
            return None

        self._translators[key] = translator
        return translator

    def _translate_texts(self, texts):
        if not texts:
            return texts
        if not self._translation_needed():
            return texts

        src = self._lang_bucket(getattr(self.cfg, "text_language", "en"))
        tgt = self._get_output_language()
        translator = self._get_translator(src, tgt)
        if not translator:
            return texts

        return translator.translate(texts)

    def _translate_texts_to(self, texts, src_lang: str, tgt_lang: str):
        if not texts:
            return texts
        if tgt_lang not in {"zh", "en"} or src_lang == tgt_lang:
            return texts
        translator = self._get_translator(src_lang, tgt_lang)
        if not translator:
            return texts
        return translator.translate(texts)

    def _translate_series(self, s: pd.Series) -> pd.Series:
        texts = ["" if pd.isna(v) else str(v) for v in s.tolist()]
        translated = self._translate_texts(texts)
        return pd.Series(translated, index=s.index)

    def _translate_labels(self, labels):
        texts = ["" if x is None else str(x) for x in labels]
        return self._translate_texts(texts)

    def _sentiment_options_for_lang(self, lang: str):
        if self._lang_bucket(lang) == "zh":
            return [
                ("zh_dianping", "\u4e2d\u6587-\u5927\u4f17\u70b9\u8bc4"),
                ("zh_general", "\u4e2d\u6587-\u901a\u7528"),
                ("zh_chinanews", "\u4e2d\u6587-\u65b0\u95fb"),
                ("zh_jd_binary", "\u4e2d\u6587-\u4eac\u4e1c"),
            ]
        return [("en_sst2", "English-SST2")]

    def _recommended_sentiment_key(self, lang: str) -> str:
        return "zh_dianping" if self._lang_bucket(lang) == "zh" else "en_sst2"

    def _derive_sentiment_key_from_cfg(self) -> str:
        key = getattr(self.cfg, "sentiment_model_key", "") or ""
        if key:
            return key
        model_map = getattr(self.cfg, "sentiment_model_map", {}) or {}
        current = getattr(self.cfg, "sentiment_model", "") or ""
        if not current or not model_map:
            return ""
        for k, p in model_map.items():
            expected = self._resolve_path(p) if hasattr(self, "_resolve_path") else p
            if os.path.normpath(str(current)) == os.path.normpath(str(expected)):
                return k
        return ""

    def _apply_sentiment_model_key(self, key: str, save: bool) -> None:
        model_map = getattr(self.cfg, "sentiment_model_map", {}) or {}
        rel_path = model_map.get(key, "")
        self.cfg.sentiment_model_key = key
        if rel_path:
            self.cfg.sentiment_model = self._resolve_path(rel_path) if hasattr(self, "_resolve_path") else rel_path

        if save:
            save_user_settings({
                "sentiment_model_key": key,
                "sentiment_model": rel_path or getattr(self.cfg, "sentiment_model", None),
            })

    def _refresh_sentiment_model_options(self, lang: str, select_key: str | None = None, save: bool = False) -> None:
        options = self._sentiment_options_for_lang(lang)
        self.sentiment_model_label_to_key = {label: key for key, label in options}
        self.sentiment_model_key_to_label = {key: label for key, label in options}
        self.sentiment_model_box["values"] = [label for _, label in options]

        key = select_key or ""
        if key not in self.sentiment_model_key_to_label:
            key = self._recommended_sentiment_key(lang)
            if key not in self.sentiment_model_key_to_label and options:
                key = options[0][0]

        label = self.sentiment_model_key_to_label.get(key, "")
        if label:
            self.sentiment_model_var.set(label)
        self._apply_sentiment_model_key(key, save=save)

    def on_language_changed(self, event=None):
        self.cfg.text_language = self.lang_var.get().strip()
        self._refresh_sentiment_model_options(
            self.cfg.text_language,
            select_key=self._recommended_sentiment_key(self.cfg.text_language),
            save=False
        )

        model_map = getattr(self.cfg, "sentiment_model_map", {}) or {}
        key = getattr(self.cfg, "sentiment_model_key", "")
        rel_path = model_map.get(key, getattr(self.cfg, "sentiment_model", ""))

        # Save to settings.json
        save_user_settings({
            "text_language": self.cfg.text_language,
            "sentiment_model_key": key,
            "sentiment_model": rel_path,
            "aihubmix_base_url": getattr(self.cfg, "aihubmix_base_url", ""),
            "aihubmix_api_key": getattr(self.cfg, "aihubmix_api_key", None),
            "aihubmix_default_model": getattr(self.cfg, "aihubmix_default_model", ""),
        })

        self._log(f"OK text_language set to: {self.cfg.text_language}")
        messagebox.showinfo("Saved", f"Text language set to: {self.cfg.text_language}\nWill be remembered next time.")

    def on_output_language_changed(self, event=None):
        label = (self.output_lang_var.get() or "").strip()
        key = self.output_lang_label_to_key.get(label, "none")
        self.cfg.output_language = key
        save_user_settings({"output_language": key})
        self._log(f"OK output_language set to: {key}")
        messagebox.showinfo("Saved", f"Output language set to: {label}\nWill be remembered next time.")

    def on_sentiment_model_changed(self, event=None):
        label = self.sentiment_model_var.get().strip()
        key = self.sentiment_model_label_to_key.get(label)
        if not key:
            return
        self._apply_sentiment_model_key(key, save=True)
        self._log(f"OK sentiment_model_key set to: {key}")
        messagebox.showinfo("Saved", f"Sentiment model set to: {label}\nWill be remembered next time.")

    def on_negative_mode_changed(self, event=None):
        """
        UIï¼šè´Ÿé¢ç­›é€‰ç­–ç•¥åˆ‡æ¢
        - STAR_ONLY
        - FUSION
        - SENTIMENT_ONLY
        """
        mode = self.negative_mode_var.get().strip()

        # å†™å›é…ç½®
        self.cfg.negative_mode = mode

        # ä¿å­˜åˆ° settings.jsonï¼ˆå’Œè¯­è¨€åˆ‡æ¢ä¸€è‡´ï¼‰
        save_user_settings({
            "negative_mode": self.cfg.negative_mode
        })

        self._log(f"âœ… negative_mode set to: {self.cfg.negative_mode}")

        messagebox.showinfo(
            "å·²ä¿å­˜",
            f"è´Ÿé¢ç­›é€‰ç­–ç•¥å·²åˆ‡æ¢ä¸ºï¼š\n{self.cfg.negative_mode}\n\n"
            "è¯¥è®¾ç½®å°†ç”¨äºä¸‹ä¸€æ¬¡ Step1â€“5 è¿è¡Œã€‚"
        )

    def on_thresholds_changed(self, event=None):
        """
        å½“ç”¨æˆ·ä¿®æ”¹ä»»æ„ä¸€ä¸ªé˜ˆå€¼/æƒé‡å‚æ•°å¹¶è§¦å‘ä¿å­˜æ—¶è°ƒç”¨ã€‚
        é™é»˜ä¿å­˜åˆ° cfg å’Œ settings.jsonï¼Œå¹¶è®°å½•æ—¥å¿—ã€‚
        """
        try:
            # 1. ä» UI å˜é‡è¯»å–æ•°å€¼
            star_th = float(self.star_th_var.get())
            conf_th = float(self.conf_th_var.get())
            w_star = float(self.fusion_w_star_var.get())
            w_sent = float(self.fusion_w_sent_var.get())
            keep_th = float(self.fusion_keep_var.get())

            # 2. æ›´æ–°å†…å­˜ä¸­çš„ Config å¯¹è±¡ (ä¸‹æ¬¡è¿è¡Œç”Ÿæ•ˆ)
            self.cfg.star_negative_threshold = star_th
            self.cfg.sentiment_conf_threshold = conf_th
            self.cfg.fusion_w_star = w_star
            self.cfg.fusion_w_sent = w_sent
            self.cfg.fusion_keep_threshold = keep_th

            # 3. æŒä¹…åŒ–åˆ° settings.json
            save_user_settings({
                "star_negative_threshold": star_th,
                "sentiment_conf_threshold": conf_th,
                "fusion_w_star": w_star,
                "fusion_w_sent": w_sent,
                "fusion_keep_threshold": keep_th,
            })

            # 4. æ‰“å°æ—¥å¿— (ä¸å¼¹çª—æ‰“æ‰°)
            self._log(
                f"âœ… Params saved: Star<={star_th} | Conf>={conf_th} | "
                f"Fusion(wStar={w_star}, wSent={w_sent}, Keep>={keep_th})"
            )

        except ValueError:
            # é˜²æ­¢ç”¨æˆ·è¾“å…¥éæ³•å­—ç¬¦å¯¼è‡´è½¬æ¢ float å¤±è´¥
            self._log("âš ï¸ å‚æ•°è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œæœªä¿å­˜ã€‚è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—ã€‚")
        except Exception as e:
            self._log(f"âŒ ä¿å­˜å‚æ•°å¤±è´¥: {e}")

    def _tk_ex_handler(exc, val, tb):
        traceback.print_exception(exc, val, tb)

    def pre_download_models(self):
        """
        -huggingface
        exe 
        ./models/
            embedding/  ()
            sentiment/<key>/  ()

        config 
        cfg.embedding_model = "./models/embedding"
        cfg.sentiment_model = "./models/sentiment/<key>"   # 
        """
        # NOTE: comment text was garbled; replaced with English placeholder.
        base_dir = os.path.dirname(os.path.abspath(sys.argv[0]))
        models_root = os.path.join(base_dir, "models")

        emb_path = getattr(self.cfg, "embedding_model", None)
        sent_path = getattr(self.cfg, "sentiment_model", None)
        trans_zh_en = getattr(self.cfg, "translate_model_zh_en", None)
        trans_en_zh = getattr(self.cfg, "translate_model_en_zh", None)

        missing = []

        # NOTE: comment text was garbled; replaced with English placeholder.
        if not emb_path:
            missing.append("embedding_model")
        else:
            # NOTE: comment text was garbled; replaced with English placeholder.
            emb_abs = emb_path
            if not os.path.isabs(emb_abs):
                emb_abs = os.path.join(base_dir, emb_path)
            if not os.path.isdir(emb_abs):
                missing.append(f"Embedding {emb_abs}")
            else:
                self._log(f" Embedding {emb_abs}")
            # NOTE: comment text was garbled; replaced with English placeholder.
            self.cfg.embedding_model = emb_abs

        # NOTE: comment text was garbled; replaced with English placeholder.
        if sent_path:
            sent_abs = sent_path
            if not os.path.isabs(sent_abs):
                sent_abs = os.path.join(base_dir, sent_path)
            if not os.path.isdir(sent_abs):
                missing.append(f"Sentiment {sent_abs}")
            else:
                self._log(f" Sentiment {sent_abs}")
            self.cfg.sentiment_model = sent_abs

        # 2.5) translation models (optional, only if output_language enabled)
        out_lang = self._get_output_language()
        if out_lang in {"zh", "en"}:
            for tag, path in [("Translate zh_en", trans_zh_en), ("Translate en_zh", trans_en_zh)]:
                if not path:
                    missing.append(f"{tag} path missing")
                    continue
                abs_path = path
                if not os.path.isabs(abs_path):
                    abs_path = os.path.join(base_dir, path)
                if not os.path.isdir(abs_path):
                    missing.append(f"{tag} missing: {abs_path}")
                else:
                    self._log(f" {tag} OK: {abs_path}")
                if "zh_en" in tag:
                    self.cfg.translate_model_zh_en = abs_path
                else:
                    self.cfg.translate_model_en_zh = abs_path

        # NOTE: comment text was garbled; replaced with English placeholder.
        # NOTE: comment text was garbled; replaced with English placeholder.
        if emb_path in (None, "", "auto"):
            default_emb = os.path.join(models_root, "embedding")
            if os.path.isdir(default_emb):
                self.cfg.embedding_model = default_emb
                self._log(f" Embedding {default_emb}")
            else:
                missing.append(f"Embedding {default_emb}")

        if sent_path in (None, "", "auto"):
            key = getattr(self.cfg, "sentiment_model_key", "") or ""
            default_sent = None
            if key:
                candidate = os.path.join(models_root, "sentiment", key)
                if os.path.isdir(candidate):
                    default_sent = candidate
            if not default_sent:
                legacy = os.path.join(models_root, "sentiment")
                if os.path.isdir(legacy):
                    default_sent = legacy
            if default_sent:
                self.cfg.sentiment_model = default_sent
                self._log(f" Sentiment {default_sent}")
            else:
                missing.append(f"Sentiment {os.path.join(models_root, 'sentiment')}")

        if out_lang in {"zh", "en"}:
            default_zh_en = os.path.join(models_root, "translate", "zh_en")
            default_en_zh = os.path.join(models_root, "translate", "en_zh")
            if os.path.isdir(default_zh_en):
                self.cfg.translate_model_zh_en = default_zh_en
                self._log(f" Translate zh_en default: {default_zh_en}")
            else:
                missing.append(f"Translate zh_en missing: {default_zh_en}")
            if os.path.isdir(default_en_zh):
                self.cfg.translate_model_en_zh = default_en_zh
                self._log(f" Translate en_zh default: {default_en_zh}")
            else:
                missing.append(f"Translate en_zh missing: {default_en_zh}")

        if missing:
            msg = (
                "Offline models missing; cannot run (release package should include models dir):\n\n"
                + "\n".join(f"- {x}" for x in missing)
                + "\n\nPlease check directory layout:\n"
                + f"{models_root}\\embedding\\...\n"
                + f"{models_root}\\sentiment\\<key>\\...\n"
            )
            self._log(msg)
            messagebox.showerror("Models missing", msg)
            raise RuntimeError(msg)

    def _on_close(self):
        """
        ä¼˜é›…é€€å‡ºï¼š
        1) æ ‡è®° closingï¼Œé˜»æ­¢æ–°çš„ after è°ƒåº¦
        2) cancel log pump çš„ after
        3) ç­‰åå°çº¿ç¨‹ç»“æŸï¼ˆdaemon=Falseï¼‰
        4) destroy Tk
        """
        import time

        # é˜²æ­¢é‡å¤è§¦å‘
        if getattr(self, "_closing", False):
            return

        self._closing = True
        print("ğŸ”´ æ­£åœ¨é€€å‡º...")

        # 1) åœæ­¢ log pumpï¼ˆéå¸¸å…³é”®ï¼‰
        try:
            if hasattr(self, "_log_pump_id") and self._log_pump_id is not None:
                self.after_cancel(self._log_pump_id)
                self._log_pump_id = None
        except Exception:
            pass

        # 2) å°è¯•æŠŠçŠ¶æ€æ¢å›ä¸€ä¸‹ï¼ˆé¿å…ææ„é˜¶æ®µ Tk å˜é‡è¿˜åœ¨å˜ï¼‰
        try:
            if hasattr(self, "status"):
                self.status.set("Closing...")
        except Exception:
            pass

        # 3) ç­‰å¾…åå°çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤šç­‰ 5 ç§’ï¼Œé¿å…å¡æ­»ï¼‰
        threads = getattr(self, "_threads", [])
        deadline = time.time() + 5.0  # æœ€å¤šç­‰ 5 ç§’
        for t in threads:
            if t is None:
                continue
            # åˆ†æ®µ joinï¼Œä¿è¯ UI è¿˜æ´»ç€
            while t.is_alive() and time.time() < deadline:
                try:
                    t.join(timeout=0.1)
                except Exception:
                    break

        # 4) é”€æ¯çª—å£
        try:
            self.master.destroy()
        except Exception:
            pass

        print("âœ… é€€å‡ºå®Œæˆ")

    def _busy(self, is_busy: bool, message: str = ""):
        """
        è®¾ç½®å¿™ç¢ŒçŠ¶æ€ï¼šç¦ç”¨ä¸»è¦æŒ‰é’® + æ›´æ–°çŠ¶æ€æ  + æ§åˆ¶è¿›åº¦æ¡
        åªä¿ç•™ä¸€å¥—é€»è¾‘ï¼Œé¿å…é‡å¤/é”™è¯¯çš„ getattr/hasattrã€‚
        """
        state = "disabled" if is_busy else "normal"

        # è¿™äº›æ˜¯ä½ åœ¨ _build_ui é‡Œåˆ›å»ºçš„æŒ‰é’®å±æ€§å
        button_names = [
            "btn_import",
            "btn_run_all",
            "btn_export",
            "btn_kplot",
            "btn_compare",
            "btn_priority",
            "btn_run_cluster",
            # å¦‚æœä½ è¿˜æœ‰å…¶å®ƒæŒ‰é’®ï¼Œæ¯”å¦‚æŠ¥å‘ŠæŒ‰é’®ï¼Œä¹Ÿå¯ä»¥åŠ ï¼š
            # "btn_report_offline",
        ]

        for name in button_names:
            if hasattr(self, name):
                btn = getattr(self, name)
                # ttk.Button / tk.Button éƒ½æ”¯æŒ config(state=...)
                try:
                    btn.config(state=state)
                except Exception:
                    pass

        # çŠ¶æ€æ 
        try:
            if hasattr(self, "status"):
                if is_busy:
                    self.status.set(message or "è¿è¡Œä¸­...")
                else:
                    self.status.set("å°±ç»ª")
        except Exception:
            pass

        # è¿›åº¦æ¡ï¼šä½ ç°åœ¨ progress é»˜è®¤æ˜¯ determinateï¼Œ
        # ä½†ä½ è¿™é‡Œç”¨ start/stop æ˜¯ indeterminate çš„æ–¹å¼ã€‚
        # ä¿é™©åšæ³•ï¼šåˆ‡æ¢ mode å¹¶ start/stopã€‚
        try:
            if hasattr(self, "progress"):
                if is_busy:
                    self.progress.config(mode="indeterminate")
                    self.progress.start(10)
                else:
                    self.progress.stop()
                    self.progress.config(mode="determinate")
                    self.progress["value"] = 0
        except Exception:
            pass

        try:
            self.update_idletasks()
        except Exception:
            pass

    def _normalize_col(self, s: str) -> str:
        """ç”¨äºåŒ¹é…åˆ—åï¼šå»ç©ºæ ¼/ä¸‹åˆ’çº¿/çŸ­æ¨ªçº¿/å¤§å°å†™ç»Ÿä¸€"""
        if s is None:
            return ""
        s = str(s).strip().lower()
        for ch in [" ", "\t", "\n", "\r", "_", "-", "â€”", "ï¼", "Â·", ".", "ï¼Œ", ",", "ï¼š", ":"]:
            s = s.replace(ch, "")
        return s

    def _auto_map_fields(self, df):
        """
        è‡ªåŠ¨è¯†åˆ«åˆ—åï¼Œå›å†™åˆ° self.cfg.field_map
        ç›®æ ‡å­—æ®µï¼š
        - textï¼ˆå¿…éœ€ï¼‰
        - asinï¼ˆå¯é€‰ï¼‰
        - starï¼ˆå¯é€‰ï¼‰
        - timeï¼ˆå¯é€‰ï¼‰
        """
        cols = list(df.columns)
        norm2orig = {self._normalize_col(c): c for c in cols}

        # å€™é€‰è¯åº“ï¼ˆä½ åé¢é‡åˆ°æ–°åˆ—åï¼Œå¾€è¿™é‡ŒåŠ å°±è¡Œï¼‰
        candidates = {
            "text": [
                "reviewtext", "review", "reviewcontent", "reviewbody", "content", "text", "body", "comment",
                "è¯„è®ºå†…å®¹", "è¯„è®ºæ­£æ–‡", "è¯„ä»·å†…å®¹", "è¯„ä»·æ­£æ–‡", "è¯„è®º", "è¯„ä»·", "å†…å®¹", "æ­£æ–‡"
            ],
            "asin": [
                "asin", "productasin", "parentasin", "sku", "spu", "å•†å“asin", "äº§å“asin", "å•†å“id", "äº§å“id"
            ],
            "star": [
                "star", "stars", "rating", "score", "rate", "è¯„åˆ†", "æ˜Ÿçº§", "æ˜Ÿ", "æ‰“åˆ†"
            ],
            "time": [
                "reviewtime", "time", "date", "datetime", "timestamp", "è¯„è®ºæ—¶é—´", "è¯„ä»·æ—¶é—´", "æ—¶é—´", "æ—¥æœŸ", "å‘è¡¨æ—¶é—´"
            ]
        }

        def find_col(key: str):
            # 1) å…ˆå°Šé‡ç”¨æˆ·/é…ç½®å†™æ­»çš„åˆ—åï¼ˆå­˜åœ¨å°±ç”¨ï¼‰
            cfg_name = (self.cfg.field_map.get(key) or "").strip()
            if cfg_name and cfg_name in cols:
                return cfg_name

            # 2) ç²¾ç¡®åŒ¹é…ï¼ˆnormalizeåç›¸ç­‰ï¼‰
            for cand in candidates[key]:
                n = self._normalize_col(cand)
                if n in norm2orig:
                    return norm2orig[n]

            # 3) æ¨¡ç³ŠåŒ…å«ï¼ˆnormalizeååŒ…å«ï¼‰
            for cand in candidates[key]:
                n = self._normalize_col(cand)
                for cn, orig in norm2orig.items():
                    if n and (n in cn or cn in n):
                        return orig

            return None

        mapped = {}
        for k in ["text", "asin", "star", "time"]:
            col = find_col(k)
            if col:
                mapped[k] = col

        # è‡³å°‘è¦æœ‰ text
        if "text" not in mapped:
            raise ValueError(
                "ç¼ºå°‘å¿…è¦åˆ—ï¼šè¯„è®ºæ­£æ–‡åˆ—ï¼ˆtextï¼‰ã€‚\n"
                f"å½“å‰åˆ—ï¼š{cols}\n"
                "è¯·æŠŠè¯„è®ºæ­£æ–‡åˆ—å‘½åä¸ºï¼šReviewText/è¯„è®ºå†…å®¹/è¯„è®ºæ­£æ–‡/è¯„ä»·å†…å®¹ ç­‰ï¼Œæˆ–åœ¨ settings.json é‡Œé…ç½® field_mapã€‚"
            )

        # å›å†™é…ç½®ï¼ˆè®©åç»­å…¨æµç¨‹éƒ½ç”¨è¯†åˆ«ç»“æœï¼‰
        self.cfg.field_map.update(mapped)

        # æ—¥å¿—æç¤ºï¼ˆä¸­è‹±ï¼‰
        self._log("âœ… Auto field mapping / è‡ªåŠ¨åˆ—åè¯†åˆ«ï¼š")
        self._log(f"   text -> {self.cfg.field_map.get('text')}")
        self._log(f"   asin -> {self.cfg.field_map.get('asin')}")
        self._log(f"   star -> {self.cfg.field_map.get('star')}")
        self._log(f"   time -> {self.cfg.field_map.get('time')}")

        # è‡ªåŠ¨é™çº§æç¤º
        if not self.cfg.field_map.get("asin"):
            self._log("â„¹ï¸ æœªè¯†åˆ«åˆ° ASIN åˆ—ï¼šè·¨ASINå¯¹æ¯”/çƒ­åŠ›å›¾åŠŸèƒ½å°†ä¸å¯ç”¨æˆ–è‡ªåŠ¨è·³è¿‡ã€‚")
        if not self.cfg.field_map.get("star"):
            self._log("â„¹ï¸ æœªè¯†åˆ«åˆ° Star/è¯„åˆ† åˆ—ï¼šæƒ…æ„Ÿæ¨¡å‹å¤±æ•ˆæ—¶çš„â€œæ˜Ÿçº§å…œåº•è´Ÿé¢è¿‡æ»¤â€å°†ä¸å¯ç”¨ã€‚")

    @staticmethod
    def apply_negative_filter(
        df: pd.DataFrame,
        star_col: str,
        sentiment_col: str | None,
        sentiment_conf_col: str | None,
        mode: str,
        star_threshold: float,
        conf_threshold: float,
        # ===== æ–°å¢ï¼šfusion å‚æ•° =====
        w_star: float = 1.0,
        w_sent: float = 1.0,
        fusion_keep_threshold: float = 1.0,
    ) -> pd.DataFrame:
        """
        ç»Ÿä¸€è´Ÿé¢è¿‡æ»¤é€»è¾‘ï¼ˆç§‘ç ” + äº§å“å®‰å…¨ï¼‰
        mode:
        - STAR_ONLY
        - SENTIMENT_ONLY
        - FUSION   (âœ… å‡çº§ä¸º WEIGHTED_FUSIONï¼šçœŸæ­£æ‹‰å¼€å·®å¼‚)
        """

        work = df.copy()

        # ---------- æ˜Ÿçº§æ¡ä»¶ ----------
        if star_col in work.columns:
            work[star_col] = pd.to_numeric(work[star_col], errors="coerce")
            star_neg = work[star_col] <= float(star_threshold)
        else:
            star_neg = pd.Series(False, index=work.index)

        # ---------- æƒ…æ„Ÿæ¡ä»¶ï¼ˆå¸¦ç½®ä¿¡åº¦ï¼‰ ----------
        if sentiment_col and sentiment_col in work.columns:
            sent_neg = (work[sentiment_col] == "negative")

            # é»˜è®¤ conf=0ï¼Œé¿å…ç¼ºåˆ—å¯¼è‡´å´©
            if sentiment_conf_col and sentiment_conf_col in work.columns:
                conf = pd.to_numeric(work[sentiment_conf_col], errors="coerce").fillna(0.0)
            else:
                conf = pd.Series(0.0, index=work.index)

            # conf_okï¼šå¿…é¡» >= é˜ˆå€¼æ‰ç®—â€œæœ‰æ•ˆè´Ÿé¢â€
            conf_ok = conf >= float(conf_threshold)
            sent_neg = sent_neg & conf_ok

            # sentiment å¼ºåº¦ï¼šæŠŠ conf æ˜ å°„åˆ° [0,1]ï¼ˆé˜ˆå€¼ä»¥ä¸Šæ‰æœ‰å¼ºåº¦ï¼‰
            # ä¾‹ï¼šconf_th=0.6ï¼Œconf=0.6 -> 0ï¼›conf=1.0 -> 1
            denom = max(1e-6, (1.0 - float(conf_threshold)))
            sent_strength = ((conf - float(conf_threshold)) / denom).clip(lower=0.0, upper=1.0)
            sent_strength = sent_strength * sent_neg.astype(float)
        else:
            sent_neg = pd.Series(False, index=work.index)
            sent_strength = pd.Series(0.0, index=work.index)

        # ---------- ç­–ç•¥é€‰æ‹© ----------
        mode = (mode or "STAR_ONLY").strip()

        if mode == "STAR_ONLY":
            mask = star_neg

        elif mode == "SENTIMENT_ONLY":
            mask = sent_neg

        elif mode == "FUSION":
            # âœ… WEIGHTED_FUSIONï¼šçœŸæ­£èƒ½æ‹‰å¼€å·®å¼‚
            # æ˜Ÿçº§ä¿¡å·ï¼šè´Ÿé¢=1ï¼Œéè´Ÿé¢=0
            star_signal = star_neg.astype(float)

            # æƒ…æ„Ÿä¿¡å·ï¼šsent_strength in [0,1]ï¼Œè¶Šæ¥è¿‘1è¶Šâ€œå¼ºè´Ÿé¢â€
            # èåˆå¾—åˆ†
            neg_score = float(w_star) * star_signal + float(w_sent) * sent_strength

            # ä¿ç•™é˜ˆå€¼ï¼šè¶Šé«˜è¶Šä¸¥æ ¼
            mask = neg_score >= float(fusion_keep_threshold)

            # å¯é€‰ï¼šæŠŠ score ç•™ä¸‹æ¥ï¼ˆåç»­ä½ åšåˆ†æ/è®ºæ–‡æ¶ˆèå¾ˆå¥½ç”¨ï¼‰
            work["_neg_score"] = neg_score

        else:
            # é˜²å¾¡ï¼šæœªçŸ¥æ¨¡å¼ï¼Œé€€åŒ–ä¸º STAR_ONLY
            mask = star_neg

        return work[mask].reset_index(drop=True)
