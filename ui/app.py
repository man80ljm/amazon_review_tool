# ui/app.py
import sys
import os
from huggingface_hub import snapshot_download
import queue
import traceback

from pathlib import Path
from config import load_user_settings, save_user_settings

import os
import threading
import tkinter as tk
from tkinter import ttk, filedialog, messagebox

import pandas as pd
import numpy as np

from config import AppConfig
from core.io_utils import load_file, save_csv, save_excel, ensure_dir
from core.sentiment import SentimentAnalyzer
from core.embedding import Embedder
from core.clustering import scan_k, fit_kmeans
from core.keywords import top_keywords_by_cluster
from core.representatives import top_representatives
from core.robustness import clustering_stability

from core.plot_k import recommend_k, plot_k_curves
from core.insights import asin_cluster_percent, plot_heatmap, cluster_priority, plot_priority,cluster_priority_safe

from core.report_word import build_offline_report


class App(ttk.Frame):
    def __init__(self, master, cfg: AppConfig):
        super().__init__(master)
        self.master = master
        self.cfg = cfg

        # âœ…ã€åŠ åœ¨è¿™é‡Œã€‘è®¾ç½®çª—å£é»˜è®¤å¤§å°
        self.master.geometry("1660x900")   # ä½ å¯ä»¥æ”¹è¿™ä¸ªæ•°
        self.master.minsize(1250, 700)      # å¯é€‰ï¼šé˜²æ­¢ç¼©å¤ªå°
        
        # åŠ è½½æœ¬åœ° settings.json
        settings = load_user_settings()
        self.cfg.apply_user_settings(settings)

        #æ‰“åŒ…ååŠ è½½æ¨¡å‹è·¯å¾„ä¿®æ­£
        from config import resolve_path
        self._resolve_path = resolve_path

        self.cfg.sentiment_model = resolve_path(getattr(self.cfg, "sentiment_model", "models/sentiment"))
        self.cfg.embedding_model = resolve_path(getattr(self.cfg, "embedding_model", "models/embedding"))
        self.sentiment_model_label_to_key = {}
        self.sentiment_model_key_to_label = {}

        
        # è®¾ç½®æ¸…åé•œåƒ
        os.environ['HF_ENDPOINT'] = 'https://mirrors.tuna.tsinghua.edu.cn/huggingface-hub'
        os.environ['HF_HUB_OFFLINE'] = '0'

        self.df = None
        self.df_work = None
        self.emb = None
        self.labels = None
        self.centers = None
        self.k_scan = None
        self.cluster_keywords = None
        self.cluster_reps = None
        self.output_dir = os.path.join(os.getcwd(), "outputs")
        ensure_dir(self.output_dir)

        self._build_ui()
        self.log_queue = queue.Queue()
        self._start_log_pump()
        self._log("App started. Ready.")
        self._job_lock = threading.Lock()
        self._running = False

        # ====== graceful shutdown support ======
        self._threads = []         # ç”¨æ¥ä¿å­˜åå°çº¿ç¨‹ï¼ˆdaemon=Falseï¼‰
        self._closing = False      # é€€å‡ºæ ‡è®°
        self._log_pump_id = None   # after å¥æŸ„ï¼ˆç”¨äº cancelï¼‰
        
        # ğŸ”¥ å…³é”®ï¼šç»‘å®šçª—å£å…³é—­äº‹ä»¶
        self.master.protocol("WM_DELETE_WINDOW", self._on_close)

    def _build_ui(self):
        self.master.title("Review Analyzer")
        self.pack(fill="both", expand=True)

        top = ttk.Frame(self)
        top.pack(fill="x", padx=10, pady=8)

        # ä¸¤è¡Œå·¥å…·æ 
        row1 = ttk.Frame(top)
        row1.pack(fill="x")
        row2 = ttk.Frame(top)
        row2.pack(fill="x", pady=(6, 0))

        # ===== Row1ï¼šä¸»æµç¨‹ =====
        self.btn_import = ttk.Button(row1, text="å¯¼å…¥æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰", command=self.on_load_csv)
        self.btn_import.pack(side="left")

        self.btn_run_all = ttk.Button(row1, text="è¿è¡Œ Step1-5ï¼ˆå…¨æµç¨‹ï¼‰", command=self.on_run_all)
        self.btn_run_all.pack(side="left", padx=8)

        self.btn_export = ttk.Button(row1, text="å¯¼å‡ºç»“æœ", command=self.on_export)
        self.btn_export.pack(side="left")

        self.btn_kplot = ttk.Button(row1, text="å¯¼å‡º/æ˜¾ç¤ºKé€‰æ‹©å›¾", command=self.on_plot_k)
        self.btn_kplot.pack(side="left", padx=8)

        self.btn_compare = ttk.Button(row1, text="è·¨ASINå¯¹æ¯”", command=self.on_asin_compare)
        self.btn_compare.pack(side="left", padx=8)

        self.btn_priority = ttk.Button(row1, text="ä¼˜å…ˆçº§æ’åº", command=self.on_priority)
        self.btn_priority.pack(side="left", padx=8)

        # å³ä¾§çŠ¶æ€
        self.status = tk.StringVar(value="Ready")
        ttk.Label(row1, textvariable=self.status).pack(side="right")

        # ===== Row2ï¼šè¯­è¨€ + ç¦»çº¿æŠ¥å‘Šï¼ˆå·²å»æ‰ LLM ç›¸å…³ï¼‰ =====
        ttk.Label(row2, text="æ–‡æœ¬è¯­è¨€:").pack(side="left")

        self.lang_var = tk.StringVar(value=getattr(self.cfg, "text_language", "en"))
        self.lang_box = ttk.Combobox(
            row2,
            textvariable=self.lang_var,
            values=["en", "zh_cn"],
            width=8,
            state="readonly"
        )
        self.lang_box.pack(side="left", padx=(6, 12))
        self.lang_box.bind("<<ComboboxSelected>>", self.on_language_changed)

        # æƒ…æ„Ÿæ¨¡å‹é€‰æ‹©
        ttk.Label(row2, text="æƒ…æ„Ÿæ¨¡å‹:").pack(side="left")
        self.sentiment_model_var = tk.StringVar(value="")
        self.sentiment_model_box = ttk.Combobox(
            row2,
            textvariable=self.sentiment_model_var,
            values=[],
            width=20,
            state="readonly"
        )
        self.sentiment_model_box.pack(side="left", padx=(6, 12))
        self.sentiment_model_box.bind("<<ComboboxSelected>>", self.on_sentiment_model_changed)

        current_key = self._derive_sentiment_key_from_cfg()
        self._refresh_sentiment_model_options(self.cfg.text_language, select_key=current_key, save=False)

        # ç¦»çº¿æŠ¥å‘ŠæŒ‰é’®
        self.btn_report_offline = ttk.Button(row2, text="ç”ŸæˆWordæŠ¥å‘Šï¼ˆç¦»çº¿ï¼‰", command=self.on_report_offline)
        self.btn_report_offline.pack(side="left", padx=(0, 8))

        # å ä½ï¼šè®©å¸ƒå±€æ›´ç¾è§‚
        ttk.Label(row2, text=" ").pack(side="left", expand=True)

        # è¿›åº¦æ¡
        self.progress = ttk.Progressbar(self, mode="determinate")
        self.progress.pack(fill="x", padx=10, pady=6)

        nb = ttk.Notebook(self)
        nb.pack(fill="both", expand=True, padx=10, pady=10)

        self.tab_data = ttk.Frame(nb)
        self.tab_k = ttk.Frame(nb)
        self.tab_results = ttk.Frame(nb)
        self.tab_log = ttk.Frame(nb)

        nb.add(self.tab_data, text="æ•°æ®é¢„è§ˆ")
        nb.add(self.tab_k, text="é€‰Kç»“æœ")
        nb.add(self.tab_results, text="èšç±»ç»“æœ")
        nb.add(self.tab_log, text="è¿è¡Œæ—¥å¿—")

        # Data preview
        self.data_text = tk.Text(self.tab_data, height=18, wrap="none")
        self.data_text.pack(fill="both", expand=True)

        # K scan
        self.k_text = tk.Text(self.tab_k, height=18, wrap="none")
        self.k_text.pack(fill="both", expand=True)

        # Results
        self.res_text = tk.Text(self.tab_results, height=18, wrap="none")
        self.res_text.pack(fill="both", expand=True)

        # Log
        self.log_text = tk.Text(self.tab_log, height=18, wrap="word")
        self.log_text.pack(fill="both", expand=True)

        # Bottom controls
        bottom = ttk.Frame(self)
        bottom.pack(fill="x", padx=10, pady=6)

        # ====== é˜ˆå€¼å˜é‡ï¼ˆä» cfg è¯»ï¼Œç¡®ä¿ UI æ‰“å¼€å°±æ˜¾ç¤ºå½“å‰å€¼ï¼‰======
        self.star_th_var = tk.DoubleVar(value=float(getattr(self.cfg, "star_negative_threshold", 4.0)))
        self.conf_th_var = tk.DoubleVar(value=float(getattr(self.cfg, "sentiment_conf_threshold", 0.6)))

        # ====== FUSION æƒé‡/é˜ˆå€¼ ======
        self.fusion_w_star_var = tk.DoubleVar(value=float(getattr(self.cfg, "fusion_w_star", 1.0)))
        self.fusion_w_sent_var = tk.DoubleVar(value=float(getattr(self.cfg, "fusion_w_sent", 1.0)))
        self.fusion_keep_var = tk.DoubleVar(value=float(getattr(self.cfg, "fusion_keep_threshold", 1.0)))

        self.auto_apply_k = tk.BooleanVar(value=True)
        ttk.Checkbutton(bottom, text="æ‰«æåè‡ªåŠ¨åº”ç”¨æ¨èK", variable=self.auto_apply_k).pack(side="left", padx=10)

        ttk.Label(bottom, text="èšç±»K:").pack(side="left")
        self.k_var = tk.IntVar(value=5)
        ttk.Spinbox(
            bottom,
            from_=self.cfg.k_min,
            to=self.cfg.k_max,
            textvariable=self.k_var,
            width=5
        ).pack(side="left", padx=6)

        # ä»…åˆ†æè´Ÿé¢
        self.only_negative = tk.BooleanVar(value=True)
        self.cb_only_negative = ttk.Checkbutton(
            bottom,
            text="ä»…åˆ†æè´Ÿé¢",
            variable=self.only_negative
        )
        self.cb_only_negative.pack(side="left", padx=10)

        # ===== è´Ÿé¢ç­›é€‰ç­–ç•¥ï¼ˆSTAR / FUSION / SENTIMENTï¼‰=====
        ttk.Label(bottom, text="è´Ÿé¢åˆ¤å®š:").pack(side="left", padx=(10, 4))

        self.negative_mode_var = tk.StringVar(
            value=getattr(self.cfg, "negative_mode", "STAR_ONLY")
        )

        self.negative_mode_box = ttk.Combobox(
            bottom,
            textvariable=self.negative_mode_var,
            values=["STAR_ONLY", "FUSION", "SENTIMENT_ONLY"],
            width=14,
            state="readonly"
        )
        self.negative_mode_box.pack(side="left")
        self.negative_mode_box.bind("<<ComboboxSelected>>", self.on_negative_mode_changed)

        # =========================================================
        # ğŸ”¥ æ–°å¢ï¼šå‚æ•°å¾®è°ƒæ§ä»¶ (Star / Conf / Fusion Weights)
        # =========================================================
        
        # 1. Star é˜ˆå€¼
        ttk.Label(bottom, text="Star<=").pack(side="left", padx=(10, 2))
        self.star_th_spin = ttk.Spinbox(
            bottom, from_=1.0, to=5.0, increment=0.5,
            textvariable=self.star_th_var, width=4
        )
        self.star_th_spin.pack(side="left")

        # 2. Conf é˜ˆå€¼
        ttk.Label(bottom, text="Conf>=").pack(side="left", padx=(8, 2))
        self.conf_th_spin = ttk.Spinbox(
            bottom, from_=0.0, to=1.0, increment=0.05,
            textvariable=self.conf_th_var, width=4
        )
        self.conf_th_spin.pack(side="left")

        # 3. Fusion å‚æ•° (W_Star, W_Sent, Keep)
        ttk.Label(bottom, text="wStar").pack(side="left", padx=(8, 2))
        self.fusion_w_star_spin = ttk.Spinbox(
            bottom, from_=0.0, to=5.0, increment=0.1,
            textvariable=self.fusion_w_star_var, width=4
        )
        self.fusion_w_star_spin.pack(side="left")

        ttk.Label(bottom, text="wSent").pack(side="left", padx=(5, 2))
        self.fusion_w_sent_spin = ttk.Spinbox(
            bottom, from_=0.0, to=5.0, increment=0.1,
            textvariable=self.fusion_w_sent_var, width=4
        )
        self.fusion_w_sent_spin.pack(side="left")

        ttk.Label(bottom, text="Keep>=").pack(side="left", padx=(5, 2))
        self.fusion_keep_spin = ttk.Spinbox(
            bottom, from_=0.0, to=5.0, increment=0.1,
            textvariable=self.fusion_keep_var, width=4
        )
        self.fusion_keep_spin.pack(side="left")

        # =========================================================

        self.btn_run_cluster = ttk.Button(
            bottom,
            text="ä»…é‡è·‘ Step4-5",
            command=self.on_run_cluster_only
        )
        self.btn_run_cluster.pack(side="right", padx=(10, 0))

        # ğŸ”¥ ç»‘å®šè‡ªåŠ¨ä¿å­˜äº‹ä»¶ (å›è½¦ OR å¤±å»ç„¦ç‚¹)
        def _bind_save(widget, func):
            widget.bind("<Return>", func)
            widget.bind("<FocusOut>", func)

        _bind_save(self.star_th_spin, self.on_thresholds_changed)
        _bind_save(self.conf_th_spin, self.on_thresholds_changed)
        _bind_save(self.fusion_w_star_spin, self.on_thresholds_changed)
        _bind_save(self.fusion_w_sent_spin, self.on_thresholds_changed)
        _bind_save(self.fusion_keep_spin, self.on_thresholds_changed)

    def _set_progress(self, cur, total, msg):
        """çº¿ç¨‹å®‰å…¨è¿›åº¦æ›´æ–°ï¼šåå°çº¿ç¨‹è°ƒç”¨ä¹Ÿä¸ä¼šç¢° Tkã€‚"""
        def _apply():
            try:
                self.status.set(msg)
                self.progress["maximum"] = max(int(total), 1)
                self.progress["value"] = int(cur)
                self.master.update_idletasks()
            except Exception:
                pass

        self._ui(_apply)          # UI æ›´æ–°å›ä¸»çº¿ç¨‹
        self._log(f"[{cur}/{total}] {msg}")  # æ—¥å¿—ç”¨é˜Ÿåˆ—ï¼Œçº¿ç¨‹å®‰å…¨

    def _start_log_pump(self):
        """
        å°† log_queue çš„å†…å®¹åˆ·åˆ° Text æ§ä»¶ã€‚
        å…³é”®ï¼šä¿å­˜ after idï¼Œé€€å‡ºæ—¶ after_cancelï¼Œé¿å… mainloop ç»“æŸåä»ç„¶å›è°ƒå¯¼è‡´å´©æºƒã€‚
        """
        import queue

        def pump():
            # å¦‚æœæ­£åœ¨å…³é—­ï¼Œå°±ä¸å†è°ƒåº¦
            if getattr(self, "_closing", False):
                return

            try:
                while True:
                    msg = self.log_queue.get_nowait()
                    if hasattr(self, "log_text") and self.log_text is not None:
                        try:
                            self.log_text.insert("end", msg + "\n")
                            self.log_text.see("end")
                        except Exception:
                            pass  # çª—å£å·²é”€æ¯
            except queue.Empty:
                pass

            # ä¿å­˜å¥æŸ„ï¼Œé€€å‡ºæ—¶å¯å–æ¶ˆ
            if not getattr(self, "_closing", False):
                try:
                    self._log_pump_id = self.after(120, pump)
                except Exception:
                    pass  # çª—å£å·²é”€æ¯

        pump()

    def _log(self, msg: str):
        """çº¿ç¨‹å®‰å…¨æ—¥å¿—ï¼šåå°çº¿ç¨‹ä¹Ÿå¯ä»¥è°ƒç”¨ã€‚"""
        try:
            self.log_queue.put(str(msg))
        except Exception:
            pass  # é˜Ÿåˆ—å·²å…³é—­/é”€æ¯

    def _log_exception(self, e: Exception):
        """æŠŠå¼‚å¸¸å †æ ˆå†™è¿›æ—¥å¿—ï¼Œæ–¹ä¾¿å®šä½ã€‚"""
        self._log("âŒ ERROR: " + str(e))
        self._log(traceback.format_exc())

    def _ui(self, fn, *args, **kwargs):
        """ä¿è¯ UI æ“ä½œåœ¨ä¸»çº¿ç¨‹æ‰§è¡Œ"""
        try:
            self.master.after(0, lambda: fn(*args, **kwargs))
        except Exception:
            pass

    def _set_running(self, is_running: bool):
        """ç»Ÿä¸€ç®¡ç†è¿è¡ŒçŠ¶æ€ + æŒ‰é’®å¯ç”¨æ€§ï¼ˆé˜²è¿ç‚¹ï¼‰"""
        self._running = is_running
        state = "disabled" if is_running else "normal"
        try:
            # è¿™äº›æŒ‰é’®åå­—æŒ‰ä½ çš„å®é™…å˜é‡åæ”¹ä¸€ä¸‹ï¼ˆä¸‹é¢æˆ‘ä¹Ÿç»™ä½ æœ€é€šç”¨å†™æ³•ï¼‰
            self.btn_run_all.config(state=state)
            self.btn_run_cluster.config(state=state)
            self.btn_export.config(state=state)
            self.btn_kplot.config(state=state)
            self.btn_compare.config(state=state)
            self.btn_priority.config(state=state)
            self.btn_import.config(state=state)
        except Exception:
            # å¦‚æœä½ æ²¡ä¿å­˜æŒ‰é’®å¼•ç”¨ï¼Œä¹Ÿæ²¡å…³ç³»ï¼šè‡³å°‘é˜²æ­¢çº¿ç¨‹é‡å…¥
            pass

    def on_load_csv(self):
        path = filedialog.askopenfilename(
            filetypes=[("CSV / Excel Files", "*.csv *.xlsx")]
        )

        if not path:
            return

        try:
            # ========= 1) å…ˆå®Œæ•´åŠ è½½æ–‡ä»¶ï¼ˆä¸åšä»»ä½•åˆ—åå‡è®¾ï¼‰ =========
            self.df = load_file(path, required_cols=None)

            # æ¸…ç©ºä¸­é—´çŠ¶æ€
            self.df_work = None
            self.emb = None
            self.labels = None
            self.centers = None
            self.k_scan = None
            self.cluster_keywords = None
            self.cluster_reps = None

            # ========= 2) è‡ªåŠ¨è¯†åˆ«åˆ—åï¼ˆå…³é”®æ–°å¢ï¼‰ =========
            self._auto_map_fields(self.df)

            fm = self.cfg.field_map  # è¯†åˆ«åçš„æ˜ å°„ç»“æœ

            # ========= 3) ç»Ÿä¸€å†…éƒ¨å­—æ®µï¼ˆåç»­æµç¨‹åªç”¨ _xxxï¼‰ =========
            self.df["_text"] = self.df[fm["text"]]

            # star / scoreï¼ˆå¯é€‰ï¼‰
            star_col = fm.get("star")
            if star_col and star_col in self.df.columns:
                self.df["_score"] = self.df[star_col]
            else:
                self.df["_score"] = None

            # asin / groupï¼ˆå¯é€‰ï¼‰
            asin_col = fm.get("asin")
            if asin_col and asin_col in self.df.columns:
                self.df["_group"] = self.df[asin_col]
            else:
                self.df["_group"] = None

            # idï¼ˆå¯é€‰ï¼‰
            id_col = fm.get("id")
            if id_col and id_col in self.df.columns:
                self.df["_id"] = self.df[id_col]
            else:
                self.df["_id"] = self.df.index.astype(str)

            # ========= 4) é¢„è§ˆ & æ—¥å¿— =========
            self.data_text.delete("1.0", "end")
            self.data_text.insert("end", f"Loaded: {path}\n")
            self.data_text.insert("end", f"Rows: {len(self.df)}\n\n")

            self._log(f"Loaded file: {path}")
            self._log(f"Total rows: {len(self.df)}")

            empty_text = self.df["_text"].astype(str).str.strip().eq("").sum()
            self._log(f"Empty text rows: {empty_text}")

            self.data_text.insert("end", self.df.head(20).to_string(index=False))

            self.status.set("Data loaded & auto-mapped")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", str(e))

    def _run_in_thread(self, fn, start_msg="Task started..."):
        """
        ç»Ÿä¸€çº¿ç¨‹å®‰å…¨æ‰§è¡Œå™¨
        ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿çº¿ç¨‹æ­£ç¡®æ¸…ç†
        """
        import threading

        # æ­£åœ¨å…³é—­å°±åˆ«å†å¯åŠ¨ä»»åŠ¡äº†
        if getattr(self, "_closing", False):
            return

        # é˜²è¿ç‚¹ï¼ˆä¸»çº¿ç¨‹ï¼‰
        if getattr(self, "_running", False):
            self._log("âš ï¸ æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆåå†æ“ä½œã€‚")
            return

        def ui(callable_):
            # å¦‚æœæ­£åœ¨å…³é—­ï¼Œä¸å†è§¦å‘ UI æ›´æ–°
            if getattr(self, "_closing", False):
                return
            try:
                self.master.after(0, callable_)
            except Exception:
                pass  # çª—å£å·²é”€æ¯ï¼Œå¿½ç•¥

        def runner():
            try:
                ui(lambda: self._set_running(True))
                ui(lambda: self.status.set("Running"))
                ui(lambda: self._log(f"â–¶ {start_msg}"))

                fn()  # åå°æ‰§è¡Œï¼šåªåšè®¡ç®—/IO/APIï¼ˆä¸è¦ç›´æ¥ç¢° Tkï¼‰

                ui(lambda: self.status.set("Done"))
                ui(lambda: self._log("âœ… Task finished."))

            except Exception as e:
                ui(lambda: self.status.set("Error"))
                ui(lambda: self._log_exception(e))
                ui(lambda: messagebox.showerror("é”™è¯¯", str(e)))
            finally:
                ui(lambda: self._set_running(False))

        t = threading.Thread(target=runner, daemon=False)  # daemon=False å¯ä»¥ join
        # ğŸ”¥ è®°å½•çº¿ç¨‹ï¼Œé€€å‡ºæ—¶ join
        if not hasattr(self, "_threads"):
            self._threads = []
        self._threads.append(t)
        t.start()
        
    def on_run_all(self):
        """
        å…¨æµç¨‹ï¼šStep1â€“5ï¼ˆä»…è®¡ç®—ï¼Œä¸å¯¼å‡ºã€ä¸å‡ºå›¾ã€ä¸ç”ŸæˆæŠ¥å‘Šï¼‰
        å…³é”®ä¿®å¤ï¼š
        - åœ¨ä¸»çº¿ç¨‹ä¸€æ¬¡æ€§è¯»å– Tk å˜é‡ï¼ˆonly_negative/auto_apply_k/k_varï¼‰
        - åå°çº¿ç¨‹ job() / _pipeline_all() å†…ç¦æ­¢å† .get() / .set()
        - è‡ªåŠ¨åº”ç”¨æ¨èKï¼šç”¨ _ui å›ä¸»çº¿ç¨‹ set
        - è¡¥é½ self.cluster_reps ç­‰çŠ¶æ€å˜é‡ï¼Œä¿è¯å¯¼å‡º/æŠ¥å‘Šå¯ç”¨
        """
        if self.df is None or len(self.df) == 0:
            messagebox.showwarning("æç¤º", "è¯·å…ˆå¯¼å…¥æ•°æ®æ–‡ä»¶")
            return

        # âœ… ä¸»çº¿ç¨‹ä¸€æ¬¡æ€§è¯»å– Tk å˜é‡ï¼ˆéå¸¸å…³é”®ï¼šåå°çº¿ç¨‹ç¦æ­¢å† get/setï¼‰
        try:
            only_negative_flag = bool(self.only_negative.get())
        except Exception:
            only_negative_flag = False

        try:
            auto_apply_flag = bool(self.auto_apply_k.get())
        except Exception:
            auto_apply_flag = False

        try:
            k_used_ui = int(self.k_var.get())
        except Exception:
            k_used_ui = None

        self.artifacts_dirty = True

        # UIï¼šå¿™ç¢Œæç¤ºæ”¾ä¸»çº¿ç¨‹
        try:
            self._busy(True, "å…¨æµç¨‹åˆ†æä¸­...")
        except Exception:
            pass

        def job():
            try:
                self._pipeline_all(
                    only_negative_flag=only_negative_flag,
                    auto_apply_flag=auto_apply_flag,
                    k_used_ui=k_used_ui
                )

                # UI ç»“æŸï¼ˆå¿…é¡»ä¸»çº¿ç¨‹ï¼‰
                def done():
                    try:
                        self._busy(False, "åˆ†æå®Œæˆ")
                    except Exception:
                        pass
                    messagebox.showinfo(
                        "å®Œæˆ",
                        "Step1â€“5 å·²å®Œæˆã€‚\n\n"
                        "è¯·æŒ‰éœ€ç‚¹å‡»ï¼š\n"
                        "â€¢ å¯¼å‡ºç»“æœ\n"
                        "â€¢ å¯¼å‡º K é€‰æ‹©å›¾\n"
                        "â€¢ è·¨ ASIN å¯¹æ¯”\n"
                        "â€¢ ä¼˜å…ˆçº§æ’åº\n"
                        "â€¢ ç”Ÿæˆ Word æŠ¥å‘Š"
                    )
                    self._log("Step1â€“5 completed. Waiting for user actions.")

                self._ui(done)

            except Exception as e:
                # å¤±è´¥ä¹Ÿè¦è§£é™¤ busyï¼ˆä¸»çº¿ç¨‹ï¼‰
                self._ui(lambda: self._busy(False, "å°±ç»ª"))
                raise

        self._run_in_thread(job, "Running Step1-5 (full pipeline)...")

    def on_run_cluster_only(self):
        """
        ä»…é‡è·‘ Step4â€“5ï¼ˆèšç±» + å…³é”®è¯/ä»£è¡¨è¯„è®ºï¼‰
        ä¿®å¤ç‚¹ï¼š
        1) å…¨éƒ¨èµ° _run_in_thread
        2) è¡¥é½ self.cluster_repsï¼Œå¦åˆ™æŠ¥å‘ŠæŒ‰é’®ä¼šè¯¯åˆ¤
        3) é‡è·‘åæ ‡è®° artifacts_dirty=Falseï¼ˆæ•°æ®å·²é½å…¨ï¼‰
        """
        if self.df_work is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆè¿è¡Œ Step1â€“5")
            return
        if self.emb is None:
            messagebox.showwarning("æç¤º", "Embedding ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ Step1â€“5")
            return

        # UIï¼šå¿™ç¢Œæç¤ºæ”¾ä¸»çº¿ç¨‹
        try:
            self._busy(True, "é‡æ–°èšç±»ä¸­ (Step4â€“5)...")
        except Exception:
            pass

        # é‡è·‘æ„å‘³ç€æ—§äº§ç‰©ä½œåºŸ
        self.artifacts_dirty = True

        def job():
            self.k_used = int(self.k_var.get())
            self._log(f"Re-run clustering with K={self.k_used}")

            # Step4
            self.labels, self.centers = fit_kmeans(
                self.emb,
                k=self.k_used,
                random_state=self.cfg.random_state
            )
            self.df_work["cluster_id"] = self.labels

            # Step5: keywords
            self.cluster_keywords = top_keywords_by_cluster(
                self.df_work[self.cfg.field_map["text"]].tolist(),
                self.labels,
                top_n=self.cfg.top_keywords,
                language=self.cfg.text_language
            )

            # Step5: reps
            reps_dict = top_representatives(
                self.emb,
                self.labels,
                self.centers,
                top_n=self.cfg.top_representatives
            )

            # â˜…å…³é”®ï¼šæŠ¥å‘Š/å¯¼å‡ºä¾èµ–è¿™ä¸ª
            self.cluster_reps = reps_dict

            rows = []
            for cid, idx_list in reps_dict.items():
                for rank, idx in enumerate(idx_list, 1):
                    row = self.df_work.iloc[idx].to_dict()
                    row["cluster_id"] = cid
                    row["rank_in_cluster"] = rank
                    rows.append(row)
            self.reps_df = pd.DataFrame(rows)

            # summary
            cluster_sizes = pd.Series(self.labels).value_counts().sort_index()
            self.cluster_summary = pd.DataFrame({
                "cluster_id": cluster_sizes.index,
                "cluster_size": cluster_sizes.values,
                "ratio": cluster_sizes.values / len(self.labels),
                "keywords": [", ".join(self.cluster_keywords.get(c, [])) for c in cluster_sizes.index]
            }).sort_values("ratio", ascending=False)

            # æ ‡è®°ï¼šå½“å‰äº§ç‰©å·²å‡†å¤‡å¥½
            self.artifacts_dirty = False

            def done():
                try:
                    self._busy(False, "èšç±»å®Œæˆ")
                except Exception:
                    pass
                messagebox.showinfo(
                    "å®Œæˆ",
                    f"å·²ä½¿ç”¨ K={self.k_used} é‡æ–°å®Œæˆèšç±»ã€‚\n\n"
                    "è¯·æŒ‰éœ€ç‚¹å‡»ï¼š\n"
                    "â€¢ å¯¼å‡ºç»“æœ\n"
                    "â€¢ è·¨ ASIN å¯¹æ¯”\n"
                    "â€¢ ä¼˜å…ˆçº§æ’åº\n"
                    "â€¢ ç”Ÿæˆ Word æŠ¥å‘Š"
                )

            self._ui(done)

        self._run_in_thread(job, "Re-running Step4-5 (cluster only)...")

    def _pipeline_all(self, only_negative_flag: bool, auto_apply_flag: bool, k_used_ui: int | None):
        """
        åå°çº¿ç¨‹è¿è¡Œçš„å…¨æµç¨‹é€»è¾‘ï¼ˆStep1-5ï¼‰
        """

        # ç»Ÿä¸€æ‹·è´ä¸€ä»½ï¼Œç”¨äºæœ€ç»ˆå¯¼å‡º"å¸¦æƒ…æ„Ÿæ ‡ç­¾"çš„å…¨é‡æ•°æ®
        df2 = self.df.copy()

        # ---------- Step1: sentimentï¼ˆé»˜è®¤å¯ç”¨ï¼›å¤±è´¥è‡ªåŠ¨é™çº§ï¼‰ ----------
        sent_model = getattr(self.cfg, "sentiment_model", None)

        # å…ˆç»™ sentiment åˆ—ä¸€ä¸ªé»˜è®¤å€¼ï¼Œä¿è¯åç»­é€»è¾‘ç¨³
        df2["sentiment"] = np.nan

        if sent_model:
            try:
                self._set_progress(0, 1, "Loading sentiment model...")
                
                # ğŸ”¥ ä¿®å¤ï¼šè¿™é‡Œä¸è¦ç”¨ embedding_modelï¼
                sa = SentimentAnalyzer(
                    model_name=sent_model,  # â† ç”¨ sentiment_model
                    batch_size=self.cfg.sentiment_batch_size,
                    max_chars=self.cfg.sentiment_max_chars
                )

                # æ³¨æ„ï¼šè¿™é‡Œç”¨ä½ å†…éƒ¨ç»Ÿä¸€åˆ— _text
                sent, conf = SentimentAnalyzer.predict_sentiment_aligned(
                    sa, df2, "_text", progress=self._set_progress, return_conf=True
                )
                df2["sentiment"] = sent
                df2["sentiment_conf"] = conf

                valid_n = int(pd.Series(sent).notna().sum())
                self._log(f"âœ… Sentiment done. valid rows={valid_n}, total={len(df2)}")

            except Exception as e:
                # æƒ…æ„Ÿæ¨¡å‹åŠ è½½/æ¨ç†å¤±è´¥ï¼šä¸ç»ˆæ­¢ï¼Œå…¨é‡ç»§ç»­ + å…è®¸ä»…è´Ÿé¢èµ°æ˜Ÿçº§å…œåº•
                self._log("âš ï¸ Sentiment failed, fallback to star-based negative filter if needed.")
                self._log_exception(e)
        else:
            # ä¸ç¦ç”¨ï¼Œä»…æç¤º
            self._log("âš ï¸ sentiment_model is empty. 'only negative' will fallback to star-based filter if possible.")

        # ---------- Step2: filterï¼ˆç»Ÿä¸€è´Ÿé¢è¿‡æ»¤ç­–ç•¥ï¼‰ ----------
        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šè¿™æ®µä»£ç å¿…é¡»åœ¨ Step1 çš„ if å—ä¹‹å¤–ï¼
        if only_negative_flag:
            # star åˆ—ï¼šä¼˜å…ˆç”¨ field_mapï¼Œå…¶æ¬¡ç”¨å†…éƒ¨ _score
            star_col = None
            try:
                star_col = (self.cfg.field_map.get("star") or "").strip()
            except Exception:
                star_col = None
            if not star_col or star_col not in df2.columns:
                star_col = "_score"

            # sentiment åˆ—ï¼šä½ è¿™é‡Œå›ºå®šå« sentiment
            sentiment_col = "sentiment" if "sentiment" in df2.columns else None

            # ç½®ä¿¡åº¦åˆ—ï¼šå½“å‰ä½ çš„ df2 é‡Œæ²¡æœ‰ sentiment_confï¼ˆå…ˆä¼  Noneï¼Œåç»­å‡çº§æ¨¡å‹è¾“å‡ºæ—¶è¡¥ï¼‰
            sentiment_conf_col = "sentiment_conf" if "sentiment_conf" in df2.columns else None

            mode = getattr(self.cfg, "negative_mode", "STAR_ONLY")
            star_th = float(getattr(self.cfg, "star_negative_threshold", 4.0))
            conf_th = float(getattr(self.cfg, "sentiment_conf_threshold", 0.6))

            # âœ… æ–°å¢ï¼šfusion å‚æ•°
            w_star = float(getattr(self.cfg, "fusion_w_star", 1.0))
            w_sent = float(getattr(self.cfg, "fusion_w_sent", 1.0))
            keep_th = float(getattr(self.cfg, "fusion_keep_threshold", 1.0))

            dfw = self.apply_negative_filter(
                df2,
                star_col=star_col,
                sentiment_col=sentiment_col,
                sentiment_conf_col=sentiment_conf_col,
                mode=mode,
                star_threshold=star_th,
                conf_threshold=conf_th,
                w_star=w_star,
                w_sent=w_sent,
                fusion_keep_threshold=keep_th
            )

            self._log(
                f"only_negative=True | mode={mode} | star_th={star_th} | conf_th={conf_th} | "
                f"w_star={w_star} | w_sent={w_sent} | keep={keep_th} | rows={len(dfw)}"
            )

            # å®‰å…¨å…œåº•ï¼šå¦‚æœç­›å®Œå˜æˆ 0 è¡Œï¼Œè‡ªåŠ¨é™çº§ä¸º ALLï¼ˆé¿å…ç”¨æˆ·è¯¯æ“ä½œç›´æ¥å´©ï¼‰
            if len(dfw) == 0:
                self._log("âš ï¸ è´Ÿé¢è¿‡æ»¤åä¸º 0 è¡Œï¼Œè‡ªåŠ¨é™çº§ä¸º ALLï¼ˆä¸åšè¿‡æ»¤ï¼‰ã€‚")
                dfw = df2.reset_index(drop=True)

        else:
            dfw = df2.reset_index(drop=True)

        self._log(f"only_negative_flag = {only_negative_flag}")
        self._log(f"Rows after filter: {len(dfw)}")

        if len(dfw) < 30:
            raise ValueError(f"è¿‡æ»¤åæ ·æœ¬å¤ªå°‘ï¼ˆ{len(dfw)}ï¼‰ã€‚å»ºè®®å–æ¶ˆä»…è´Ÿé¢æˆ–è°ƒæ•´é˜ˆå€¼/ç­–ç•¥ã€‚")

        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šèµ‹å€¼ç»™ self.df_work
        self.df_work = dfw
        
        self._log(f"âœ… df_work å·²èµ‹å€¼ï¼Œshape={self.df_work.shape}")

        # ---------- Step3: embedding ----------
        self._set_progress(0, 1, "Loading embedding model...")
        
        # ğŸ”¥ è¯Šæ–­ï¼šæ‰“å°æ‰€æœ‰å…³é”®å˜é‡
        self._log(f"ğŸ” DEBUG - df_work ä¿¡æ¯:")
        self._log(f"  - shape: {self.df_work.shape if self.df_work is not None else 'None'}")
        self._log(f"  - columns: {list(self.df_work.columns) if self.df_work is not None else 'None'}")
        self._log(f"  - _text ç±»å‹: {type(self.df_work['_text']) if self.df_work is not None and '_text' in self.df_work.columns else 'N/A'}")
        
        if self.df_work is not None and '_text' in self.df_work.columns:
            texts_raw = self.df_work["_text"]
            self._log(f"  - _text å‰3æ¡: {texts_raw.head(3).tolist()}")
            self._log(f"  - _text.isnull().sum(): {texts_raw.isnull().sum()}")
        
        self._log(f"ğŸ” DEBUG - cfg ä¿¡æ¯:")
        self._log(f"  - embedding_model: {repr(self.cfg.embedding_model)}")
        self._log(f"  - embedding_batch_size: {repr(self.cfg.embedding_batch_size)}")
        self._log(f"  - type(embedding_batch_size): {type(self.cfg.embedding_batch_size)}")
        
        model_name = getattr(self.cfg, "embedding_model", None)
        batch_size_raw = getattr(self.cfg, "embedding_batch_size", None)
        
        self._log(f"ğŸ” DEBUG - getattr ç»“æœ:")
        self._log(f"  - model_name: {repr(model_name)}")
        self._log(f"  - batch_size_raw: {repr(batch_size_raw)}")
        
        if not model_name:
            raise RuntimeError(
                "embedding_model ä¸ºç©º(None)ã€‚\n"
                "é€šå¸¸æ˜¯ settings.json è¦†ç›–å¯¼è‡´ã€‚\n"
                "è§£å†³:åˆ é™¤ settings.json æˆ–åœ¨ settings.json ä¸­è®¾ç½® embedding_model='models/embedding'ã€‚"
            )

        # ğŸ”¥ å…³é”®é˜²å¾¡ï¼šbatch_size
        if batch_size_raw is None or not isinstance(batch_size_raw, (int, float)) or batch_size_raw <= 0:
            self._log(f"âš ï¸ embedding_batch_size æ— æ•ˆ: {repr(batch_size_raw)}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 64")
            batch_size_safe = 64
        else:
            batch_size_safe = int(batch_size_raw)
        
        self._log(f"ğŸ” å‡†å¤‡åˆ›å»º Embedder:")
        self._log(f"  - model_name: {repr(model_name)}")
        self._log(f"  - batch_size: {repr(batch_size_safe)}")
        
        # cache è·¯å¾„
        tag = "neg" if only_negative_flag else "all"
        emb_cache = os.path.join(self.output_dir, f"embeddings_{tag}_{len(self.df_work)}.npy")
        
        # ğŸ”¥ åœ¨åˆ›å»º Embedder ä¹‹å‰æ‰“å°
        self._log("ğŸ” å³å°†æ‰§è¡Œ: emb = Embedder(...)")
        
        try:
            emb = Embedder(
                model_name=model_name,
                batch_size=batch_size_safe
            )
            self._log("âœ… Embedder åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            self._log(f"âŒ Embedder åˆ›å»ºå¤±è´¥!")
            self._log(f"  - Exception type: {type(e)}")
            self._log(f"  - Exception message: {str(e)}")
            raise
        
        # ğŸ”¥ å‡†å¤‡æ–‡æœ¬æ•°æ®
        self._log("ğŸ” å‡†å¤‡ encode çš„æ–‡æœ¬æ•°æ®:")
        
        if self.df_work is None:
            raise RuntimeError("df_work ä¸º None!")
        
        if "_text" not in self.df_work.columns:
            raise RuntimeError(f"df_work ç¼ºå°‘ _text åˆ—! å½“å‰åˆ—: {list(self.df_work.columns)}")
        
        texts_series = self.df_work["_text"]
        self._log(f"  - texts_series ç±»å‹: {type(texts_series)}")
        self._log(f"  - texts_series é•¿åº¦: {len(texts_series) if texts_series is not None else 'None'}")
        
        if texts_series is None:
            raise RuntimeError("df_work['_text'] ä¸º None!")
        
        texts_list = texts_series.fillna("").astype(str).tolist()
        self._log(f"  - texts_list ç±»å‹: {type(texts_list)}")
        self._log(f"  - texts_list é•¿åº¦: {len(texts_list) if texts_list is not None else 'None'}")
        self._log(f"  - texts_list å‰3æ¡: {texts_list[:3] if texts_list else 'None'}")
        
        if texts_list is None:
            raise RuntimeError("texts_list ä¸º None!")
        
        if len(texts_list) == 0:
            raise RuntimeError("texts_list ä¸ºç©ºåˆ—è¡¨!")
        
        self._log("ğŸ” å³å°†æ‰§è¡Œ: emb.encode(...)")
        
        try:
            self.emb = emb.encode(
                texts_list,
                cache_path=emb_cache,
                progress=self._set_progress
            )
            self._log("âœ… emb.encode() æˆåŠŸ")
        except Exception as e:
            self._log(f"âŒ emb.encode() å¤±è´¥!")
            self._log(f"  - Exception type: {type(e)}")
            self._log(f"  - Exception message: {str(e)}")
            raise

        self._log(f"Embedding model: {self.cfg.embedding_model}")
        try:
            self._log(f"Embedding shape: {self.emb.shape}")
        except Exception:
            pass

        # ---------- Step4: scan k ----------
        self._set_progress(0, 1, "Scanning k...")
        self.k_scan = scan_k(
            self.emb,
            self.cfg.k_min,
            self.cfg.k_max,
            random_state=self.cfg.random_state
        )
        self._log(f"K scan done. range=[{self.cfg.k_min},{self.cfg.k_max}]")

        rec = recommend_k(self.k_scan.k_to_silhouette)
        self.k_best = int(rec.best_k)
        score = self.k_scan.k_to_silhouette.get(rec.best_k, float("nan"))
        self._log(f"Recommended K by silhouette = {self.k_best} (score={score:.4f})")

        # ä½ åŸæ¥ä¼šæ¸²æŸ“ K æ‰«æç»“æœï¼ˆæ³¨æ„ï¼šæ­¤å‡½æ•°å†…éƒ¨å¿…é¡»çº¿ç¨‹å®‰å…¨ï¼‰
        try:
            self._render_k_scan()
        except Exception as e:
            self._log("âš ï¸ _render_k_scan failed (ignored).")
            self._log_exception(e)

        # ---------- è‡ªåŠ¨åº”ç”¨æ¨èKï¼ˆå¦‚æœå‹¾é€‰ï¼‰ ----------
        # âœ… è¿™é‡Œä¸èƒ½ self.k_var.setï¼Œå¿…é¡»å›ä¸»çº¿ç¨‹
        if auto_apply_flag:
            self._ui(lambda: self.k_var.set(self.k_best))

            # å¦‚æœè‡ªåŠ¨åº”ç”¨æ¨èKï¼Œæˆ‘ä»¬ä¹ŸåŒæ­¥æŠŠ k_used_ui æ”¹æˆ k_bestï¼ˆç”¨äºæœ¬æ¬¡èšç±»ï¼‰
            k_for_cluster = self.k_best
        else:
            # ä¸è‡ªåŠ¨åº”ç”¨ï¼šç”¨ç”¨æˆ·ç‚¹å‡»æŒ‰é’®é‚£ä¸€åˆ»çš„ Kï¼ˆä¸»çº¿ç¨‹è¯»å‡ºæ¥çš„ï¼‰
            k_for_cluster = int(k_used_ui) if k_used_ui is not None else self.k_best

        self.k_used = int(k_for_cluster)
        self._log(f"Clustering K used = {self.k_used}")

        # ---------- Step4/5: fit kmeans + keywords + representatives ----------
        # è¿™é‡Œä¸å†è°ƒç”¨ä½ åŸæ¥çš„ _pipeline_cluster_onlyï¼ˆå®ƒå¤§æ¦‚ç‡å†…éƒ¨ä¹Ÿåœ¨ get/set Tk å˜é‡ï¼‰
        self._set_progress(0, 1, f"Clustering with K={self.k_used}...")

        self.labels, self.centers = fit_kmeans(
            self.emb,
            k=self.k_used,
            random_state=self.cfg.random_state
        )

        # å†™å› cluster_idï¼ˆåç»­å¯¼å‡º/å¯¹æ¯”/æŠ¥å‘Šéƒ½ä¾èµ–ï¼‰
        self.df_work["cluster_id"] = self.labels

        self._set_progress(0, 1, "Extracting keywords...")
        self.cluster_keywords = top_keywords_by_cluster(
            self.df_work["_text"].tolist(),
            self.labels,
            top_n=self.cfg.top_keywords,
            language=self.cfg.text_language
        )

        self._set_progress(0, 1, "Selecting representatives...")
        reps_dict = top_representatives(
            self.emb,
            self.labels,
            self.centers,
            top_n=self.cfg.top_representatives
        )

        # â˜…å…³é”®ï¼šæŠ¥å‘Š/å¯¼å‡ºä¾èµ–è¿™ä¸ª
        self.cluster_reps = reps_dict

        # reps_df
        rows = []
        for cid, idx_list in reps_dict.items():
            for rank, idx in enumerate(idx_list, 1):
                row = self.df_work.iloc[int(idx)].to_dict()
                row["cluster_id"] = int(cid)
                row["rank_in_cluster"] = int(rank)
                rows.append(row)
        self.reps_df = pd.DataFrame(rows)

        # cluster_summaryï¼ˆå¯¼å‡º/æŠ¥å‘Šç”¨ï¼‰
        cluster_sizes = pd.Series(self.labels).value_counts().sort_index()
        self.cluster_summary = pd.DataFrame({
            "cluster_id": cluster_sizes.index,
            "cluster_size": cluster_sizes.values,
            "ratio": cluster_sizes.values / len(self.labels),
            "keywords": [", ".join(self.cluster_keywords.get(int(c), [])) for c in cluster_sizes.index]
        }).sort_values("ratio", ascending=False)

        # ---------- Exportï¼ˆä¿ç•™ä½ åŸæ¥çš„ reviews_with_sentiment.csvï¼‰ ----------
        out_csv = os.path.join(self.output_dir, "reviews_with_sentiment.csv")
        save_csv(df2, out_csv)
        self._log(f"Exported: {out_csv}")

        # æ ‡è®°ï¼šå½“å‰äº§ç‰©å·²å‡†å¤‡å¥½
        self.artifacts_dirty = False

    def _is_negative_by_star(self, df: pd.DataFrame) -> pd.Series:
        """
        æƒ…æ„Ÿæ¨¡å‹ä¸å¯ç”¨æ—¶ï¼Œç”¨æ˜Ÿçº§å…œåº•â€œä»…è´Ÿé¢â€ï¼š
        - ä¼˜å…ˆç”¨ _scoreï¼ˆä½ åœ¨ on_load_csv å·²æ˜ å°„ï¼‰
        - æ¬¡é€‰ç”¨ Star
        è§„åˆ™ï¼š<=2 è§†ä¸ºè´Ÿé¢
        """
        s = None
        if "_score" in df.columns:
            s = df["_score"]
        elif "Star" in df.columns:
            s = df["Star"]

        if s is None:
            return pd.Series([False] * len(df), index=df.index)

        s_num = pd.to_numeric(s, errors="coerce")
        return s_num.le(2)

    def _pipeline_cluster_only(self):
        if self.emb is None:
            raise ValueError("embeddings ä¸ºç©ºï¼šè¯·å…ˆè¿è¡Œåˆ° Step3ï¼ˆEmbeddingï¼‰æˆ–ç›´æ¥è¿è¡Œå…¨æµç¨‹ã€‚")
        if self.df_work is None:
            raise ValueError("df_work ä¸ºç©ºï¼šè¯·å…ˆè¿è¡Œå…¨æµç¨‹ï¼ˆè‡³å°‘å®Œæˆè¿‡æ»¤ Step2ï¼‰ï¼Œæˆ–å–æ¶ˆâ€œä»…è´Ÿé¢â€åé‡è¯•ã€‚")

        k = int(self.k_var.get())
        self._set_progress(0, 1, f"Clustering k={k} ...")

        # Step4: KMeans
        labels, centers = fit_kmeans(
            self.emb,
            k=k,
            random_state=self.cfg.random_state
        )

        self.labels = labels
        self.centers = centers

        # å†™å› df_work
        self.df_work["cluster_id"] = labels

        # æ¯ä¸ª cluster çš„æ ·æœ¬æ•°
        sizes = self.df_work["cluster_id"].value_counts().sort_index().to_dict()
        self._log(f"Cluster sizes: {sizes}")

        # Step5: keywordsï¼ˆå…³é”®ï¼šæ¥å…¥è¯­è¨€ï¼‰
        self._set_progress(0, 1, "Extracting keywords...")

        lang = getattr(self.cfg, "text_language", "en")  # æ¥è‡ª UI + settings.json
        self.cluster_keywords = top_keywords_by_cluster(
            self.df_work["_text"].tolist(),
            self.labels,
            top_n=self.cfg.top_keywords,
            language=lang
        )

        self._log(
            f"Keywords extracted for clusters (language={lang}): "
            + ", ".join(str(cid) for cid in self.cluster_keywords.keys())
        )

        # Step5: representatives
        self._set_progress(0, 1, "Finding representatives...")
        self.cluster_reps = top_representatives(
            self.emb,
            self.labels,
            self.centers,
            top_n=self.cfg.top_representatives
        )

        # Robustness
        self._set_progress(0, 1, "Robustness (bootstrap ARI)...")
        stab = clustering_stability(
            self.emb,
            k=k,
            runs=5,
            random_state=self.cfg.random_state
        )

        # Render
        self._render_results(stab)

    def _render_k_scan(self):
        self.k_text.delete("1.0", "end")
        self.k_text.insert("end", "k\tinertia(SSE)\tsilhouette\n")
        for k in range(self.cfg.k_min, self.cfg.k_max + 1):
            sse = self.k_scan.k_to_inertia.get(k, None)
            sil = self.k_scan.k_to_silhouette.get(k, None)
            self.k_text.insert("end", f"{k}\t{(sse or 0):.2f}\t\t{(sil or 0):.4f}\n")

    def _render_results(self, stability: dict):
        self.res_text.delete("1.0", "end")
        self.res_text.insert("end", f"Filtered rows: {len(self.df_work)}\n")
        self.res_text.insert(
            "end",
            f"Stability ARI (bootstrap): mean={stability['ari_mean']:.3f}, "
            f"min={stability['ari_min']:.3f}, max={stability['ari_max']:.3f}\n\n"
        )

        for c in sorted(self.cluster_keywords.keys()):
            self.res_text.insert("end", f"=== Cluster {c} ===\n")
            kws = ", ".join(self.cluster_keywords[c])
            self.res_text.insert("end", f"Keywords: {kws}\n")

            reps = self.cluster_reps.get(c, [])
            self.res_text.insert("end", "Representatives:\n")
            for idx in reps:
                row = self.df_work.iloc[idx]
                gid = row["_group"] if row["_group"] is not None else "-"
                score = row["_score"] if row["_score"] is not None else "-"
                text = str(row["_text"])[:180]
                self.res_text.insert(
                    "end",
                    f"- ({gid}, Score={score}) {text}...\n"
                )
            self.res_text.insert("end", "\n")

    def on_plot_k(self):
        if self.k_scan is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆè¿è¡Œå…¨æµç¨‹ï¼ˆè‡³å°‘è·‘åˆ°é€‰Kæ‰«æï¼‰")
            return

        rec = recommend_k(self.k_scan.k_to_silhouette)
        best_k = int(rec.best_k)

        png_path = os.path.join(self.output_dir, "k_selection.png")
        plot_k_curves(
            self.k_scan.k_to_inertia,
            self.k_scan.k_to_silhouette,
            best_k,
            png_path
        )

        # å¦‚æœå‹¾é€‰äº†è‡ªåŠ¨åº”ç”¨æ¨èKï¼Œåˆ™åŒæ­¥æ›´æ–° Spinbox æ˜¾ç¤º
        if self.auto_apply_k.get():
            try:
                self.k_var.set(best_k)
            except Exception:
                pass

        cur_k = None
        try:
            cur_k = int(self.k_var.get())
        except Exception:
            cur_k = best_k

        messagebox.showinfo(
            "å®Œæˆ",
            f"Ké€‰æ‹©å›¾å·²å¯¼å‡ºï¼š\n{png_path}\n\n"
            f"æ¨èK={best_k}\nå½“å‰K={cur_k}\n\n"
            f"å¦‚éœ€æ›´æ–°èšç±»ç»“æœï¼šè¯·ç‚¹â€œä»…é‡è·‘ Step4-5ï¼ˆç”¨å½“å‰Kï¼‰â€ã€‚"
        )

    def on_asin_compare(self):
        """
        è·¨ASINå¯¹æ¯”ï¼ˆä¿ç•™æ—§ç‰ˆ + æ ¸å¿ƒå‡çº§ï¼‰ï¼š
        æ—§ï¼š
        - ASINÃ—Cluster å æ¯”çƒ­åŠ›å›¾ + csv
        æ–°ï¼ˆæ ¸å¿ƒå‡çº§ï¼‰ï¼š
        - Attribute Taxonomy
        - ASINÃ—Attribute share% çƒ­åŠ›å›¾
        - ASINÃ—Attribute pain çƒ­åŠ›å›¾
        - Opportunity Insights
        - å¯¼å‡ºï¼šasin_attribute_matrix.xlsx
        """
        import os
        import pandas as pd
        from tkinter import messagebox

        # 0) å‰ç½®æ£€æŸ¥
        if self.df_work is None or "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("æç¤º", "è¯·å…ˆå®Œæˆèšç±»ï¼ˆStep4-5ï¼‰")
            return

        df_clustered = self.df_work.copy()

        # 1) ASINåˆ— / Staråˆ— å…¼å®¹
        asin_col = None
        try:
            asin_col = (self.cfg.field_map.get("asin") or "").strip()
        except Exception:
            asin_col = None
        if not asin_col:
            asin_col = "_group"

        if asin_col not in df_clustered.columns:
            messagebox.showwarning(
                "æç¤º",
                f"æœªæ‰¾åˆ° ASIN åˆ—ï¼ˆå½“å‰ä½¿ç”¨ï¼š{asin_col}ï¼‰ã€‚\n"
                "è¯·ç¡®è®¤æ•°æ®ä¸­åŒ…å« ASINï¼Œæˆ–æ£€æŸ¥è‡ªåŠ¨åˆ—åè¯†åˆ«/field_mapã€‚"
            )
            return

        star_col = None
        try:
            star_col = (self.cfg.field_map.get("star") or "").strip()
        except Exception:
            star_col = None
        if not star_col or star_col not in df_clustered.columns:
            star_col = "_score" if "_score" in df_clustered.columns else ("Star" if "Star" in df_clustered.columns else None)

        if star_col is None or star_col not in df_clustered.columns:
            messagebox.showwarning("æç¤º", "ç¼ºå°‘è¯„åˆ†åˆ—ï¼ˆStar/_scoreï¼‰ï¼Œæ— æ³•è®¡ç®— pain ä¸ Priorityã€‚")
            return

        # 2) cluster_keywordsï¼ˆç”¨äº Attribute taxonomyï¼‰
        cluster_keywords = getattr(self, "cluster_keywords", None)
        if not cluster_keywords:
            # å…œåº•ï¼šä» cluster_summary æ‹¿
            cs = getattr(self, "cluster_summary", None)
            if cs is not None and hasattr(cs, "columns") and ("cluster_id" in cs.columns) and ("keywords" in cs.columns):
                cluster_keywords = dict(zip(cs["cluster_id"].tolist(), cs["keywords"].tolist()))

        if not cluster_keywords:
            messagebox.showwarning("æç¤º", "æ²¡æœ‰æ‰¾åˆ° cluster_keywordsã€‚è¯·ç¡®è®¤ Step5 å·²ç”Ÿæˆå…³é”®è¯ã€‚")
            return

        # 3) è¾“å‡ºç›®å½•
        out_dir = getattr(self, "output_dir", None) or os.path.join(os.getcwd(), "outputs")
        os.makedirs(out_dir, exist_ok=True)

        # =========================
        # A) æ—§ï¼šASINÃ—Cluster çƒ­åŠ›å›¾ï¼ˆä¿ç•™ï¼‰
        # =========================
        try:
            pivot_cluster = asin_cluster_percent(df_clustered, asin_col=asin_col, cluster_col="cluster_id")
            self.asin_pivot = pivot_cluster

            old_png = os.path.join(out_dir, "asin_cluster_percent_heatmap.png")
            fig = plot_heatmap(pivot_cluster, save_path=old_png, title="ASIN Ã— Cluster Share (%)")
            import matplotlib.pyplot as plt
            plt.close(fig)

            old_csv = os.path.join(out_dir, "asin_cluster_percent.csv")
            pivot_cluster.round(2).to_csv(old_csv, encoding="utf-8-sig")

            # ç»™å†™æŠ¥å‘Šç”¨
            self.asin_heatmap_png = old_png

        except Exception as e:
            messagebox.showwarning("æç¤º", f"æ—§ç‰ˆè·¨ASINçƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥ï¼š{e}")
            return

        # =========================
        # B) æ–°ï¼šASINÃ—Attributeï¼ˆæ ¸å¿ƒå‡çº§ï¼‰
        # =========================
        try:
            from core.insights import (
                build_attribute_taxonomy,
                asin_attribute_share,
                asin_attribute_pain,
                opportunity_insights,
            )

            taxonomy_df = build_attribute_taxonomy(cluster_keywords, topn=3)
            share_pivot = asin_attribute_share(
                df_clustered,
                asin_col=asin_col,
                cluster_col="cluster_id",
                taxonomy_df=taxonomy_df
            )
            pain_pivot = asin_attribute_pain(
                df_clustered,
                asin_col=asin_col,
                cluster_col="cluster_id",
                star_col=star_col,
                taxonomy_df=taxonomy_df
            )
            opp_df = opportunity_insights(pain_pivot, topk=15)

            out_xlsx = os.path.join(out_dir, "asin_attribute_matrix.xlsx")
            with pd.ExcelWriter(out_xlsx, engine="openpyxl") as writer:
                taxonomy_df.to_excel(writer, sheet_name="attribute_taxonomy", index=False)
                share_pivot.to_excel(writer, sheet_name="asin_attribute_share")
                pain_pivot.to_excel(writer, sheet_name="asin_attribute_pain")
                (opp_df if opp_df is not None else pd.DataFrame()).to_excel(writer, sheet_name="opportunity_top", index=False)

            # ä¸¤å¼ æ–°çƒ­åŠ›å›¾ï¼ˆæ²¿ç”¨ä½ ç°åœ¨çš„ imshow ç”»æ³•ï¼‰
            import numpy as np
            import matplotlib.pyplot as plt

            def _plot_heatmap(pivot_df: pd.DataFrame, title: str, out_png: str):
                if pivot_df is None or pivot_df.shape[0] == 0 or pivot_df.shape[1] == 0:
                    return
                fig = plt.figure(figsize=(12, max(4, 0.35 * pivot_df.shape[0])))
                ax = fig.add_subplot(111)
                data = pivot_df.values.astype(float)
                im = ax.imshow(data, aspect="auto")

                ax.set_title(title)
                ax.set_yticks(np.arange(pivot_df.shape[0]))
                ax.set_yticklabels(pivot_df.index.astype(str).tolist(), fontsize=8)

                ax.set_xticks(np.arange(pivot_df.shape[1]))
                ax.set_xticklabels(pivot_df.columns.astype(str).tolist(), rotation=45, ha="right", fontsize=8)

                fig.colorbar(im, ax=ax, fraction=0.02, pad=0.02)
                fig.tight_layout()
                fig.savefig(out_png, dpi=200)
                plt.close(fig)

            png_share = os.path.join(out_dir, "asin_attribute_share.png")
            png_pain  = os.path.join(out_dir, "asin_attribute_pain.png")
            _plot_heatmap(share_pivot, "ASIN Ã— Attribute Share (%)", png_share)
            _plot_heatmap(pain_pivot,  "ASIN Ã— Attribute Pain (Priority)", png_pain)

            # ç»™å†™æŠ¥å‘Šç”¨ï¼ˆä¸‹ä¸€æ­¥ç”¨ï¼‰
            self.asin_attr_xlsx = out_xlsx
            self.asin_attr_share_png = png_share
            self.asin_attr_pain_png = png_pain
            self.asin_taxonomy_df = taxonomy_df
            self.asin_opp_df = opp_df

        except Exception as e:
            messagebox.showwarning("æç¤º", f"æ ¸å¿ƒå‡çº§ï¼ˆASINÃ—Attributeï¼‰ç”Ÿæˆå¤±è´¥ï¼š{e}")
            return

        # 4) ç»Ÿä¸€å¼¹çª— + æ—¥å¿—
        try:
            self._log(f"âœ… å·²è¾“å‡ºæ—§çƒ­åŠ›å›¾ï¼š{old_png}")
            self._log(f"âœ… å·²è¾“å‡ºæ—§CSVï¼š{old_csv}")
            self._log(f"âœ… å·²è¾“å‡ºæ–°Excelï¼š{out_xlsx}")
            self._log(f"âœ… å·²è¾“å‡ºæ–°çƒ­åŠ›å›¾ï¼š{png_share}")
            self._log(f"âœ… å·²è¾“å‡ºæ–°çƒ­åŠ›å›¾ï¼š{png_pain}")
        except Exception:
            pass

        messagebox.showinfo(
            "å®Œæˆ",
            "è·¨ASINå¯¹æ¯”å·²å¯¼å‡ºï¼š\n"
            f"[æ—§] çƒ­åŠ›å›¾ï¼š{old_png}\n"
            f"[æ—§] CSVï¼š{old_csv}\n\n"
            f"[æ–°] Excelï¼š{out_xlsx}\n"
            f"[æ–°] Shareçƒ­åŠ›å›¾ï¼š{png_share}\n"
            f"[æ–°] Painçƒ­åŠ›å›¾ï¼š{png_pain}\n"
        )

    def on_priority(self):
        if self.df_work is None or "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("æç¤º", "è¯·å…ˆå®Œæˆèšç±»ï¼ˆStep4-5ï¼‰")
            return

        df = self.df_work.copy()

        # ===== 1. åˆ†ç»„é”®å…œåº•ï¼ˆæ²¡æœ‰ ASIN ä¹Ÿèƒ½è·‘ï¼‰=====
        # ä¼˜å…ˆ ASINï¼Œå…¶æ¬¡æ™¯ç‚¹åç§°ï¼Œæœ€å ALL
        group_col = None
        for cand in ["ASIN", "asin", "æ™¯ç‚¹åç§°", "place", "group"]:
            if cand in df.columns:
                group_col = cand
                break

        if group_col is None:
            df["__GROUP__"] = "ALL"
            group_col = "__GROUP__"

        # ===== 2. è¯„åˆ†åˆ—å…œåº• =====
        try:
            star_col = (self.cfg.field_map.get("star") or "").strip()
        except Exception:
            star_col = None

        if not star_col or star_col not in df.columns:
            star_col = "_score"

        if star_col not in df.columns:
            messagebox.showwarning(
                "æç¤º",
                f"æœªæ‰¾åˆ°è¯„åˆ†åˆ—ï¼ˆå½“å‰ä½¿ç”¨ï¼š{star_col}ï¼‰ã€‚\n"
                "è¯·ç¡®è®¤æ•°æ®ä¸­åŒ…å« Star/Ratingï¼Œæˆ–æ£€æŸ¥è‡ªåŠ¨åˆ—åè¯†åˆ«/field_mapã€‚"
            )
            return

        # ===== 3. è°ƒç”¨å®‰å…¨ç‰ˆä¼˜å…ˆçº§è®¡ç®— =====
        pr = cluster_priority_safe(
            df,
            cluster_col="cluster_id",
            star_col=star_col,
            group_col=group_col
        )

        self.priority_df = pr

        # ===== 4. å¯¼å‡º =====
        png_path = os.path.join(self.output_dir, "cluster_priority.png")
        fig = plot_priority(pr, save_path=png_path)
        import matplotlib.pyplot as plt
        plt.close(fig)

        csv_path = os.path.join(self.output_dir, "cluster_priority.csv")
        pr.to_csv(csv_path, index=False, encoding="utf-8-sig")

        messagebox.showinfo("å®Œæˆ", f"ä¼˜å…ˆçº§æ’åºå·²å¯¼å‡ºï¼š\n{png_path}\n{csv_path}")

    def on_export(self):
        if self.df_work is None or self.labels is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆè¿è¡Œæµç¨‹å¾—åˆ°èšç±»ç»“æœ")
            return
        if "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("æç¤º", "å½“å‰ df_work ç¼ºå°‘ cluster_idï¼Œè¯·å…ˆé‡è·‘ Step4-5")
            return

        # 1) å¯¼å‡ºå¸¦clusterçš„æ˜ç»†
        detail_path = os.path.join(self.output_dir, "clustered_reviews.csv")
        save_csv(self.df_work, detail_path)

        # ====== åˆ—åå…¼å®¹ï¼šä¼˜å…ˆä½¿ç”¨æ˜ å°„åˆ—ï¼Œå¦åˆ™ç”¨å†…éƒ¨ç»Ÿä¸€åˆ— ======
        asin_col = (getattr(self.cfg, "field_map", {}) or {}).get("asin") or None
        star_col = (getattr(self.cfg, "field_map", {}) or {}).get("star") or None
        text_col = (getattr(self.cfg, "field_map", {}) or {}).get("text") or None
        id_col   = (getattr(self.cfg, "field_map", {}) or {}).get("id") or None

        # fallback
        if not asin_col or asin_col not in self.df_work.columns:
            asin_col = "_group" if "_group" in self.df_work.columns else None
        if not star_col or star_col not in self.df_work.columns:
            star_col = "_score" if "_score" in self.df_work.columns else None
        if not text_col or text_col not in self.df_work.columns:
            text_col = "_text" if "_text" in self.df_work.columns else None
        if not id_col or id_col not in self.df_work.columns:
            id_col = "_id" if "_id" in self.df_work.columns else None

        # 2) å¯¼å‡ºç°‡æ‘˜è¦è¡¨ï¼ˆTable 1ï¼‰
        rows = []
        total = len(self.df_work)
        for c in sorted(self.cluster_keywords.keys()):
            idx = (self.df_work["cluster_id"] == c)
            ratio = float(idx.mean()) if total > 0 else 0.0
            rows.append({
                "cluster_id": int(c),
                "cluster_size": int(idx.sum()),
                "ratio": ratio,
                "keywords": ", ".join(self.cluster_keywords.get(c, [])),
            })
        summary = pd.DataFrame(rows).sort_values("ratio", ascending=False)

        # 3) ä»£è¡¨è¯„è®ºè¡¨ï¼ˆå…¼å®¹å­—æ®µï¼‰
        rep_rows = []
        for c, idx_list in (self.cluster_reps or {}).items():
            for rank, i in enumerate(idx_list, start=1):
                r = self.df_work.iloc[int(i)]

                rep_rows.append({
                    "cluster_id": int(c),
                    "rank": int(rank),
                    "ASIN": r.get(asin_col, "-") if asin_col else r.get("_group", "-"),
                    "Star": r.get(star_col, "-") if star_col else r.get("_score", "-"),
                    "review_id": r.get(id_col, "-") if id_col else r.get("_id", "-"),
                    "review_text": r.get(text_col, "") if text_col else r.get("_text", ""),
                })

        reps_df = pd.DataFrame(rep_rows)

        xlsx_path = os.path.join(self.output_dir, "results.xlsx")
        sheets = {"cluster_summary": summary, "representatives": reps_df}

        if hasattr(self, "asin_pivot") and self.asin_pivot is not None:
            sheets["asin_cluster_percent"] = self.asin_pivot.reset_index()

        if hasattr(self, "priority_df") and self.priority_df is not None:
            sheets["cluster_priority"] = self.priority_df

        save_excel(sheets, xlsx_path)

        messagebox.showinfo("å¯¼å‡ºå®Œæˆ", f"å·²å¯¼å‡ºï¼š\n- {detail_path}\n- {xlsx_path}")

    def on_report_offline(self):
        if self.df_work is None or self.cluster_keywords is None or self.cluster_reps is None or self.k_scan is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆè¿è¡Œ Step1-5 å¹¶å¾—åˆ°èšç±»ç»“æœåå†ç”ŸæˆæŠ¥å‘Š")
            return
        if "cluster_id" not in self.df_work.columns:
            messagebox.showwarning("æç¤º", "å½“å‰ df_work ç¼ºå°‘ cluster_idï¼Œè¯·å…ˆé‡è·‘ Step4-5")
            return

        def job():
            # ====== åˆ—åå…¼å®¹ï¼šä¼˜å…ˆä½¿ç”¨æ˜ å°„åˆ—ï¼Œå¦åˆ™ç”¨å†…éƒ¨ç»Ÿä¸€åˆ— ======
            asin_col = (getattr(self.cfg, "field_map", {}) or {}).get("asin") or None
            star_col = (getattr(self.cfg, "field_map", {}) or {}).get("star") or None
            text_col = (getattr(self.cfg, "field_map", {}) or {}).get("text") or None
            id_col   = (getattr(self.cfg, "field_map", {}) or {}).get("id") or None

            if not asin_col or asin_col not in self.df_work.columns:
                asin_col = "_group" if "_group" in self.df_work.columns else None
            if not star_col or star_col not in self.df_work.columns:
                star_col = "_score" if "_score" in self.df_work.columns else None
            if not text_col or text_col not in self.df_work.columns:
                text_col = "_text" if "_text" in self.df_work.columns else None
            if not id_col or id_col not in self.df_work.columns:
                id_col = "_id" if "_id" in self.df_work.columns else None

            # summary
            rows = []
            total = len(self.df_work)
            for c in sorted(self.cluster_keywords.keys()):
                idx = (self.df_work["cluster_id"] == c)
                ratio = float(idx.mean()) if total > 0 else 0.0
                rows.append({
                    "cluster_id": int(c),
                    "cluster_size": int(idx.sum()),
                    "ratio": ratio,
                    "keywords": ", ".join(self.cluster_keywords.get(c, [])),
                })
            summary = pd.DataFrame(rows).sort_values("ratio", ascending=False)

            # representatives
            rep_rows = []
            for c, idx_list in (self.cluster_reps or {}).items():
                for rank, i in enumerate(idx_list, start=1):
                    r = self.df_work.iloc[int(i)]
                    rep_rows.append({
                        "cluster_id": int(c),
                        "rank": int(rank),
                        "ASIN": r.get(asin_col, "-") if asin_col else r.get("_group", "-"),
                        "Star": r.get(star_col, "-") if star_col else r.get("_score", "-"),
                        "review_id": r.get(id_col, "-") if id_col else r.get("_id", "-"),
                        "review_text": r.get(text_col, "") if text_col else r.get("_text", ""),
                    })
            reps_df = pd.DataFrame(rep_rows)

            # ====== å›¾/è¡¨è·¯å¾„ï¼ˆå­˜åœ¨å°±æ’å…¥ï¼‰ ======
            k_png = os.path.join(self.output_dir, "k_selection.png")

            # âœ… æ—§è·¨ASINçƒ­åŠ›å›¾ï¼šä½ ç°åœ¨ç”Ÿæˆçš„æ˜¯è¿™ä¸ªåå­—
            asin_png = os.path.join(self.output_dir, "asin_cluster_percent_heatmap.png")

            # âœ… Priority å›¾ï¼ˆä¼˜å…ˆçº§æ’åºæŒ‰é’®ç”Ÿæˆï¼‰
            pr_png = os.path.join(self.output_dir, "cluster_priority.png")

            # âœ… æ–°ï¼šASINÃ—Attribute æ ¸å¿ƒå‡çº§äº§ç‰©
            attr_xlsx = os.path.join(self.output_dir, "asin_attribute_matrix.xlsx")
            attr_share_png = os.path.join(self.output_dir, "asin_attribute_share.png")
            attr_pain_png  = os.path.join(self.output_dir, "asin_attribute_pain.png")

            rec = recommend_k(self.k_scan.k_to_silhouette)

            out_path = build_offline_report(
                cfg=self.cfg,
                output_dir=self.output_dir,
                df_all=self.df,          # åŸå§‹å…¨é‡
                df_work=self.df_work,    # ç”¨äºèšç±»çš„é‚£ä»½
                k_to_inertia=self.k_scan.k_to_inertia,
                k_to_silhouette=self.k_scan.k_to_silhouette,
                k_best=int(rec.best_k),
                cluster_summary=summary,
                reps_df=reps_df,

                # æ—§ï¼šå›¾
                k_plot_png=k_png if os.path.exists(k_png) else None,
                asin_heatmap_png=asin_png if os.path.exists(asin_png) else None,
                priority_png=pr_png if os.path.exists(pr_png) else None,

                # âœ… æ–°ï¼šASINÃ—Attributeï¼ˆæ ¸å¿ƒå‡çº§ï¼‰
                asin_attr_xlsx=attr_xlsx if os.path.exists(attr_xlsx) else None,
                asin_attr_share_png=attr_share_png if os.path.exists(attr_share_png) else None,
                asin_attr_pain_png=attr_pain_png if os.path.exists(attr_pain_png) else None,
                
                key_findings_with_metrics=True,   # âœ… è®ºæ–‡ç‰ˆï¼šå¸¦æ•°å€¼
            )

            self._log(f"âœ… Offline report generated: {out_path}")
            self._ui(lambda: messagebox.showinfo("å®Œæˆ", f"ç¦»çº¿WordæŠ¥å‘Šå·²ç”Ÿæˆï¼š\n{out_path}"))

        self._run_in_thread(job, "Generating offline Word report...")

    def _lang_bucket(self, lang: str) -> str:
        if not lang:
            return "en"
        return "zh" if lang.lower().startswith("zh") else "en"

    def _sentiment_options_for_lang(self, lang: str):
        if self._lang_bucket(lang) == "zh":
            return [
                ("zh_dianping", "??-????"),
                ("zh_general", "??-??"),
                ("zh_chinanews", "??-??"),
                ("zh_jd_binary", "??-??"),
            ]
        return [("en_sst2", "English-SST2")]

    def _recommended_sentiment_key(self, lang: str) -> str:
        return "zh_dianping" if self._lang_bucket(lang) == "zh" else "en_sst2"

    def _derive_sentiment_key_from_cfg(self) -> str:
        key = getattr(self.cfg, "sentiment_model_key", "") or ""
        if key:
            return key
        model_map = getattr(self.cfg, "sentiment_model_map", {}) or {}
        current = getattr(self.cfg, "sentiment_model", "") or ""
        if not current or not model_map:
            return ""
        for k, p in model_map.items():
            expected = self._resolve_path(p) if hasattr(self, "_resolve_path") else p
            if os.path.normpath(str(current)) == os.path.normpath(str(expected)):
                return k
        return ""

    def _apply_sentiment_model_key(self, key: str, save: bool) -> None:
        model_map = getattr(self.cfg, "sentiment_model_map", {}) or {}
        rel_path = model_map.get(key, "")
        self.cfg.sentiment_model_key = key
        if rel_path:
            self.cfg.sentiment_model = self._resolve_path(rel_path) if hasattr(self, "_resolve_path") else rel_path

        if save:
            save_user_settings({
                "sentiment_model_key": key,
                "sentiment_model": rel_path or getattr(self.cfg, "sentiment_model", None),
            })

    def _refresh_sentiment_model_options(self, lang: str, select_key: str | None = None, save: bool = False) -> None:
        options = self._sentiment_options_for_lang(lang)
        self.sentiment_model_label_to_key = {label: key for key, label in options}
        self.sentiment_model_key_to_label = {key: label for key, label in options}
        self.sentiment_model_box["values"] = [label for _, label in options]

        key = select_key or ""
        if key not in self.sentiment_model_key_to_label:
            key = self._recommended_sentiment_key(lang)
            if key not in self.sentiment_model_key_to_label and options:
                key = options[0][0]

        label = self.sentiment_model_key_to_label.get(key, "")
        if label:
            self.sentiment_model_var.set(label)
        self._apply_sentiment_model_key(key, save=save)

    def on_language_changed(self, event=None):
        self.cfg.text_language = self.lang_var.get().strip()
        self._refresh_sentiment_model_options(
            self.cfg.text_language,
            select_key=self._recommended_sentiment_key(self.cfg.text_language),
            save=False
        )

        model_map = getattr(self.cfg, "sentiment_model_map", {}) or {}
        key = getattr(self.cfg, "sentiment_model_key", "")
        rel_path = model_map.get(key, getattr(self.cfg, "sentiment_model", ""))

        # ????? settings.json
        save_user_settings({
            "text_language": self.cfg.text_language,
            "sentiment_model_key": key,
            "sentiment_model": rel_path,
            "aihubmix_base_url": getattr(self.cfg, "aihubmix_base_url", ""),
            "aihubmix_api_key": getattr(self.cfg, "aihubmix_api_key", None),
            "aihubmix_default_model": getattr(self.cfg, "aihubmix_default_model", ""),
        })

        self._log(f"? text_language set to: {self.cfg.text_language}")
        messagebox.showinfo("???", f"?????????{self.cfg.text_language}
??????????")

    def on_sentiment_model_changed(self, event=None):
        label = self.sentiment_model_var.get().strip()
        key = self.sentiment_model_label_to_key.get(label)
        if not key:
            return
        self._apply_sentiment_model_key(key, save=True)
        self._log(f"? sentiment_model_key set to: {key}")
        messagebox.showinfo("???", f"?????????{label}
??????????")

    def on_negative_mode_changed(self, event=None):
        """
        UIï¼šè´Ÿé¢ç­›é€‰ç­–ç•¥åˆ‡æ¢
        - STAR_ONLY
        - FUSION
        - SENTIMENT_ONLY
        """
        mode = self.negative_mode_var.get().strip()

        # å†™å›é…ç½®
        self.cfg.negative_mode = mode

        # ä¿å­˜åˆ° settings.jsonï¼ˆå’Œè¯­è¨€åˆ‡æ¢ä¸€è‡´ï¼‰
        save_user_settings({
            "negative_mode": self.cfg.negative_mode
        })

        self._log(f"âœ… negative_mode set to: {self.cfg.negative_mode}")

        messagebox.showinfo(
            "å·²ä¿å­˜",
            f"è´Ÿé¢ç­›é€‰ç­–ç•¥å·²åˆ‡æ¢ä¸ºï¼š\n{self.cfg.negative_mode}\n\n"
            "è¯¥è®¾ç½®å°†ç”¨äºä¸‹ä¸€æ¬¡ Step1â€“5 è¿è¡Œã€‚"
        )

    def on_thresholds_changed(self, event=None):
        """
        å½“ç”¨æˆ·ä¿®æ”¹ä»»æ„ä¸€ä¸ªé˜ˆå€¼/æƒé‡å‚æ•°å¹¶è§¦å‘ä¿å­˜æ—¶è°ƒç”¨ã€‚
        é™é»˜ä¿å­˜åˆ° cfg å’Œ settings.jsonï¼Œå¹¶è®°å½•æ—¥å¿—ã€‚
        """
        try:
            # 1. ä» UI å˜é‡è¯»å–æ•°å€¼
            star_th = float(self.star_th_var.get())
            conf_th = float(self.conf_th_var.get())
            w_star = float(self.fusion_w_star_var.get())
            w_sent = float(self.fusion_w_sent_var.get())
            keep_th = float(self.fusion_keep_var.get())

            # 2. æ›´æ–°å†…å­˜ä¸­çš„ Config å¯¹è±¡ (ä¸‹æ¬¡è¿è¡Œç”Ÿæ•ˆ)
            self.cfg.star_negative_threshold = star_th
            self.cfg.sentiment_conf_threshold = conf_th
            self.cfg.fusion_w_star = w_star
            self.cfg.fusion_w_sent = w_sent
            self.cfg.fusion_keep_threshold = keep_th

            # 3. æŒä¹…åŒ–åˆ° settings.json
            save_user_settings({
                "star_negative_threshold": star_th,
                "sentiment_conf_threshold": conf_th,
                "fusion_w_star": w_star,
                "fusion_w_sent": w_sent,
                "fusion_keep_threshold": keep_th,
            })

            # 4. æ‰“å°æ—¥å¿— (ä¸å¼¹çª—æ‰“æ‰°)
            self._log(
                f"âœ… Params saved: Star<={star_th} | Conf>={conf_th} | "
                f"Fusion(wStar={w_star}, wSent={w_sent}, Keep>={keep_th})"
            )

        except ValueError:
            # é˜²æ­¢ç”¨æˆ·è¾“å…¥éæ³•å­—ç¬¦å¯¼è‡´è½¬æ¢ float å¤±è´¥
            self._log("âš ï¸ å‚æ•°è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œæœªä¿å­˜ã€‚è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—ã€‚")
        except Exception as e:
            self._log(f"âŒ ä¿å­˜å‚æ•°å¤±è´¥: {e}")

    def _tk_ex_handler(exc, val, tb):
        traceback.print_exception(exc, val, tb)

    def pre_download_models(self):
        """
        ????-????????????????????????huggingface???
        ???????exe ??????????
        ./models/
            embedding/  (??????)
            sentiment/<key>/  (??????)

        config ???
        cfg.embedding_model = "./models/embedding"
        cfg.sentiment_model = "./models/sentiment/<key>"   # ??????
        """
        # ???????????exe ???/ ??????
        base_dir = os.path.dirname(os.path.abspath(sys.argv[0]))
        models_root = os.path.join(base_dir, "models")

        emb_path = getattr(self.cfg, "embedding_model", None)
        sent_path = getattr(self.cfg, "sentiment_model", None)

        missing = []

        # 1) embedding????
        if not emb_path:
            missing.append("embedding_model?????")
        else:
            # ?????????????????exe/?????
            emb_abs = emb_path
            if not os.path.isabs(emb_abs):
                emb_abs = os.path.join(base_dir, emb_path)
            if not os.path.isdir(emb_abs):
                missing.append(f"Embedding ????????{emb_abs}")
            else:
                self._log(f"? Embedding ?????{emb_abs}")
            # ?? cfg?????????????
            self.cfg.embedding_model = emb_abs

        # 2) sentiment???????????????????????
        if sent_path:
            sent_abs = sent_path
            if not os.path.isabs(sent_abs):
                sent_abs = os.path.join(base_dir, sent_path)
            if not os.path.isdir(sent_abs):
                missing.append(f"Sentiment ????????{sent_abs}")
            else:
                self._log(f"? Sentiment ?????{sent_abs}")
            self.cfg.sentiment_model = sent_abs

        # 3) ?????????????./models/embedding ? ./models/sentiment/<key>
        # ?? config ?????????? fallback ?????????
        if emb_path in (None, "", "auto"):
            default_emb = os.path.join(models_root, "embedding")
            if os.path.isdir(default_emb):
                self.cfg.embedding_model = default_emb
                self._log(f"? Embedding ???????{default_emb}")
            else:
                missing.append(f"Embedding ????????{default_emb}")

        if sent_path in (None, "", "auto"):
            key = getattr(self.cfg, "sentiment_model_key", "") or ""
            default_sent = None
            if key:
                candidate = os.path.join(models_root, "sentiment", key)
                if os.path.isdir(candidate):
                    default_sent = candidate
            if not default_sent:
                legacy = os.path.join(models_root, "sentiment")
                if os.path.isdir(legacy):
                    default_sent = legacy
            if default_sent:
                self.cfg.sentiment_model = default_sent
                self._log(f"? Sentiment ???????{default_sent}")
            else:
                missing.append(f"Sentiment ????????{os.path.join(models_root, 'sentiment')}")

        if missing:
            msg = "??????????????????? models ????

" + "
".join(f"- {x}" for x in missing) +                 "

????????
"                 f"{models_root}\embedding\...
"                 f"{models_root}\sentiment\<key>\...
"
            self._log(msg)
            messagebox.showerror("????", msg)
            raise RuntimeError(msg)

    def _on_close(self):
        """
        ä¼˜é›…é€€å‡ºï¼š
        1) æ ‡è®° closingï¼Œé˜»æ­¢æ–°çš„ after è°ƒåº¦
        2) cancel log pump çš„ after
        3) ç­‰åå°çº¿ç¨‹ç»“æŸï¼ˆdaemon=Falseï¼‰
        4) destroy Tk
        """
        import time

        # é˜²æ­¢é‡å¤è§¦å‘
        if getattr(self, "_closing", False):
            return

        self._closing = True
        print("ğŸ”´ æ­£åœ¨é€€å‡º...")

        # 1) åœæ­¢ log pumpï¼ˆéå¸¸å…³é”®ï¼‰
        try:
            if hasattr(self, "_log_pump_id") and self._log_pump_id is not None:
                self.after_cancel(self._log_pump_id)
                self._log_pump_id = None
        except Exception:
            pass

        # 2) å°è¯•æŠŠçŠ¶æ€æ¢å›ä¸€ä¸‹ï¼ˆé¿å…ææ„é˜¶æ®µ Tk å˜é‡è¿˜åœ¨å˜ï¼‰
        try:
            if hasattr(self, "status"):
                self.status.set("Closing...")
        except Exception:
            pass

        # 3) ç­‰å¾…åå°çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤šç­‰ 5 ç§’ï¼Œé¿å…å¡æ­»ï¼‰
        threads = getattr(self, "_threads", [])
        deadline = time.time() + 5.0  # æœ€å¤šç­‰ 5 ç§’
        for t in threads:
            if t is None:
                continue
            # åˆ†æ®µ joinï¼Œä¿è¯ UI è¿˜æ´»ç€
            while t.is_alive() and time.time() < deadline:
                try:
                    t.join(timeout=0.1)
                except Exception:
                    break

        # 4) é”€æ¯çª—å£
        try:
            self.master.destroy()
        except Exception:
            pass

        print("âœ… é€€å‡ºå®Œæˆ")

    def _busy(self, is_busy: bool, message: str = ""):
        """
        è®¾ç½®å¿™ç¢ŒçŠ¶æ€ï¼šç¦ç”¨ä¸»è¦æŒ‰é’® + æ›´æ–°çŠ¶æ€æ  + æ§åˆ¶è¿›åº¦æ¡
        åªä¿ç•™ä¸€å¥—é€»è¾‘ï¼Œé¿å…é‡å¤/é”™è¯¯çš„ getattr/hasattrã€‚
        """
        state = "disabled" if is_busy else "normal"

        # è¿™äº›æ˜¯ä½ åœ¨ _build_ui é‡Œåˆ›å»ºçš„æŒ‰é’®å±æ€§å
        button_names = [
            "btn_import",
            "btn_run_all",
            "btn_export",
            "btn_kplot",
            "btn_compare",
            "btn_priority",
            "btn_run_cluster",
            # å¦‚æœä½ è¿˜æœ‰å…¶å®ƒæŒ‰é’®ï¼Œæ¯”å¦‚æŠ¥å‘ŠæŒ‰é’®ï¼Œä¹Ÿå¯ä»¥åŠ ï¼š
            # "btn_report_offline",
        ]

        for name in button_names:
            if hasattr(self, name):
                btn = getattr(self, name)
                # ttk.Button / tk.Button éƒ½æ”¯æŒ config(state=...)
                try:
                    btn.config(state=state)
                except Exception:
                    pass

        # çŠ¶æ€æ 
        try:
            if hasattr(self, "status"):
                if is_busy:
                    self.status.set(message or "è¿è¡Œä¸­...")
                else:
                    self.status.set("å°±ç»ª")
        except Exception:
            pass

        # è¿›åº¦æ¡ï¼šä½ ç°åœ¨ progress é»˜è®¤æ˜¯ determinateï¼Œ
        # ä½†ä½ è¿™é‡Œç”¨ start/stop æ˜¯ indeterminate çš„æ–¹å¼ã€‚
        # ä¿é™©åšæ³•ï¼šåˆ‡æ¢ mode å¹¶ start/stopã€‚
        try:
            if hasattr(self, "progress"):
                if is_busy:
                    self.progress.config(mode="indeterminate")
                    self.progress.start(10)
                else:
                    self.progress.stop()
                    self.progress.config(mode="determinate")
                    self.progress["value"] = 0
        except Exception:
            pass

        try:
            self.update_idletasks()
        except Exception:
            pass

    def _normalize_col(self, s: str) -> str:
        """ç”¨äºåŒ¹é…åˆ—åï¼šå»ç©ºæ ¼/ä¸‹åˆ’çº¿/çŸ­æ¨ªçº¿/å¤§å°å†™ç»Ÿä¸€"""
        if s is None:
            return ""
        s = str(s).strip().lower()
        for ch in [" ", "\t", "\n", "\r", "_", "-", "â€”", "ï¼", "Â·", ".", "ï¼Œ", ",", "ï¼š", ":"]:
            s = s.replace(ch, "")
        return s

    def _auto_map_fields(self, df):
        """
        è‡ªåŠ¨è¯†åˆ«åˆ—åï¼Œå›å†™åˆ° self.cfg.field_map
        ç›®æ ‡å­—æ®µï¼š
        - textï¼ˆå¿…éœ€ï¼‰
        - asinï¼ˆå¯é€‰ï¼‰
        - starï¼ˆå¯é€‰ï¼‰
        - timeï¼ˆå¯é€‰ï¼‰
        """
        cols = list(df.columns)
        norm2orig = {self._normalize_col(c): c for c in cols}

        # å€™é€‰è¯åº“ï¼ˆä½ åé¢é‡åˆ°æ–°åˆ—åï¼Œå¾€è¿™é‡ŒåŠ å°±è¡Œï¼‰
        candidates = {
            "text": [
                "reviewtext", "review", "reviewcontent", "reviewbody", "content", "text", "body", "comment",
                "è¯„è®ºå†…å®¹", "è¯„è®ºæ­£æ–‡", "è¯„ä»·å†…å®¹", "è¯„ä»·æ­£æ–‡", "è¯„è®º", "è¯„ä»·", "å†…å®¹", "æ­£æ–‡"
            ],
            "asin": [
                "asin", "productasin", "parentasin", "sku", "spu", "å•†å“asin", "äº§å“asin", "å•†å“id", "äº§å“id"
            ],
            "star": [
                "star", "stars", "rating", "score", "rate", "è¯„åˆ†", "æ˜Ÿçº§", "æ˜Ÿ", "æ‰“åˆ†"
            ],
            "time": [
                "reviewtime", "time", "date", "datetime", "timestamp", "è¯„è®ºæ—¶é—´", "è¯„ä»·æ—¶é—´", "æ—¶é—´", "æ—¥æœŸ", "å‘è¡¨æ—¶é—´"
            ]
        }

        def find_col(key: str):
            # 1) å…ˆå°Šé‡ç”¨æˆ·/é…ç½®å†™æ­»çš„åˆ—åï¼ˆå­˜åœ¨å°±ç”¨ï¼‰
            cfg_name = (self.cfg.field_map.get(key) or "").strip()
            if cfg_name and cfg_name in cols:
                return cfg_name

            # 2) ç²¾ç¡®åŒ¹é…ï¼ˆnormalizeåç›¸ç­‰ï¼‰
            for cand in candidates[key]:
                n = self._normalize_col(cand)
                if n in norm2orig:
                    return norm2orig[n]

            # 3) æ¨¡ç³ŠåŒ…å«ï¼ˆnormalizeååŒ…å«ï¼‰
            for cand in candidates[key]:
                n = self._normalize_col(cand)
                for cn, orig in norm2orig.items():
                    if n and (n in cn or cn in n):
                        return orig

            return None

        mapped = {}
        for k in ["text", "asin", "star", "time"]:
            col = find_col(k)
            if col:
                mapped[k] = col

        # è‡³å°‘è¦æœ‰ text
        if "text" not in mapped:
            raise ValueError(
                "ç¼ºå°‘å¿…è¦åˆ—ï¼šè¯„è®ºæ­£æ–‡åˆ—ï¼ˆtextï¼‰ã€‚\n"
                f"å½“å‰åˆ—ï¼š{cols}\n"
                "è¯·æŠŠè¯„è®ºæ­£æ–‡åˆ—å‘½åä¸ºï¼šReviewText/è¯„è®ºå†…å®¹/è¯„è®ºæ­£æ–‡/è¯„ä»·å†…å®¹ ç­‰ï¼Œæˆ–åœ¨ settings.json é‡Œé…ç½® field_mapã€‚"
            )

        # å›å†™é…ç½®ï¼ˆè®©åç»­å…¨æµç¨‹éƒ½ç”¨è¯†åˆ«ç»“æœï¼‰
        self.cfg.field_map.update(mapped)

        # æ—¥å¿—æç¤ºï¼ˆä¸­è‹±ï¼‰
        self._log("âœ… Auto field mapping / è‡ªåŠ¨åˆ—åè¯†åˆ«ï¼š")
        self._log(f"   text -> {self.cfg.field_map.get('text')}")
        self._log(f"   asin -> {self.cfg.field_map.get('asin')}")
        self._log(f"   star -> {self.cfg.field_map.get('star')}")
        self._log(f"   time -> {self.cfg.field_map.get('time')}")

        # è‡ªåŠ¨é™çº§æç¤º
        if not self.cfg.field_map.get("asin"):
            self._log("â„¹ï¸ æœªè¯†åˆ«åˆ° ASIN åˆ—ï¼šè·¨ASINå¯¹æ¯”/çƒ­åŠ›å›¾åŠŸèƒ½å°†ä¸å¯ç”¨æˆ–è‡ªåŠ¨è·³è¿‡ã€‚")
        if not self.cfg.field_map.get("star"):
            self._log("â„¹ï¸ æœªè¯†åˆ«åˆ° Star/è¯„åˆ† åˆ—ï¼šæƒ…æ„Ÿæ¨¡å‹å¤±æ•ˆæ—¶çš„â€œæ˜Ÿçº§å…œåº•è´Ÿé¢è¿‡æ»¤â€å°†ä¸å¯ç”¨ã€‚")

    @staticmethod
    def apply_negative_filter(
        df: pd.DataFrame,
        star_col: str,
        sentiment_col: str | None,
        sentiment_conf_col: str | None,
        mode: str,
        star_threshold: float,
        conf_threshold: float,
        # ===== æ–°å¢ï¼šfusion å‚æ•° =====
        w_star: float = 1.0,
        w_sent: float = 1.0,
        fusion_keep_threshold: float = 1.0,
    ) -> pd.DataFrame:
        """
        ç»Ÿä¸€è´Ÿé¢è¿‡æ»¤é€»è¾‘ï¼ˆç§‘ç ” + äº§å“å®‰å…¨ï¼‰
        mode:
        - STAR_ONLY
        - SENTIMENT_ONLY
        - FUSION   (âœ… å‡çº§ä¸º WEIGHTED_FUSIONï¼šçœŸæ­£æ‹‰å¼€å·®å¼‚)
        """

        work = df.copy()

        # ---------- æ˜Ÿçº§æ¡ä»¶ ----------
        if star_col in work.columns:
            work[star_col] = pd.to_numeric(work[star_col], errors="coerce")
            star_neg = work[star_col] <= float(star_threshold)
        else:
            star_neg = pd.Series(False, index=work.index)

        # ---------- æƒ…æ„Ÿæ¡ä»¶ï¼ˆå¸¦ç½®ä¿¡åº¦ï¼‰ ----------
        if sentiment_col and sentiment_col in work.columns:
            sent_neg = (work[sentiment_col] == "negative")

            # é»˜è®¤ conf=0ï¼Œé¿å…ç¼ºåˆ—å¯¼è‡´å´©
            if sentiment_conf_col and sentiment_conf_col in work.columns:
                conf = pd.to_numeric(work[sentiment_conf_col], errors="coerce").fillna(0.0)
            else:
                conf = pd.Series(0.0, index=work.index)

            # conf_okï¼šå¿…é¡» >= é˜ˆå€¼æ‰ç®—â€œæœ‰æ•ˆè´Ÿé¢â€
            conf_ok = conf >= float(conf_threshold)
            sent_neg = sent_neg & conf_ok

            # sentiment å¼ºåº¦ï¼šæŠŠ conf æ˜ å°„åˆ° [0,1]ï¼ˆé˜ˆå€¼ä»¥ä¸Šæ‰æœ‰å¼ºåº¦ï¼‰
            # ä¾‹ï¼šconf_th=0.6ï¼Œconf=0.6 -> 0ï¼›conf=1.0 -> 1
            denom = max(1e-6, (1.0 - float(conf_threshold)))
            sent_strength = ((conf - float(conf_threshold)) / denom).clip(lower=0.0, upper=1.0)
            sent_strength = sent_strength * sent_neg.astype(float)
        else:
            sent_neg = pd.Series(False, index=work.index)
            sent_strength = pd.Series(0.0, index=work.index)

        # ---------- ç­–ç•¥é€‰æ‹© ----------
        mode = (mode or "STAR_ONLY").strip()

        if mode == "STAR_ONLY":
            mask = star_neg

        elif mode == "SENTIMENT_ONLY":
            mask = sent_neg

        elif mode == "FUSION":
            # âœ… WEIGHTED_FUSIONï¼šçœŸæ­£èƒ½æ‹‰å¼€å·®å¼‚
            # æ˜Ÿçº§ä¿¡å·ï¼šè´Ÿé¢=1ï¼Œéè´Ÿé¢=0
            star_signal = star_neg.astype(float)

            # æƒ…æ„Ÿä¿¡å·ï¼šsent_strength in [0,1]ï¼Œè¶Šæ¥è¿‘1è¶Šâ€œå¼ºè´Ÿé¢â€
            # èåˆå¾—åˆ†
            neg_score = float(w_star) * star_signal + float(w_sent) * sent_strength

            # ä¿ç•™é˜ˆå€¼ï¼šè¶Šé«˜è¶Šä¸¥æ ¼
            mask = neg_score >= float(fusion_keep_threshold)

            # å¯é€‰ï¼šæŠŠ score ç•™ä¸‹æ¥ï¼ˆåç»­ä½ åšåˆ†æ/è®ºæ–‡æ¶ˆèå¾ˆå¥½ç”¨ï¼‰
            work["_neg_score"] = neg_score

        else:
            # é˜²å¾¡ï¼šæœªçŸ¥æ¨¡å¼ï¼Œé€€åŒ–ä¸º STAR_ONLY
            mask = star_neg

        return work[mask].reset_index(drop=True)
